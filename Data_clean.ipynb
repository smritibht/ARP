{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from pandas_ods_reader import read_ods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data from api on the web\n",
    "url = 'http://chargepoints.dft.gov.uk/api/retrieve/registry/format/csv'\n",
    "chargepoint_df = pd.read_csv(url)\n",
    "\n",
    "# COMBINED WITH DATA FROM OCM (OPEN CHARGE MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chargeDeviceID</th>\n",
       "      <th>reference</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>subBuildingName</th>\n",
       "      <th>buildingName</th>\n",
       "      <th>buildingNumber</th>\n",
       "      <th>thoroughfare</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>connector8Type</th>\n",
       "      <th>connector8RatedOutputKW</th>\n",
       "      <th>connector8OutputCurrent</th>\n",
       "      <th>connector8RatedVoltage</th>\n",
       "      <th>connector8ChargeMethod</th>\n",
       "      <th>connector8ChargeMode</th>\n",
       "      <th>connector8TetheredCable</th>\n",
       "      <th>connector8Status</th>\n",
       "      <th>connector8Description</th>\n",
       "      <th>connector8Validated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c911241d00294e8bb714eee2e83fa475</td>\n",
       "      <td>PP-12289</td>\n",
       "      <td>Alex F Noble &amp; Son</td>\n",
       "      <td>55.875053</td>\n",
       "      <td>-3.173333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swinton Place</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa6c94460e902005a0b660266190c8ba</td>\n",
       "      <td>PP-12295</td>\n",
       "      <td>Ancaster Nissan Dealership</td>\n",
       "      <td>51.411173</td>\n",
       "      <td>-0.055369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>Croydon Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eb1848290d5a7de9c9ccabc67fefa211</td>\n",
       "      <td>PP-12290</td>\n",
       "      <td>Beadles Nissan Ltd</td>\n",
       "      <td>51.451127</td>\n",
       "      <td>0.050619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43-53</td>\n",
       "      <td>Eltham High Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91e50fe1e39af2869d3336eaaeebdb43</td>\n",
       "      <td>PP-12292</td>\n",
       "      <td>Benfield Motors</td>\n",
       "      <td>54.978947</td>\n",
       "      <td>-1.599306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176</td>\n",
       "      <td>Portland Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65b1e92c585fd4c2159d5f33b5030ff2</td>\n",
       "      <td>PP-12198</td>\n",
       "      <td>Circus Road</td>\n",
       "      <td>51.533633</td>\n",
       "      <td>-0.172353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circus Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     chargeDeviceID reference                        name  \\\n",
       "0  c911241d00294e8bb714eee2e83fa475  PP-12289          Alex F Noble & Son   \n",
       "1  fa6c94460e902005a0b660266190c8ba  PP-12295  Ancaster Nissan Dealership   \n",
       "2  eb1848290d5a7de9c9ccabc67fefa211  PP-12290         Beadles Nissan Ltd    \n",
       "3  91e50fe1e39af2869d3336eaaeebdb43  PP-12292             Benfield Motors   \n",
       "4  65b1e92c585fd4c2159d5f33b5030ff2  PP-12198                 Circus Road   \n",
       "\n",
       "    latitude  longitude subBuildingName buildingName buildingNumber  \\\n",
       "0  55.875053  -3.173333             NaN          NaN            NaN   \n",
       "1  51.411173  -0.055369             NaN          NaN             61   \n",
       "2  51.451127   0.050619             NaN          NaN          43-53   \n",
       "3  54.978947  -1.599306             NaN          NaN            176   \n",
       "4  51.533633  -0.172353             NaN          NaN            NaN   \n",
       "\n",
       "         thoroughfare         street  ... connector8Type  \\\n",
       "0                 NaN  Swinton Place  ...            NaN   \n",
       "1        Croydon Road            NaN  ...            NaN   \n",
       "2  Eltham High Street            NaN  ...            NaN   \n",
       "3       Portland Road            NaN  ...            NaN   \n",
       "4         Circus Road            NaN  ...            NaN   \n",
       "\n",
       "  connector8RatedOutputKW connector8OutputCurrent connector8RatedVoltage  \\\n",
       "0                     NaN                     NaN                    NaN   \n",
       "1                     NaN                     NaN                    NaN   \n",
       "2                     NaN                     NaN                    NaN   \n",
       "3                     NaN                     NaN                    NaN   \n",
       "4                     NaN                     NaN                    NaN   \n",
       "\n",
       "  connector8ChargeMethod connector8ChargeMode connector8TetheredCable  \\\n",
       "0                    NaN                  NaN                     NaN   \n",
       "1                    NaN                  NaN                     NaN   \n",
       "2                    NaN                  NaN                     NaN   \n",
       "3                    NaN                  NaN                     NaN   \n",
       "4                    NaN                  NaN                     NaN   \n",
       "\n",
       "  connector8Status connector8Description connector8Validated  \n",
       "0              NaN                   NaN                 NaN  \n",
       "1              NaN                   NaN                 NaN  \n",
       "2              NaN                   NaN                 NaN  \n",
       "3              NaN                   NaN                 NaN  \n",
       "4              NaN                   NaN                 NaN  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get shape of data\n",
    "chargepoint_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31702, 158)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chargepoint_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# retreive comments from openchargemap api\n",
    "url = 'https://api.openchargemap.io/v3/poi/?output=json&countrycode=GB&maxresults=100000&compact=true&verbose=false&key=1e2b0b1e-5b1e-4b3a-8b9a-0b8b9a3a2b1e&includecomments=true'\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# convert json to dataframe\n",
    "ocm_comments_df = pd.DataFrame(data)\n",
    "ocm_comments_df.to_csv('data/ocm_comments.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25344, 23)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocm_comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocm_comments_df.head()\n",
    "# unnest the column AddressInfo and UserComments\n",
    "ocm_comments_df = pd.concat([ocm_comments_df.drop(['AddressInfo'], axis=1), ocm_comments_df['AddressInfo'].apply(pd.Series)], axis=1)\n",
    "\n",
    "# COMBINED WITH CHARGEPOINT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two dataframes using latitude and longitude\n",
    "chargepoint_df = chargepoint_df.merge(ocm_comments_df, how='left', left_on=['latitude', 'longitude'], right_on=['Latitude', 'Longitude'])\n",
    "\n",
    "# COMBINED DATA (OCM + CHARGEPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chargeDeviceID</th>\n",
       "      <th>reference</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>subBuildingName</th>\n",
       "      <th>buildingName</th>\n",
       "      <th>buildingNumber</th>\n",
       "      <th>thoroughfare</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>CountryID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>DistanceUnit</th>\n",
       "      <th>AccessComments</th>\n",
       "      <th>RelatedURL</th>\n",
       "      <th>ContactTelephone1</th>\n",
       "      <th>ContactTelephone2</th>\n",
       "      <th>ContactEmail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c911241d00294e8bb714eee2e83fa475</td>\n",
       "      <td>PP-12289</td>\n",
       "      <td>Alex F Noble &amp; Son</td>\n",
       "      <td>55.875053</td>\n",
       "      <td>-3.173333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swinton Place</td>\n",
       "      <td>...</td>\n",
       "      <td>EH20 9FB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.875053</td>\n",
       "      <td>-3.173333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Charge Points Located in Customer Parking Area...</td>\n",
       "      <td>http://afnoble.nissan.co.uk/</td>\n",
       "      <td>0131 440 5353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa6c94460e902005a0b660266190c8ba</td>\n",
       "      <td>PP-12295</td>\n",
       "      <td>Ancaster Nissan Dealership</td>\n",
       "      <td>51.411173</td>\n",
       "      <td>-0.055369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>Croydon Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eb1848290d5a7de9c9ccabc67fefa211</td>\n",
       "      <td>PP-12290</td>\n",
       "      <td>Beadles Nissan Ltd</td>\n",
       "      <td>51.451127</td>\n",
       "      <td>0.050619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43-53</td>\n",
       "      <td>Eltham High Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91e50fe1e39af2869d3336eaaeebdb43</td>\n",
       "      <td>PP-12292</td>\n",
       "      <td>Benfield Motors</td>\n",
       "      <td>54.978947</td>\n",
       "      <td>-1.599306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176</td>\n",
       "      <td>Portland Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NE2 1AR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.978947</td>\n",
       "      <td>-1.599306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>020 7247 4114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65b1e92c585fd4c2159d5f33b5030ff2</td>\n",
       "      <td>PP-12198</td>\n",
       "      <td>Circus Road</td>\n",
       "      <td>51.533633</td>\n",
       "      <td>-0.172353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circus Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     chargeDeviceID reference                        name  \\\n",
       "0  c911241d00294e8bb714eee2e83fa475  PP-12289          Alex F Noble & Son   \n",
       "1  fa6c94460e902005a0b660266190c8ba  PP-12295  Ancaster Nissan Dealership   \n",
       "2  eb1848290d5a7de9c9ccabc67fefa211  PP-12290         Beadles Nissan Ltd    \n",
       "3  91e50fe1e39af2869d3336eaaeebdb43  PP-12292             Benfield Motors   \n",
       "4  65b1e92c585fd4c2159d5f33b5030ff2  PP-12198                 Circus Road   \n",
       "\n",
       "    latitude  longitude subBuildingName buildingName buildingNumber  \\\n",
       "0  55.875053  -3.173333             NaN          NaN            NaN   \n",
       "1  51.411173  -0.055369             NaN          NaN             61   \n",
       "2  51.451127   0.050619             NaN          NaN          43-53   \n",
       "3  54.978947  -1.599306             NaN          NaN            176   \n",
       "4  51.533633  -0.172353             NaN          NaN            NaN   \n",
       "\n",
       "         thoroughfare         street  ...  Postcode CountryID   Latitude  \\\n",
       "0                 NaN  Swinton Place  ...  EH20 9FB       1.0  55.875053   \n",
       "1        Croydon Road            NaN  ...       NaN       NaN        NaN   \n",
       "2  Eltham High Street            NaN  ...       NaN       NaN        NaN   \n",
       "3       Portland Road            NaN  ...   NE2 1AR       1.0  54.978947   \n",
       "4         Circus Road            NaN  ...       NaN       NaN        NaN   \n",
       "\n",
       "  Longitude DistanceUnit                                     AccessComments  \\\n",
       "0 -3.173333          0.0  Charge Points Located in Customer Parking Area...   \n",
       "1       NaN          NaN                                                NaN   \n",
       "2       NaN          NaN                                                NaN   \n",
       "3 -1.599306          0.0                                                NaN   \n",
       "4       NaN          NaN                                                NaN   \n",
       "\n",
       "                     RelatedURL ContactTelephone1 ContactTelephone2  \\\n",
       "0  http://afnoble.nissan.co.uk/     0131 440 5353               NaN   \n",
       "1                           NaN               NaN               NaN   \n",
       "2                           NaN               NaN               NaN   \n",
       "3                           NaN     020 7247 4114               NaN   \n",
       "4                           NaN               NaN               NaN   \n",
       "\n",
       "  ContactEmail  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# save the data to csv\n",
    "chargepoint_df.to_csv('data/chargepoint.csv')\n",
    "\n",
    "chargepoint_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>PES area</th>\n",
       "      <th>Average variable unit price (Â£/kWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Northern Scotland</td>\n",
       "      <td>0.118306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>0.147227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>0.113377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>South East</td>\n",
       "      <td>0.109783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>South Wales</td>\n",
       "      <td>0.122350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           PES area  Average variable unit price (Â£/kWh)\n",
       "0  2010  Northern Scotland                             0.118306\n",
       "1  2010   Northern Ireland                             0.147227\n",
       "2  2010      West Midlands                             0.113377\n",
       "3  2010         South East                             0.109783\n",
       "4  2010        South Wales                             0.122350"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get electricity data with only sheet name \"2.2.4\" and skipping first 12 rows\n",
    "electricity_df = pd.read_excel('data/table_224.xlsx', sheet_name='2.2.4', skiprows=12)\n",
    "# rename the columns\n",
    "electricity_df.columns = ['Year', 'Region', 'PES area', '1', '2', '3', '4', '5', '6', 'Average variable unit price (Â£/kWh)', '7']\n",
    "# drop columns 1-7\n",
    "electricity_df = electricity_df.drop(['1', '2', '3', '4', '5', '6', '7'], axis=1)\n",
    "# drop Region column\n",
    "electricity_df = electricity_df.drop(['Region'], axis=1)\n",
    "electricity_df.head()\n",
    "\n",
    "# COMBINED WITH FUEL PRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Northern Scotland', 'Northern Ireland', 'West Midlands',\n",
       "       'South East', 'South Wales', 'Southern Scotland', 'Eastern',\n",
       "       'Yorkshire', 'Merseyside & North Wales', 'London', 'North West',\n",
       "       'North East', 'East Midlands', 'South West', 'Southern',\n",
       "       'United Kingdom', 'North Scotland', 'South Scotland'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show unique values in PES area\n",
    "electricity_df['PES area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['North Scotland', 'Northern Ireland', 'West Midlands',\n",
       "       'South East', 'South Wales', 'South Scotland', 'Eastern',\n",
       "       'Yorkshire', 'Merseyside & North Wales', 'London', 'North West',\n",
       "       'North East', 'East Midlands', 'South West', 'Southern',\n",
       "       'United Kingdom'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace PES area values with the correct names\n",
    "\n",
    "electricity_df['PES area'] = electricity_df['PES area'].replace(['Northern Scotland'], 'North Scotland')\n",
    "electricity_df['PES area'] = electricity_df['PES area'].replace(['Southern Scotland'], 'South Scotland')\n",
    "# check if the values are replaced\n",
    "electricity_df['PES area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region name</th>\n",
       "      <th>ITL level</th>\n",
       "      <th>ITL code</th>\n",
       "      <th>Year</th>\n",
       "      <th>gdhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>1997</td>\n",
       "      <td>10757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>Other</td>\n",
       "      <td>TLB</td>\n",
       "      <td>1997</td>\n",
       "      <td>11016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North East</td>\n",
       "      <td>ITL1</td>\n",
       "      <td>TLC</td>\n",
       "      <td>1997</td>\n",
       "      <td>9253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tees Valley and Durham</td>\n",
       "      <td>ITL2</td>\n",
       "      <td>TLC1</td>\n",
       "      <td>1997</td>\n",
       "      <td>9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hartlepool and Stockton-on-Tees</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLC11</td>\n",
       "      <td>1997</td>\n",
       "      <td>9264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Region name ITL level ITL code  Year   gdhi\n",
       "0                   United Kingdom        UK       UK  1997  10757\n",
       "1                          England     Other      TLB  1997  11016\n",
       "2                       North East      ITL1      TLC  1997   9253\n",
       "3           Tees Valley and Durham      ITL2     TLC1  1997   9200\n",
       "4  Hartlepool and Stockton-on-Tees      ITL3    TLC11  1997   9264"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gdhi data\n",
    "gdhi_df = pd.read_excel(\"data/regionalgrossdisposablehouseholdincomeallitlregions.xls\", sheet_name=\"Table 3\", skiprows=1)\n",
    "# melt the dataframe\n",
    "gdhi_df = pd.melt(gdhi_df, id_vars=['Region name', 'ITL level','ITL code'], var_name='Year', value_vars=['1997', '1998', \n",
    "                                                                                                         '1999', '2000', '2001', '2002', \n",
    "                                                                                                         '2003','2004', '2005', '2006', \n",
    "                                                                                                         '2007', '2008', '2009', '2010',\n",
    "                                                                                                         '2011', '2012', '2013', '2014', \n",
    "                                                                                                         '2015', '2016', '2017','2018', \n",
    "                                                                                                         '2019', '2020'])\n",
    "# rename the column value to gdhi\n",
    "gdhi_df = gdhi_df.rename(columns={'value': 'gdhi'})\n",
    "gdhi_df.head()\n",
    "\n",
    "# COMBINED WITH POPULATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population data\n",
    "population_df = pd.read_csv('data/ukdetailedtimeseries2001to2020/MYEB1_detailed_population_estimates_series_UK_(2020_geog21).csv')\n",
    "# remove word \"population\" from column names\n",
    "population_df.columns = population_df.columns.str.replace('population_', '')\n",
    "\n",
    "# melt the dataframe\n",
    "population_df = pd.melt(population_df, id_vars=['ladcode21', 'laname21','country','sex','age'], var_name='Year', \n",
    "                        value_vars=['2001', '2002', '2003', '2004', '2005', '2006', '2007','2008', '2009', '2010', '2011', '2012', \n",
    "                                    '2013','2014', '2015', '2016', '2017', '2018', '2019', '2020'])\n",
    "# rename the column value to population\n",
    "population_df = population_df.rename(columns={'value': 'population'})\n",
    "\n",
    "# remove ladcode21 column\n",
    "population_df = population_df.drop(['ladcode21','country'], axis=1)\n",
    "\n",
    "# COMBINED WITH GDHI DATA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the values in laname21 column to match the values in gdhi data \"Region name\" columns\n",
    "# change Barking and Dagenham to \"Barking & Dagenham and Havering\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Barking and Dagenham', 'Havering'], 'Barking & Dagenham and Havering')\n",
    "# change \"Angus\" to \"Angus and Dundee City\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Angus', 'Dundee City'], 'Angus and Dundee City')\n",
    "# change Maldon to Heart of Essex\n",
    "population_df.loc[population_df['laname21'].str.contains('Maldon', case=False, na=False), 'laname21'] = 'Heart of Essex'\n",
    "# change the values in laname21 column to match the values in gdhi data \"Region name\" columns\n",
    "# change \"Hartlepool\" to \"Durham CC\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hartlepool'], 'Hartlepool and Stockton-on-Tees')\n",
    "# change \"Aberdeen City\" to \"Aberdeen City and Aberdeenshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Aberdeen City'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Aberdeenshire\" to \"Aberdeen City and Aberdeenshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Aberdeenshire'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Adur\" to \"West Sussex (South West)\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Worthing', 'Adur', 'Arun', 'Chichester', 'Horsham', 'Mid Sussex'], 'West Sussex (South West)')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Allerdale', 'Barrow-in-Furness', 'Carlisle', 'Copeland'], 'West Cumbria')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Eden', 'South Lakeland'], 'East Cumbria')\n",
    "# change \"Argyll and Bute\" to \"Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Argyll and Bute'], 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute')\n",
    "# change Ashfield to \"North Nottinghamshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Ashfield', 'Bassetlaw', 'Bolsover', 'Gedling'], 'North Nottinghamshire')\n",
    "# change Babergh to \"Suffolk\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Babergh', 'East Suffolk', 'Ipswich', 'Mid Suffolk', 'West Suffolk'], 'Suffolk')\n",
    "# change Barnsley to \"Barnsley, Doncaster and Rotherham\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Barnsley', 'Doncaster', 'Rotherham'], 'Barnsley, Doncaster and Rotherham')\n",
    "# change Basildon to \"Thurrock\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Basildon'], 'Thurrock')\n",
    "# change Basingstoke and Deane to \"North Hampshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Basingstoke and Deane', 'Hart', 'Rushmoor'], 'North Hampshire')\n",
    "# change Bath and North East Somerset to \"Bath and North East Somerset, North Somerset and South Gloucestershire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bath and North East Somerset', 'North Somerset', 'South Gloucestershire'], 'Bath and North East Somerset, North Somerset and South Gloucestershire')\n",
    "# change Bexley to \"Bexley and Greenwich\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bexley', 'Greenwich'], 'Bexley and Greenwich')\n",
    "# change Blaby to \"Leicestershire CC and Rutland\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Blaby', 'Charnwood', 'Harborough', 'Hinckley and Bosworth', 'Melton', 'North West Leicestershire', 'Oadby and Wigston', 'Rutland'], 'Leicestershire CC and Rutland')\n",
    "# change Blaenau Gwent to \"Gwent Valleys\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Blaenau Gwent', 'Torfaen'], 'Gwent Valleys')\n",
    "# change Bolton to \"Greater Manchester North West\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bolton', 'Bury'], 'Greater Manchester North West')\n",
    "# change Boston to \"Lincolnshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Boston', 'North Kesteven', 'West Lindsey', 'South Kesteven', 'South Holland'], 'Lincolnshire')\n",
    "# change Bracknell Forest to \"Berkshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bracknell Forest', 'Reading', 'Slough', 'West Berkshire', 'Windsor and Maidenhead', 'Wokingham'], 'Berkshire')\n",
    "# change Braintree to \"Essex Haven Gateway\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Braintree', 'Brentwood', 'Castle Point', 'Colchester', 'Chelmsford', 'Rochford'], 'Essex Haven Gateway')\n",
    "# change Breckland to \"Breckland and South Norfolk\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Breckland', 'Broadland', 'Great Yarmouth', 'South Norfolk'], 'Breckland and South Norfolk')\n",
    "# change Bridgend to \"Bridgend and Neath Port Talbot\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bridgend', 'Merthyr Tydfil', 'Neath Port Talbot', 'Rhondda Cynon Taf'], 'Bridgend and Neath Port Talbot')\n",
    "#  change Bromsgrove to \"Worcestershire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bromsgrove', 'Malvern Hills', 'Redditch', 'Worcester', 'Wychavon'], 'Worcestershire')\n",
    "# change Broxbourne to \"Hertfordshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Watford', 'Stevenage', 'St Albans', 'Three Rivers', 'Welwyn Hatfield', 'North Hertfordshire', 'Broxbourne', 'East Hertfordshire', 'Dacorum', 'Hertsmere'], 'Hertfordshire')\n",
    "# change Broxtowe to \"South and West Derbyshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Broxtowe', 'Amber Valley', 'Derbyshire Dales', 'Erewash', 'South Derbyshire'], 'South and West Derbyshire')\n",
    "# change Buckinghamshire to \"Buckinghamshire CC\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Buckinghamshire'], 'Buckinghamshire CC')\n",
    "# change Burnley to \"East Lancashire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Burnley', 'Hyndburn', 'Pendle', 'Ribble Valley', 'Rossendale'], 'East Lancashire')\n",
    "# change Caerphilly to \"Cardiff and Vale of Glamorgan\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Caerphilly', 'Cardiff', 'Vale of Glamorgan'], 'Cardiff and Vale of Glamorgan')\n",
    "# change Cambridge to Cambridgeshire CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Cambridge', 'East Cambridgeshire', 'Fenland', 'Huntingdonshire', 'South Cambridgeshire'], 'Cambridgeshire CC')\n",
    "# change Cannock Chase to Staffordshire CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Newcastle-under-Lyme', 'Cannock Chase', 'East Staffordshire', 'Lichfield', 'South Staffordshire', 'Tamworth', 'Staffordshire Moorlands', 'Stafford'], 'Staffordshire CC')\n",
    "# change Carmarthenshire to South West Wales\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Carmarthenshire', 'Pembrokeshire'], 'South West Wales')\n",
    "# change Ceredigion to Central Valleys\n",
    "population_df.loc[population_df['laname21'].str.contains('Ceredigion', case=False, na=False), 'laname21'] = 'Central Valleys'\n",
    "# change Cherwell to Oxfordshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Cherwell', 'Oxford', 'South Oxfordshire', 'Vale of White Horse', 'West Oxfordshire'], 'Oxfordshire')\n",
    "# change Chesterfield to East Derbyshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Chesterfield', 'North East Derbyshire', 'High Peak'], 'East Derbyshire')\n",
    "# change Chorley to Chorley and West Lancashire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Chorley', 'Fylde', 'South Ribble', 'West Lancashire'], 'Chorley and West Lancashire')\n",
    "# change City of London to Camden and City of London\n",
    "population_df['laname21'] = population_df['laname21'].replace(['City of London', 'Camden'], 'Camden and City of London')\n",
    "# change Clackmannanshire to Clackmannanshire and Fife\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Clackmannanshire', 'Fife'], 'Clackmannanshire and Fife')\n",
    "# change Conwy to Conwy and Denbighshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Conwy', 'Denbighshire'], 'Conwy and Denbighshire')\n",
    "# change Cornwall to Cornwall and Isles of Scilly\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Cornwall', 'Isles of Scilly'], 'Cornwall and Isles of Scilly')\n",
    "# change County Durham to Durham CC\n",
    "population_df.loc[population_df['laname21'].str.contains('County Durham', case=False, na=False), 'laname21'] = 'Durham CC'\n",
    "# change Crawley to West Sussex\n",
    "population_df.loc[population_df['laname21'].str.contains('Crawley', case=False, na=False), 'laname21'] = 'West Sussex (North East)'\n",
    "# change East Ayrshire to East Ayrshire and North Ayrshire mainland\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Ayrshire', 'North Ayrshire'], 'East Ayrshire and North Ayrshire mainland')\n",
    "# change East Devon to Devon CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Devon', 'Exeter', 'Mid Devon', 'North Devon', 'South Hams', 'Teignbridge', 'Torridge', 'West Devon'], 'Devon CC')\n",
    "# change East Dunbartonshire to East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Dunbartonshire', 'West dunbartonshire', 'West Dunbartonshire'], 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond')\n",
    "# change East Hampshire to Central Hampshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Hampshire', 'Eastleigh', 'New Forest'], 'Central Hampshire')\n",
    "# change East Lothian to East Lothian and Midlothian\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Lothian', 'Midlothian'], 'East Lothian and Midlothian')\n",
    "# change East Renfrewshire to Inverclyde, East Renfrewshire and Renfrewshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Renfrewshire', 'Inverclyde', 'Renfrewshire'], 'Inverclyde, East Renfrewshire and Renfrewshire')\n",
    "# change Eastbourne to East Sussex\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Eastbourne', 'East Sussex'])\n",
    "# change Elmbridge to West Surrey\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Elmbridge', 'Epsom and Ewell', 'Guildford', 'Runnymede', 'Spelthorne', 'Woking', 'Waverley', 'Surrey Heath'], 'West Surrey')\n",
    "# change Fareham to South Hampshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Fareham', 'Gosport', 'Havant'], 'South Hampshire')\n",
    "# change Flintshire to Flintshire and Wrexham\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Flintshire', 'Wrexham'], 'Flintshire and Wrexham')\n",
    "# change Folkestone and Hythe to East Kent\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Folkestone and Hythe', 'Dover', 'Ashford', 'Canterbury'], 'East Kent')\n",
    "# change Forest of Dean to Gloucestershire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Gloucester', 'Forest of Dean', 'Cotswold', 'Cheltenham', 'Stroud', 'Tewkesbury'], 'Gloucestershire')\n",
    "# change Gateshead to Tyneside\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Newcastle upon Tyne', 'Gateshead', 'North Tyneside', 'South Tyneside'], 'Tyneside')\n",
    "# change Hackney to Hackney and Newham\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hackney', 'Newham'], 'Hackney and Newham')\n",
    "# change Hammersmith and Fulham to Kensington & Chelsea and Hammersmith & Fulham\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hammersmith and Fulham', 'Kensington and Chelsea'], 'Kensington & Chelsea and Hammersmith & Fulham')\n",
    "# change Harlow to Essex Thames Gateway\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Harlow', 'Epping Forest'], 'Essex Thames Gateway')\n",
    "# change Harrow to Harrow and Hillingdon\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Harrow', 'Hillingdon'], 'Harrow and Hillingdon')\n",
    "# change Haringey to Haringey and Islington\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Haringey', 'Islington'], 'Haringey and Islington')\n",
    "# change Hastings to East Sussex CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hastings', 'Lewes', 'Rother', 'Wealden'], 'East Sussex CC')\n",
    "# change Highland to Highlands and Islands\n",
    "population_df.loc[population_df['laname21'].str.contains('Highland', case=False, na=False), 'laname21'] = 'Caithness and Sutherland and Ross and Cromarty'\n",
    "# change Hounslow to Hounslow and Richmond upon Thames\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hounslow', 'Richmond upon Thames'], 'Hounslow and Richmond upon Thames')\n",
    "# change King's Lynn and West Norfolk to North and West Norfolk\n",
    "population_df['laname21'] = population_df['laname21'].replace([\"King's Lynn and West Norfolk\", 'North Norfolk'], 'North and West Norfolk')\n",
    "# change Kingston upon Thames to Merton, Kingston upon Thames and Sutton\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Kingston upon Thames', 'Merton', 'Sutton'], 'Merton, Kingston upon Thames and Sutton')\n",
    "# change Kirklees to Calderdale and Kirklees\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Kirklees', 'Calderdale'], 'Calderdale and Kirklees')\n",
    "# change Knowsley to East Merseyside\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Knowsley', 'St. Helens'], 'East Merseyside')\n",
    "# change Lancaster to Lancaster and Wyre\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Lancaster', 'Wyre', 'Wyre Forest'], 'Lancaster and Wyre')\n",
    "# change Lewisham to Lewisham and Southwark\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Lewisham', 'Southwark'], 'Lewisham and Southwark')\n",
    "# change Lincoln to North and North East Lincolnshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Lincoln', 'North East Lincolnshire', 'North Lincolnshire', 'East Lindsey'], 'North and North East Lincolnshire')\n",
    "# change Maidstone to Medway\n",
    "population_df['laname21'] = population_df['laname21'].replace('Maidstone', 'Medway')\n",
    "# change Mansfield to Nottingham\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Mansfield', 'Newark and Sherwood'], 'Nottingham')\n",
    "# change Mendip to Somerset\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Mendip', 'South Somerset', 'Somerset West and Taunton', 'Sedgemoor'], 'Somerset')\n",
    "# change Mole Valley to East Surrey\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Mole Valley', 'Reigate and Banstead', 'Tandridge'], 'East Surrey')\n",
    "# change Monmouthshire to Monmouthshire and Newport\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Monmouthshire', 'Newport'], 'Monmouthshire and Newport')\n",
    "# change Moray to Inverness and Nairn and Moray, Badenoch and Strathspey\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Moray'], 'Inverness and Nairn and Moray, Badenoch and Strathspey')\n",
    "# change North Warwickshire to Warwickshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Warwick', 'North Warwickshire', 'Nuneaton and Bedworth', 'Rugby', 'Stratford-on-Avon'], 'Warwickshire')\n",
    "# change Norwich to Norwich and East Norfolk\n",
    "population_df.loc[population_df['laname21'].str.contains('Norwich', case=False, na=False), 'laname21'] = 'Norwich and East Norfolk'\n",
    "# change Oldham to Greater Manchester North East\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Oldham', 'Rochdale', 'Salford'], 'Greater Manchester North East')\n",
    "# change Perth and Kinross to Perth and Kinross and Stirling\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Perth and Kinross', 'Stirling'], 'Perth and Kinross and Stirling')\n",
    "# change preston to Mid Lancashire\n",
    "population_df.loc[population_df['laname21'].str.contains('Preston', case=False, na=False), 'laname21'] = 'Mid Lancashire'\n",
    "# change 'Redcar and Cleveland' to South Teesside\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Redcar and Cleveland'], 'South Teesside')\n",
    "# change Redcar and Cleveland to North Yorkshire CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Richmondshire', 'Middlesbrough', 'Hambleton', 'Harrogate', 'Ryedale', 'Scarborough', 'Selby', 'Craven'], 'North Yorkshire CC')\n",
    "# change Redbridge to Redbridge and Waltham Forest\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Redbridge', 'Waltham Forest'], 'Redbridge and Waltham Forest')\n",
    "# change Rushcliffe to Nottinghamshire\n",
    "population_df.loc[population_df['laname21'].str.contains('Rushcliffe', case=False, na=False), 'laname21'] = 'South Nottinghamshire'\n",
    "# change Shropshire to Shropshire CC\n",
    "population_df.loc[population_df['laname21'].str.contains('Shropshire', case=False, na=False), 'laname21'] = 'Shropshire CC'\n",
    "# change Stockport to Greater Manchester South East\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Stockport', 'Tameside', 'Wigan'], 'Greater Manchester South East')\n",
    "# change 'Trafford' to Greater Manchester South West\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Trafford'], 'Greater Manchester South West')\n",
    "# change Stockton-on-Tees to Hartlepool and Stockton-on-Tees\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Stockton-on-Tees', 'Hartlepool and Stockton-on-Tees'])\n",
    "# change Tendring to Essex\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Tendring', 'Uttlesford'], 'West Essex')\n",
    "# change Test Valley to Central Hampshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Test Valley'], 'Central Hampshire')\n",
    "# change Winchester to Portsmouth\n",
    "population_df.loc[population_df['laname21'].str.contains('Winchester', case=False, na=False), 'laname21'] = 'Portsmouth'\n",
    "# 'Tonbridge and Malling' to west Kent\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Tonbridge and Malling', 'Tunbridge Wells', 'Sevenoaks'], 'West Kent')\n",
    "# change Tunbridge Wells to Kent Thames Gateway\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Thanet', 'Swale', 'Gravesham', 'Dartford'], 'Kent Thames Gateway')\n",
    "\n",
    "# group the population data by year, laname21, sex and age and sum the population\n",
    "population_df = population_df.groupby(['Year', 'laname21', 'sex', 'age'])['population'].sum().reset_index()\n",
    "\n",
    "# check if population data and gdhi data have the same laname21 and Region name and save as text file\n",
    "set_pop = set(gdhi_df['Region name'].unique()) - set(population_df['laname21'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>ITL level</th>\n",
       "      <th>ITL code</th>\n",
       "      <th>Year</th>\n",
       "      <th>gdhi</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "      <th>ITL level 1</th>\n",
       "      <th>ITL level 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2267</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2373</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2445</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2481</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2569</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ITL level 3 ITL level ITL code  Year     gdhi  sex  \\\n",
       "0  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "1  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "2  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "3  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "4  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "\n",
       "   age  population ITL level 1             ITL level 2  \n",
       "0    0        2267    Scotland  North Eastern Scotland  \n",
       "1    1        2373    Scotland  North Eastern Scotland  \n",
       "2    2        2445    Scotland  North Eastern Scotland  \n",
       "3    3        2481    Scotland  North Eastern Scotland  \n",
       "4    4        2569    Scotland  North Eastern Scotland  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the dataframes gdhi_df and population_df on laname21 and Year\n",
    "gdhi_population_df = gdhi_df.merge(population_df, how='right', left_on=['Region name', 'Year'], right_on=['laname21', 'Year'])\n",
    "gdhi_population_df\n",
    "\n",
    "# rename Region name to ITL level 3\n",
    "gdhi_population_df = gdhi_population_df.rename(columns={'Region name': 'ITL level 3'})\n",
    "\n",
    "# drop laname21 column\n",
    "gdhi_population_df = gdhi_population_df.drop(['laname21'], axis=1)\n",
    "\n",
    "# remove all rows with ITL2\n",
    "gdhi_population_df = gdhi_population_df[gdhi_population_df['ITL level'] == 'ITL3']\n",
    "\n",
    "# Create a new column ITL level 1 such that it is the first 3 letters of ITL code are TLC then value is North East, \n",
    "# if TLD then value is North West, \n",
    "# if TLE then value is Yorkshire and The Humber, \n",
    "# if TLF then value is East Midlands, \n",
    "# if TLG then value is West Midlands, \n",
    "# if TLH then value is East of England, \n",
    "# if TLI then value is London, \n",
    "# if TLJ then value is South East, \n",
    "# if TLK then value is South West, \n",
    "# if TLM then value is Wales, \n",
    "# if TLN then value is Scotland, \n",
    "# if TLP then value is Northern Ireland\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL code'].str[:3]\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLC'], 'North East')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLD'], 'North West')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLE'], 'Yorkshire and The Humber')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLF'], 'East Midlands')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLG'], 'West Midlands')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLH'], 'East of England')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLI'], 'London')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLJ'], 'South East')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLK'], 'South West')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLL'], 'Wales')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLM'], 'Scotland')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLN'], 'Northern Ireland')\n",
    "\n",
    "# create a new column ITL level 2 such that it is the first 4 letters of ITL code are TLC1 then value is Tees Valley and Durham,\n",
    "# if TLC2 then value is Northumberland and Tyne and Wear,\n",
    "# if TLD1 then value is Cumbria,\n",
    "# if TLD3 then value is Greater Manchester,\n",
    "# if TLD4 then value is Lancashire,\n",
    "# if TLD6 then value is Cheshire,\n",
    "# if TLD7 then value is Merseyside,\n",
    "# if TLE1 then value is East Yorkshire and Northern Lincolnshire,\n",
    "# if TLE2 then value is North Yorkshire,\n",
    "# if TLE3 then value is South Yorkshire,\n",
    "# if TLE4 then value is West Yorkshire,\n",
    "# if TLF1 then value is Derbyshire and Nottinghamshire,\n",
    "# if TLF2 then value is Leicestershire, Rutland and Northamptonshire,\n",
    "# if TLF3 then value is Lincolnshire,\n",
    "# if TLG1 then value is Herefordshire, Worcestershire and Warwickshire,\n",
    "# if TLG2 then value is Shropshire and Staffordshire,\n",
    "# if TLG3 then value is West Midlands,\n",
    "# if TLH1 then value is East Anglia,\n",
    "# if TLH2 then value is Bedfordshire and Hertfordshire,\n",
    "# if TLH3 then value is Essex,\n",
    "# if TLI3 then value is Inner London - West,\n",
    "# if TLI4 then value is Inner London - East,\n",
    "# if TLI5 then value is Outer London - East and North East,\n",
    "# if TLI6 then value is Outer London - South,\n",
    "# if TLI7 then value is Outer London - West and North West,\n",
    "# if TLJ1 then value is Berkshire, Buckinghamshire and Oxfordshire,\n",
    "# if TLJ2 then value is Surrey, East and West Sussex,\n",
    "# if TLJ3 then value is Hampshire and Isle of Wight,\n",
    "# if TLJ4 then value is Kent,\n",
    "# if TLK1 then value is Gloucestershire, Wiltshire and Bristol/Bath area,\n",
    "# if TLK2 then value is Dorset and Somerset,\n",
    "# if TLK3 then value is Cornwall and Isles of Scilly,\n",
    "# if TLK4 then value is Devon,\n",
    "# if TLL1 then value is West Wales and The Valleys,\n",
    "# if TLL2 then value is East Wales,\n",
    "# if TLM5 then value is North Eastern Scotland,\n",
    "# if TLM6 then value is Highlands and Islands,\n",
    "# if TLM7 then value is Eastern Scotland,\n",
    "# if TLM8 then value is West Central Scotland,\n",
    "# if TLM9 then value is Southern Scotland,\n",
    "# if TLN0 then value is Northern Ireland\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL code'].str[:4]\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLC1'], 'Tees Valley and Durham')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLC2'], 'Northumberland and Tyne and Wear')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD1'], 'Cumbria')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD3'], 'Greater Manchester')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD4'], 'Lancashire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD6'], 'Cheshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD7'], 'Merseyside')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLE1'], 'East Yorkshire and Northern Lincolnshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLE2'], 'North Yorkshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLE3'], 'South Yorkshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLE4'], 'West Yorkshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLF1'], 'Derbyshire and Nottinghamshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLF2'], 'Leicestershire, Rutland and Northamptonshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLF3'], 'Lincolnshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLG1'], 'Herefordshire, Worcestershire and Warwickshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLG2'], 'Shropshire and Staffordshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLG3'], 'West Midlands')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLH1'], 'East Anglia')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLH2'], 'Bedfordshire and Hertfordshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLH3'], 'Essex')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI3'], 'Inner London - West')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI4'], 'Inner London - East')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI5'], 'Outer London - East and North East')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI6'], 'Outer London - South')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI7'], 'Outer London - West and North West')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLJ1'], 'Berkshire, Buckinghamshire and Oxfordshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLJ2'], 'Surrey, East and West Sussex')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLJ3'], 'Hampshire and Isle of Wight')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLJ4'], 'Kent')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLK1'], 'Gloucestershire, Wiltshire and Bristol/Bath area')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLK2'], 'Dorset and Somerset')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLK3'], 'Cornwall and Isles of Scilly')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLK4'], 'Devon')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLL1'], 'West Wales and The Valleys')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLL2'], 'East Wales')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM5'], 'North Eastern Scotland')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM6'], 'Highlands and Islands')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM7'], 'Eastern Scotland')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM8'], 'West Central Scotland')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM9'], 'Southern Scotland')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLN0'], 'Northern Ireland')\n",
    "\n",
    "\n",
    "gdhi_population_df.head()\n",
    "\n",
    "# COMBINED GDHI AND POPULATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scotland', 'Northern Ireland', 'London',\n",
       "       'Yorkshire and The Humber', 'South West', 'East of England',\n",
       "       'South East', 'West Midlands', 'North West', 'Wales', 'North East',\n",
       "       'East Midlands'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show unique values in ITL level 1\n",
    "gdhi_population_df['ITL level 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Units</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>ONS Sort</th>\n",
       "      <th>ONS Code</th>\n",
       "      <th>ONS Geography</th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>1.0</td>\n",
       "      <td>K02000001</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>110.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>2.0</td>\n",
       "      <td>K03000001</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>106.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>3.0</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>90.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>4.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Units           BodyType    Fuel Keepership ONS Sort   ONS Code  \\\n",
       "0  Thousands  Buses and coaches  Diesel    Company      1.0  K02000001   \n",
       "1  Thousands  Buses and coaches  Diesel    Company      2.0  K03000001   \n",
       "2  Thousands  Buses and coaches  Diesel    Company      3.0  E92000001   \n",
       "3  Thousands  Buses and coaches  Diesel    Company      4.0  E12000001   \n",
       "4  Thousands  Buses and coaches  Diesel    Company      5.0  E06000047   \n",
       "\n",
       "      ONS Geography     Year Number of vehicles  \n",
       "0    United Kingdom  2022 Q4            110.929  \n",
       "1     Great Britain  2022 Q4            106.768  \n",
       "2           England  2022 Q4              90.01  \n",
       "3        North East  2022 Q4              4.103  \n",
       "4     County Durham  2022 Q4              0.608  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/veh0105.ods\"\n",
    "\n",
    "# load a sheet based on its index (1 based)\n",
    "sheet_idx = 4\n",
    "vehicle_fuel_df = read_ods(path, sheet_idx)\n",
    "\n",
    "# make third row the header\n",
    "vehicle_fuel_df.columns = vehicle_fuel_df.iloc[3]\n",
    "# drop first 4 rows\n",
    "vehicle_fuel_df = vehicle_fuel_df.iloc[4:]\n",
    "vehicle_fuel_df.head()\n",
    "\n",
    "# renumber index\n",
    "vehicle_fuel_df = vehicle_fuel_df.reset_index(drop=True)\n",
    "\n",
    "# melt the dataframe\n",
    "vehicle_fuel_df = pd.melt(vehicle_fuel_df, id_vars=['Units', 'BodyType', 'Fuel [note 2]', 'Keepership [note 3]', 'ONS Sort [note 6]', \n",
    "                                                    'ONS Code [note 6]', 'ONS Geography [note 6]'], var_name='Year', \n",
    "                                                    value_vars = ['2022 Q4', '2022 Q3', '2022 Q2', '2022 Q1', '2021 Q4', '2021 Q3', \n",
    "                                                                  '2021 Q2', '2021 Q1', '2020 Q4', '2020 Q3', '2020 Q2', '2020 Q1', \n",
    "                                                                  '2019 Q4', '2019 Q3', '2019 Q2', '2019 Q1', '2018 Q4', '2018 Q3', \n",
    "                                                                  '2018 Q2', '2018 Q1', '2017 Q4', '2017 Q3', '2017 Q2', '2017 Q1', \n",
    "                                                                  '2016 Q4', '2016 Q3', '2016 Q2', '2016 Q1', '2015 Q4', '2015 Q3', \n",
    "                                                                  '2015 Q2', '2015 Q1', '2014 Q4', '2014 Q3', '2014 Q2', '2014 Q1', \n",
    "                                                                  '2013 Q4', '2013 Q3', '2013 Q2', '2013 Q1', '2012 Q4', '2012 Q3', \n",
    "                                                                  '2012 Q2', '2012 Q1', '2011 Q4', '2011 Q3', '2011 Q2', '2011 Q1', \n",
    "                                                                  '2010 Q4', '2010 Q3', '2010 Q2', '2010 Q1', '2009 Q4'])\n",
    "# rename the column value to number of vehicles\n",
    "vehicle_fuel_df = vehicle_fuel_df.rename(columns={'value': 'Number of vehicles'})\n",
    "# rename the columns to remove the square brackets\n",
    "vehicle_fuel_df = vehicle_fuel_df.rename(columns={'Fuel [note 2]': 'Fuel', 'Keepership [note 3]': 'Keepership',\n",
    "                                                    'ONS Sort [note 6]': 'ONS Sort', 'ONS Code [note 6]': 'ONS Code',\n",
    "                                                    'ONS Geography [note 6]': 'ONS Geography'})\n",
    "vehicle_fuel_df.head()\n",
    "\n",
    "# COMBINED WITH ELECTRIC VEHICLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Units</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>ONS Sort</th>\n",
       "      <th>ONS Code</th>\n",
       "      <th>ONS Geography</th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>1.0</td>\n",
       "      <td>K02000001</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>1808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>2.0</td>\n",
       "      <td>K03000001</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>1702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>3.0</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>1343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>[c]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Units           BodyType              Fuel Keepership ONS Sort   ONS Code  \\\n",
       "0  Number  Buses and coaches  Battery electric    Company      1.0  K02000001   \n",
       "1  Number  Buses and coaches  Battery electric    Company      2.0  K03000001   \n",
       "2  Number  Buses and coaches  Battery electric    Company      3.0  E92000001   \n",
       "3  Number  Buses and coaches  Battery electric    Company      4.0  E12000001   \n",
       "4  Number  Buses and coaches  Battery electric    Company      5.0  E06000047   \n",
       "\n",
       "      ONS Geography     Year Number of vehicles  \n",
       "0    United Kingdom  2022 Q3             1808.0  \n",
       "1     Great Britain  2022 Q3             1702.0  \n",
       "2           England  2022 Q3             1343.0  \n",
       "3        North East  2022 Q3               21.0  \n",
       "4     County Durham  2022 Q3                [c]  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/veh0142.ods\"\n",
    "\n",
    "# load a sheet based on its index (1 based)\n",
    "sheet_idx = 4\n",
    "vehicle_electricity_df = read_ods(path, sheet_idx)\n",
    "\n",
    "# make third row the header\n",
    "vehicle_electricity_df.columns = vehicle_electricity_df.iloc[3]\n",
    "# drop first 4 rows\n",
    "vehicle_electricity_df = vehicle_electricity_df.iloc[4:]\n",
    "vehicle_electricity_df.head()\n",
    "\n",
    "# renumber index\n",
    "vehicle_electricity_df = vehicle_electricity_df.reset_index(drop=True)\n",
    "# melt the dataframe\n",
    "vehicle_electricity_df = pd.melt(vehicle_electricity_df, id_vars=['Units', 'BodyType', 'Fuel', 'Keepership [note 3]', \n",
    "                                                                  'ONS Sort [note 6]', 'ONS Code [note 6]', 'ONS Geography [note 6]'], \n",
    "                                                                  var_name='Year', \n",
    "                                                                  value_vars = ['2022 Q3', '2022 Q2', '2022 Q1', '2021 Q4', '2021 Q3', \n",
    "                                                                                '2021 Q2', '2021 Q1', '2020 Q4', '2020 Q3', '2020 Q2',\n",
    "                                                                                '2020 Q1', '2019 Q4', '2019 Q3', '2019 Q2', '2019 Q1', \n",
    "                                                                                '2018 Q4', '2018 Q3', '2018 Q2', '2018 Q1', '2017 Q4', \n",
    "                                                                                '2017 Q3', '2017 Q2', '2017 Q1', '2016 Q4', '2016 Q3', \n",
    "                                                                                '2016 Q2', '2016 Q1', '2015 Q4', '2015 Q3', '2015 Q2', \n",
    "                                                                                '2015 Q1', '2014 Q4', '2014 Q3', '2014 Q2', '2014 Q1', \n",
    "                                                                                '2013 Q4', '2013 Q3', '2013 Q2', '2013 Q1', '2012 Q4', \n",
    "                                                                                '2012 Q3', '2012 Q2', '2012 Q1', '2011 Q4', '2011 Q3', \n",
    "                                                                                '2011 Q2', '2011 Q1', '2010 Q4', '2010 Q3', '2010 Q2', \n",
    "                                                                                '2010 Q1', '2009 Q4'])\n",
    "# rename the column value to \"Number of vehicles\"\n",
    "vehicle_electricity_df = vehicle_electricity_df.rename(columns={'value': 'Number of vehicles'})\n",
    "# rename the columns to remove the square brackets\n",
    "vehicle_electricity_df = vehicle_electricity_df.rename(columns={'Keepership [note 3]': 'Keepership',\n",
    "                                                                'ONS Sort [note 6]': 'ONS Sort',\n",
    "                                                                'ONS Code [note 6]': 'ONS Code',\n",
    "                                                                'ONS Geography [note 6]': 'ONS Geography'})\n",
    "vehicle_electricity_df.head()\n",
    "\n",
    "# COMBINED WITH OTHER VEHICLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Units</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>ONS Sort</th>\n",
       "      <th>ONS Code</th>\n",
       "      <th>ONS Geography</th>\n",
       "      <th>Number of vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>1.0</td>\n",
       "      <td>K02000001</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>2.0</td>\n",
       "      <td>K03000001</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>3.0</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299769</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>462.0</td>\n",
       "      <td>N09000010</td>\n",
       "      <td>Newry, Mourne and Down</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299770</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>463.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Local Authority unknown within Northern Ire...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299771</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>464.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Vehicle under disposal, previously GB</td>\n",
       "      <td>2914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299772</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>465.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Vehicle under disposal, previously NI</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299773</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>466.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Region or county unknown</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1299774 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year      Units           BodyType              Fuel Keepership  \\\n",
       "0        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "1        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "2        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "3        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "4        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "...       ...        ...                ...               ...        ...   \n",
       "1299769  2022  Thousands              Total             Total      Total   \n",
       "1299770  2022  Thousands              Total             Total      Total   \n",
       "1299771  2022  Thousands              Total             Total      Total   \n",
       "1299772  2022  Thousands              Total             Total      Total   \n",
       "1299773  2022  Thousands              Total             Total      Total   \n",
       "\n",
       "         ONS Sort   ONS Code  \\\n",
       "0             1.0  K02000001   \n",
       "1             2.0  K03000001   \n",
       "2             3.0  E92000001   \n",
       "3             4.0  E12000001   \n",
       "4             5.0  E06000047   \n",
       "...           ...        ...   \n",
       "1299769     462.0  N09000010   \n",
       "1299770     463.0        [z]   \n",
       "1299771     464.0        [z]   \n",
       "1299772     465.0        [z]   \n",
       "1299773     466.0        [z]   \n",
       "\n",
       "                                             ONS Geography  Number of vehicles  \n",
       "0                                           United Kingdom                   0  \n",
       "1                                            Great Britain                  38  \n",
       "2                                                  England                  36  \n",
       "3                                               North East                   0  \n",
       "4                                            County Durham                   0  \n",
       "...                                                    ...                 ...  \n",
       "1299769                             Newry, Mourne and Down                 494  \n",
       "1299770     Local Authority unknown within Northern Ire...                  14  \n",
       "1299771              Vehicle under disposal, previously GB                2914  \n",
       "1299772              Vehicle under disposal, previously NI                  56  \n",
       "1299773                           Region or county unknown                  14  \n",
       "\n",
       "[1299774 rows x 9 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two vehicle dataframes\n",
    "vehicle_df = pd.concat([vehicle_fuel_df, vehicle_electricity_df])\n",
    "# remove last 3 characters from year column\n",
    "vehicle_df['Year'] = vehicle_df['Year'].str[:-3]\n",
    "# convert year column to integer\n",
    "vehicle_df['Year'] = vehicle_df['Year'].astype(int)\n",
    "# replace any text in number of vehicles column with 0\n",
    "vehicle_df['Number of vehicles'] = vehicle_df['Number of vehicles'].replace('[x]', 0)\n",
    "vehicle_df['Number of vehicles'] = vehicle_df['Number of vehicles'].replace('[c]', 0)\n",
    "# if number of vehicles is NaN or not a number, set to 0\n",
    "vehicle_df['Number of vehicles'] = vehicle_df['Number of vehicles'].fillna(0)\n",
    "# convert number of vehicles column to integer\n",
    "vehicle_df['Number of vehicles'] = vehicle_df['Number of vehicles'].astype(int)\n",
    "# aggregate the number of vehicles by year\n",
    "vehicle_df = vehicle_df.groupby(['Year', 'Units', 'BodyType', 'Fuel', 'Keepership', 'ONS Sort', 'ONS Code', 'ONS Geography']).agg({'Number of vehicles': 'sum'}).reset_index()\n",
    "vehicle_df\n",
    "\n",
    "# COMBINED DATAFRAME (VEHICLE AND EV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Make</th>\n",
       "      <th>GenModel</th>\n",
       "      <th>Model</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Number of vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>AIXAM</td>\n",
       "      <td>AIXAM MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>ALBION</td>\n",
       "      <td>ALBION MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>ALBION</td>\n",
       "      <td>ALBION MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>ALEXANDER DENNIS</td>\n",
       "      <td>ALEXANDER DENNIS MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>ALEXANDER DENNIS</td>\n",
       "      <td>ALEXANDER DENNIS MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year           BodyType              Make  \\\n",
       "0  1994Q4  Buses and coaches             AIXAM   \n",
       "1  1994Q4  Buses and coaches            ALBION   \n",
       "2  1994Q4  Buses and coaches            ALBION   \n",
       "3  1994Q4  Buses and coaches  ALEXANDER DENNIS   \n",
       "4  1994Q4  Buses and coaches  ALEXANDER DENNIS   \n",
       "\n",
       "                         GenModel    Model              Fuel  \\\n",
       "0             AIXAM MODEL MISSING  MISSING            Diesel   \n",
       "1            ALBION MODEL MISSING  MISSING            Diesel   \n",
       "2            ALBION MODEL MISSING  MISSING            Petrol   \n",
       "3  ALEXANDER DENNIS MODEL MISSING  MISSING  Battery electric   \n",
       "4  ALEXANDER DENNIS MODEL MISSING  MISSING            Diesel   \n",
       "\n",
       "   Number of vehicles  \n",
       "0                   0  \n",
       "1                  26  \n",
       "2                   7  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a sheet with car models bought and quarter they were purchased\n",
    "car_models_df = pd.read_csv('data/vehicle-licensing-statistics-2022-data-files/df_VEH0120_GB.csv')\n",
    "# melt the dataframe\n",
    "car_models_df = pd.melt(car_models_df, id_vars=['BodyType', 'Make', 'GenModel', 'Model', 'Fuel'], var_name='Year', \n",
    "                        value_vars = ['2022Q3', '2022Q2', '2022Q1', '2021Q4', '2021Q3', '2021Q2', '2021Q1', '2020Q4', '2020Q3',\n",
    "                                        '2020Q2', '2020Q1', '2019Q4', '2019Q3', '2019Q2', '2019Q1', '2018Q4', '2018Q3', '2018Q2',\n",
    "                                        '2018Q1', '2017Q4', '2017Q3', '2017Q2', '2017Q1', '2016Q4', '2016Q3', '2016Q2', '2016Q1',\n",
    "                                        '2015Q4', '2015Q3', '2015Q2', '2015Q1', '2014Q4', '2014Q3', '2014Q2', '2014Q1', '2013Q4',\n",
    "                                        '2013Q3', '2013Q2', '2013Q1', '2012Q4', '2012Q3', '2012Q2', '2012Q1', '2011Q4', '2011Q3',\n",
    "                                        '2011Q2', '2011Q1', '2010Q4', '2010Q3', '2010Q2', '2010Q1', '2009Q4', '2009Q3', '2009Q2',\n",
    "                                        '2009Q1', '2008Q4', '2008Q3', '2007Q4', '2006Q4', '2005Q4', '2004Q4', '2003Q4', '2002Q4', \n",
    "                                        '2001Q4', '2000Q4', '1999Q4', '1998Q4', '1997Q4', '1996Q4', '1995Q4', '1994Q4'])\n",
    "# aggregate the number of cars bought by year, make, genmodel, model, fuel and year\n",
    "# fill the NaN values with 0\n",
    "car_models_df['value'] = car_models_df['value'].fillna(0)\n",
    "car_models_df = car_models_df.groupby(['Year', 'BodyType', 'Make', 'GenModel', 'Model', 'Fuel']).agg({'value': 'sum'}).reset_index()\n",
    "# rename the column value to \"Number of vehicles\"\n",
    "car_models_df = car_models_df.rename(columns={'value': 'Number of vehicles'})\n",
    "car_models_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ULSP:  Pump price (p/litre)</th>\n",
       "      <th>ULSD: Pump price (p/litre)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>75.330148</td>\n",
       "      <td>77.139578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>80.254930</td>\n",
       "      <td>81.894003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>86.796860</td>\n",
       "      <td>90.820266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>91.395871</td>\n",
       "      <td>95.179094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>94.384374</td>\n",
       "      <td>96.984666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>107.001178</td>\n",
       "      <td>117.556702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>99.593804</td>\n",
       "      <td>104.146614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011</td>\n",
       "      <td>133.412774</td>\n",
       "      <td>138.805382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>135.761462</td>\n",
       "      <td>142.171851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>134.312143</td>\n",
       "      <td>140.624926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>127.418609</td>\n",
       "      <td>133.474037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015</td>\n",
       "      <td>111.033772</td>\n",
       "      <td>114.996870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>108.949773</td>\n",
       "      <td>110.420045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>117.512806</td>\n",
       "      <td>120.206574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>125.001226</td>\n",
       "      <td>129.945303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>124.816777</td>\n",
       "      <td>131.664396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021</td>\n",
       "      <td>131.396517</td>\n",
       "      <td>135.037887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>164.641685</td>\n",
       "      <td>177.778373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>146.352737</td>\n",
       "      <td>162.737857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   ULSP:  Pump price (p/litre)  ULSD: Pump price (p/litre)\n",
       "0   2003                     75.330148                   77.139578\n",
       "1   2004                     80.254930                   81.894003\n",
       "2   2005                     86.796860                   90.820266\n",
       "3   2006                     91.395871                   95.179094\n",
       "4   2007                     94.384374                   96.984666\n",
       "5   2008                    107.001178                  117.556702\n",
       "6   2009                     99.593804                  104.146614\n",
       "7   2010                    116.904146                  119.234615\n",
       "8   2011                    133.412774                  138.805382\n",
       "9   2012                    135.761462                  142.171851\n",
       "10  2013                    134.312143                  140.624926\n",
       "11  2014                    127.418609                  133.474037\n",
       "12  2015                    111.033772                  114.996870\n",
       "13  2016                    108.949773                  110.420045\n",
       "14  2017                    117.512806                  120.206574\n",
       "15  2018                    125.001226                  129.945303\n",
       "16  2019                    124.816777                  131.664396\n",
       "17  2020                    114.092268                  119.455858\n",
       "18  2021                    131.396517                  135.037887\n",
       "19  2022                    164.641685                  177.778373\n",
       "20  2023                    146.352737                  162.737857"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data with fuel prices\n",
    "fuel_prices_df = pd.read_excel('data/Weekly_Fuel_Prices_120623.xlsx', sheet_name='All years', skiprows=7)\n",
    "# keep columns 1, 2, 7\n",
    "fuel_prices_df = fuel_prices_df.iloc[:, [0, 1, 6]]\n",
    "# aggregate by quarter and get mean\n",
    "fuel_prices_df = fuel_prices_df.groupby(fuel_prices_df['Date'].dt.to_period(\"Q\")).mean()\n",
    "# aggregate by year and get mean\n",
    "fuel_prices_df = fuel_prices_df.groupby(fuel_prices_df.index.year).mean()\n",
    "# reset index\n",
    "fuel_prices_df = fuel_prices_df.reset_index()\n",
    "# rename column Date to Year\n",
    "fuel_prices_df = fuel_prices_df.rename(columns={'Date': 'Year'})\n",
    "fuel_prices_df\n",
    "\n",
    "# COMBINED WITH ELECTRICITY PRICES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['East Midlands', 'East of England', 'London', 'North East',\n",
       "       'North West', 'Northern Ireland', 'Scotland', 'South East',\n",
       "       'South West', 'Wales', 'West Midlands', 'Yorkshire and The Humber'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine electric and fuel prices dataframes by year and left join fuel to electric\n",
    "fuel_electric_prices_df = pd.merge(electricity_df, fuel_prices_df, on='Year', how='left')\n",
    "fuel_electric_prices_df\n",
    "\n",
    "# combine North Scotland and South Scotland into Scotland and rename\n",
    "fuel_electric_prices_df.loc[fuel_electric_prices_df['PES area'].str.contains('North Scotland', case=False, na=False), 'PES area'] = 'Scotland'\n",
    "fuel_electric_prices_df.loc[fuel_electric_prices_df['PES area'].str.contains('South Scotland', case=False, na=False), 'PES area'] = 'Scotland'\n",
    "# combine Merseyside & North Wales and South Wales into Wales and rename\n",
    "fuel_electric_prices_df.loc[fuel_electric_prices_df['PES area'].str.contains('Merseyside & North Wales', case=False, na=False), 'PES area'] = 'Wales'\n",
    "fuel_electric_prices_df.loc[fuel_electric_prices_df['PES area'].str.contains('South Wales', case=False, na=False), 'PES area'] = 'Wales'\n",
    "# replace Eastern with East of England\n",
    "fuel_electric_prices_df['PES area'] = fuel_electric_prices_df['PES area'].replace('Eastern', 'East of England')\n",
    "# replace Yorkshire with Yorkshire and The Humber\n",
    "fuel_electric_prices_df['PES area'] = fuel_electric_prices_df['PES area'].replace('Yorkshire', 'Yorkshire and The Humber')\n",
    "# drop rows with PES area as \"United Kingdom\" and \"Southern\"\n",
    "fuel_electric_prices_df = fuel_electric_prices_df[fuel_electric_prices_df['PES area'] != 'United Kingdom']\n",
    "fuel_electric_prices_df = fuel_electric_prices_df[fuel_electric_prices_df['PES area'] != 'Southern']\n",
    "\n",
    "# aggregate all the data by year and PES area and get the mean\n",
    "fuel_electric_prices_df = fuel_electric_prices_df.groupby(['Year', 'PES area']).mean().reset_index()\n",
    "\n",
    "# show unique values in PES Area column\n",
    "fuel_electric_prices_df['PES area'].unique()\n",
    "# COMBINED DATAFRAME (FUEL + ELECTRICITY PRICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>ITL level</th>\n",
       "      <th>ITL code</th>\n",
       "      <th>Year</th>\n",
       "      <th>gdhi</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "      <th>ITL level 1</th>\n",
       "      <th>ITL level 2</th>\n",
       "      <th>PES area</th>\n",
       "      <th>Average variable unit price (Â£/kWh)</th>\n",
       "      <th>ULSP:  Pump price (p/litre)</th>\n",
       "      <th>ULSD: Pump price (p/litre)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2762</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2741</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2596</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2501</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354349</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>768</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354350</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>621</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354351</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>586</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354352</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>451</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354353</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2140</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354354 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ITL level 3 ITL level ITL code  Year     gdhi  \\\n",
       "0       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "1       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "2       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "3       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "4       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "...                                 ...       ...      ...   ...      ...   \n",
       "354349            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "354350            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "354351            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "354352            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "354353            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "\n",
       "        sex  age  population    ITL level 1  \\\n",
       "0         1    0        2801       Scotland   \n",
       "1         1    1        2762       Scotland   \n",
       "2         1    2        2741       Scotland   \n",
       "3         1    3        2596       Scotland   \n",
       "4         1    4        2501       Scotland   \n",
       "...     ...  ...         ...            ...   \n",
       "354349    2   86         768  East Midlands   \n",
       "354350    2   87         621  East Midlands   \n",
       "354351    2   88         586  East Midlands   \n",
       "354352    2   89         451  East Midlands   \n",
       "354353    2   90        2140  East Midlands   \n",
       "\n",
       "                                         ITL level 2       PES area  \\\n",
       "0                             North Eastern Scotland       Scotland   \n",
       "1                             North Eastern Scotland       Scotland   \n",
       "2                             North Eastern Scotland       Scotland   \n",
       "3                             North Eastern Scotland       Scotland   \n",
       "4                             North Eastern Scotland       Scotland   \n",
       "...                                              ...            ...   \n",
       "354349  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "354350  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "354351  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "354352  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "354353  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "\n",
       "        Average variable unit price (Â£/kWh)   ULSP:  Pump price (p/litre)  \\\n",
       "0                                  0.117261                    116.904146   \n",
       "1                                  0.117261                    116.904146   \n",
       "2                                  0.117261                    116.904146   \n",
       "3                                  0.117261                    116.904146   \n",
       "4                                  0.117261                    116.904146   \n",
       "...                                     ...                           ...   \n",
       "354349                             0.166876                    114.092268   \n",
       "354350                             0.166876                    114.092268   \n",
       "354351                             0.166876                    114.092268   \n",
       "354352                             0.166876                    114.092268   \n",
       "354353                             0.166876                    114.092268   \n",
       "\n",
       "        ULSD: Pump price (p/litre)  \n",
       "0                       119.234615  \n",
       "1                       119.234615  \n",
       "2                       119.234615  \n",
       "3                       119.234615  \n",
       "4                       119.234615  \n",
       "...                            ...  \n",
       "354349                  119.455858  \n",
       "354350                  119.455858  \n",
       "354351                  119.455858  \n",
       "354352                  119.455858  \n",
       "354353                  119.455858  \n",
       "\n",
       "[354354 rows x 14 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set Year to integer\n",
    "fuel_electric_prices_df['Year'] = fuel_electric_prices_df['Year'].astype(int)\n",
    "gdhi_population_df['Year'] = gdhi_population_df['Year'].astype(int)\n",
    "# add fuel_electric_prices_df to gdhi_population_df\n",
    "gdhi_population_fuel_electric_df = gdhi_population_df.merge(fuel_electric_prices_df, how='inner', left_on=['Year', 'ITL level 1'], right_on=['Year', 'PES area'])\n",
    "gdhi_population_fuel_electric_df\n",
    "# drop PES area column\n",
    "\n",
    "# COMBINED DATAFRAME (GDHI + POPULATION + FUEL + ELECTRICITY PRICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].str.strip()\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Barking and Dagenham', 'Havering'], 'Barking & Dagenham and Havering')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Angus', 'Dundee City'], 'Angus and Dundee City')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hartlepool'], 'Hartlepool and Stockton-on-Tees')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Aberdeen City'], 'Aberdeen City and Aberdeenshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Aberdeenshire'], 'Aberdeen City and Aberdeenshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Worthing', 'Adur', 'Arun', 'Chichester', 'Horsham', 'Mid Sussex'], 'West Sussex (South West)')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Allerdale', 'Barrow-in-Furness', 'Carlisle', 'Copeland'], 'West Cumbria')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Eden', 'South Lakeland'], 'East Cumbria')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Argyll and Bute'], 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Ashfield', 'Bassetlaw', 'Bolsover', 'Gedling'], 'North Nottinghamshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Babergh', 'East Suffolk', 'Ipswich', 'Mid Suffolk', 'West Suffolk'], 'Suffolk')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Barnsley', 'Doncaster', 'Rotherham'], 'Barnsley, Doncaster and Rotherham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Basildon'], 'Thurrock')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Basingstoke and Deane', 'Hart', 'Rushmoor'], 'North Hampshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bath and North East Somerset', 'North Somerset', 'South Gloucestershire'], 'Bath and North East Somerset, North Somerset and South Gloucestershire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bexley', 'Greenwich'], 'Bexley and Greenwich')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Blaby', 'Charnwood', 'Harborough', 'Hinckley and Bosworth', 'Melton', 'North West Leicestershire', 'Oadby and Wigston', 'Rutland'], 'Leicestershire CC and Rutland')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Blaenau Gwent', 'Torfaen'], 'Gwent Valleys')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bolton', 'Bury'], 'Greater Manchester North West')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Boston', 'North Kesteven', 'West Lindsey', 'South Kesteven', 'South Holland'], 'Lincolnshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bracknell Forest', 'Reading', 'Slough', 'West Berkshire', 'Windsor and Maidenhead', 'Wokingham'], 'Berkshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Braintree', 'Brentwood', 'Castle Point', 'Colchester', 'Chelmsford', 'Rochford'], 'Essex Haven Gateway')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Breckland', 'Broadland', 'Great Yarmouth', 'South Norfolk'], 'Breckland and South Norfolk')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bridgend', 'Merthyr Tydfil', 'Neath Port Talbot', 'Rhondda Cynon Taf'], 'Bridgend and Neath Port Talbot')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bromsgrove', 'Malvern Hills', 'Redditch', 'Worcester', 'Wychavon'], 'Worcestershire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Watford', 'Stevenage', 'St Albans', 'Three Rivers', 'Welwyn Hatfield', 'North Hertfordshire', 'Broxbourne', 'East Hertfordshire', 'Dacorum', 'Hertsmere'], 'Hertfordshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Broxtowe', 'Amber Valley', 'Derbyshire Dales', 'Erewash', 'South Derbyshire'], 'South and West Derbyshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Buckinghamshire'], 'Buckinghamshire CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Burnley', 'Hyndburn', 'Pendle', 'Ribble Valley', 'Rossendale'], 'East Lancashire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Caerphilly', 'Cardiff', 'Vale of Glamorgan'], 'Cardiff and Vale of Glamorgan')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cambridge', 'East Cambridgeshire', 'Fenland', 'Huntingdonshire', 'South Cambridgeshire'], 'Cambridgeshire CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Newcastle-under-Lyme', 'Cannock Chase', 'East Staffordshire', 'Lichfield', 'South Staffordshire', 'Tamworth', 'Staffordshire Moorlands', 'Stafford'], 'Staffordshire CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Carmarthenshire', 'Pembrokeshire'], 'South West Wales')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cherwell', 'Oxford', 'South Oxfordshire', 'Vale of White Horse', 'West Oxfordshire'], 'Oxfordshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Chesterfield', 'North East Derbyshire', 'High Peak'], 'East Derbyshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Chorley', 'Fylde', 'South Ribble', 'West Lancashire'], 'Chorley and West Lancashire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['City of London', 'Camden'], 'Camden and City of London')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Clackmannanshire', 'Fife'], 'Clackmannanshire and Fife')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Conwy', 'Denbighshire'], 'Conwy and Denbighshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cornwall', 'Isles of Scilly'], 'Cornwall and Isles of Scilly')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Ayrshire', 'North Ayrshire'], 'East Ayrshire and North Ayrshire mainland')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Devon', 'Exeter', 'Mid Devon', 'North Devon', 'South Hams', 'Teignbridge', 'Torridge', 'West Devon'], 'Devon CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Dunbartonshire', 'West dunbartonshire', 'West Dunbartonshire'], 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Hampshire', 'Eastleigh', 'New Forest'], 'Central Hampshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Lothian', 'Midlothian'], 'East Lothian and Midlothian')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Renfrewshire', 'Inverclyde', 'Renfrewshire'], 'Inverclyde, East Renfrewshire and Renfrewshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Eastbourne', 'East Sussex'])\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Elmbridge', 'Epsom and Ewell', 'Guildford', 'Runnymede', 'Spelthorne', 'Woking', 'Waverley', 'Surrey Heath'], 'West Surrey')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Fareham', 'Gosport', 'Havant'], 'South Hampshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Flintshire', 'Wrexham'], 'Flintshire and Wrexham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Folkestone and Hythe', 'Dover', 'Ashford', 'Canterbury'], 'East Kent')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Gloucester', 'Forest of Dean', 'Cotswold', 'Cheltenham', 'Stroud', 'Tewkesbury'], 'Gloucestershire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Newcastle upon Tyne', 'Gateshead', 'North Tyneside', 'South Tyneside'], 'Tyneside')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hackney', 'Newham'], 'Hackney and Newham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hammersmith and Fulham', 'Kensington and Chelsea'], 'Kensington & Chelsea and Hammersmith & Fulham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Harlow', 'Epping Forest'], 'Essex Thames Gateway')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Harrow', 'Hillingdon'], 'Harrow and Hillingdon')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:129: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Haringey', 'Islington'], 'Haringey and Islington')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hastings', 'Lewes', 'Rother', 'Wealden'], 'East Sussex CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hounslow', 'Richmond upon Thames'], 'Hounslow and Richmond upon Thames')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace([\"King's Lynn and West Norfolk\", 'North Norfolk'], 'North and West Norfolk')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Kingston upon Thames', 'Merton', 'Sutton'], 'Merton, Kingston upon Thames and Sutton')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Kirklees', 'Calderdale'], 'Calderdale and Kirklees')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Knowsley', 'St. Helens'], 'East Merseyside')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lancaster', 'Wyre', 'Wyre Forest'], 'Lancaster and Wyre')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lewisham', 'Southwark'], 'Lewisham and Southwark')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lincoln', 'North East Lincolnshire', 'North Lincolnshire', 'East Lindsey'], 'North and North East Lincolnshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace('Maidstone', 'Medway')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mansfield', 'Newark and Sherwood'], 'Nottingham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mendip', 'South Somerset', 'Somerset West and Taunton', 'Sedgemoor'], 'Somerset')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mole Valley', 'Reigate and Banstead', 'Tandridge'], 'East Surrey')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Monmouthshire', 'Newport'], 'Monmouthshire and Newport')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Moray'], 'Inverness and Nairn and Moray, Badenoch and Strathspey')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Warwick', 'North Warwickshire', 'Nuneaton and Bedworth', 'Rugby', 'Stratford-on-Avon'], 'Warwickshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Oldham', 'Rochdale', 'Salford'], 'Greater Manchester North East')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Perth and Kinross', 'Stirling'], 'Perth and Kinross and Stirling')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Redcar and Cleveland'], 'South Teesside')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Richmondshire', 'Middlesbrough', 'Hambleton', 'Harrogate', 'Ryedale', 'Scarborough', 'Selby', 'Craven'], 'North Yorkshire CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Redbridge', 'Waltham Forest'], 'Redbridge and Waltham Forest')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Stockport', 'Tameside', 'Wigan'], 'Greater Manchester South East')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Trafford'], 'Greater Manchester South West')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Stockton-on-Tees', 'Hartlepool and Stockton-on-Tees'])\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Tendring', 'Uttlesford'], 'West Essex')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Test Valley'], 'Central Hampshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:195: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Tonbridge and Malling', 'Tunbridge Wells', 'Sevenoaks'], 'West Kent')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_33343/1121752590.py:197: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Thanet', 'Swale', 'Gravesham', 'Dartford'], 'Kent Thames Gateway')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# remove all rows with ONS Geography 'Vehicle under disposal, previously GB','Vehicle under disposal, previously NI','Region or county unknown'\n",
    "vehicle_removed_df = vehicle_df[~vehicle_df['ONS Geography'].isin(['Vehicle under disposal, previously NI','Region or county unknown'])]\n",
    "# strip whitespace from ONS Geography column from front and back\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].str.strip()\n",
    "\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Barking and Dagenham', 'Havering'], 'Barking & Dagenham and Havering')\n",
    "# change \"Angus\" to \"Angus and Dundee City\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Angus', 'Dundee City'], 'Angus and Dundee City')\n",
    "# change Maldon to Heart of Essex\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Maldon', case=False, na=False), 'ONS Geography'] = 'Heart of Essex'\n",
    "# change the values in laname21 column to match the values in gdhi data \"Region name\" columns\n",
    "# change \"Hartlepool\" to \"Durham CC\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hartlepool'], 'Hartlepool and Stockton-on-Tees')\n",
    "# change \"Aberdeen City\" to \"Aberdeen City and Aberdeenshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Aberdeen City'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Aberdeenshire\" to \"Aberdeen City and Aberdeenshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Aberdeenshire'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Adur\" to \"West Sussex (South West)\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Worthing', 'Adur', 'Arun', 'Chichester', 'Horsham', 'Mid Sussex'], 'West Sussex (South West)')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Allerdale', 'Barrow-in-Furness', 'Carlisle', 'Copeland'], 'West Cumbria')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Eden', 'South Lakeland'], 'East Cumbria')\n",
    "# change \"Argyll and Bute\" to \"Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Argyll and Bute'], 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute')\n",
    "# change Ashfield to \"North Nottinghamshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Ashfield', 'Bassetlaw', 'Bolsover', 'Gedling'], 'North Nottinghamshire')\n",
    "# change Babergh to \"Suffolk\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Babergh', 'East Suffolk', 'Ipswich', 'Mid Suffolk', 'West Suffolk'], 'Suffolk')\n",
    "# change Barnsley to \"Barnsley, Doncaster and Rotherham\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Barnsley', 'Doncaster', 'Rotherham'], 'Barnsley, Doncaster and Rotherham')\n",
    "# change Basildon to \"Thurrock\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Basildon'], 'Thurrock')\n",
    "# change Basingstoke and Deane to \"North Hampshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Basingstoke and Deane', 'Hart', 'Rushmoor'], 'North Hampshire')\n",
    "# change Bath and North East Somerset to \"Bath and North East Somerset, North Somerset and South Gloucestershire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bath and North East Somerset', 'North Somerset', 'South Gloucestershire'], 'Bath and North East Somerset, North Somerset and South Gloucestershire')\n",
    "# change Bexley to \"Bexley and Greenwich\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bexley', 'Greenwich'], 'Bexley and Greenwich')\n",
    "# change Blaby to \"Leicestershire CC and Rutland\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Blaby', 'Charnwood', 'Harborough', 'Hinckley and Bosworth', 'Melton', 'North West Leicestershire', 'Oadby and Wigston', 'Rutland'], 'Leicestershire CC and Rutland')\n",
    "# change Blaenau Gwent to \"Gwent Valleys\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Blaenau Gwent', 'Torfaen'], 'Gwent Valleys')\n",
    "# change Bolton to \"Greater Manchester North West\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bolton', 'Bury'], 'Greater Manchester North West')\n",
    "# change Boston to \"Lincolnshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Boston', 'North Kesteven', 'West Lindsey', 'South Kesteven', 'South Holland'], 'Lincolnshire')\n",
    "# change Bracknell Forest to \"Berkshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bracknell Forest', 'Reading', 'Slough', 'West Berkshire', 'Windsor and Maidenhead', 'Wokingham'], 'Berkshire')\n",
    "# change Braintree to \"Essex Haven Gateway\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Braintree', 'Brentwood', 'Castle Point', 'Colchester', 'Chelmsford', 'Rochford'], 'Essex Haven Gateway')\n",
    "# change Breckland to \"Breckland and South Norfolk\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Breckland', 'Broadland', 'Great Yarmouth', 'South Norfolk'], 'Breckland and South Norfolk')\n",
    "# change Bridgend to \"Bridgend and Neath Port Talbot\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bridgend', 'Merthyr Tydfil', 'Neath Port Talbot', 'Rhondda Cynon Taf'], 'Bridgend and Neath Port Talbot')\n",
    "#  change Bromsgrove to \"Worcestershire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bromsgrove', 'Malvern Hills', 'Redditch', 'Worcester', 'Wychavon'], 'Worcestershire')\n",
    "# change Broxbourne to \"Hertfordshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Watford', 'Stevenage', 'St Albans', 'Three Rivers', 'Welwyn Hatfield', 'North Hertfordshire', 'Broxbourne', 'East Hertfordshire', 'Dacorum', 'Hertsmere'], 'Hertfordshire')\n",
    "# change Broxtowe to \"South and West Derbyshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Broxtowe', 'Amber Valley', 'Derbyshire Dales', 'Erewash', 'South Derbyshire'], 'South and West Derbyshire')\n",
    "# change Buckinghamshire to \"Buckinghamshire CC\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Buckinghamshire'], 'Buckinghamshire CC')\n",
    "# change Burnley to \"East Lancashire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Burnley', 'Hyndburn', 'Pendle', 'Ribble Valley', 'Rossendale'], 'East Lancashire')\n",
    "# change Caerphilly to \"Cardiff and Vale of Glamorgan\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Caerphilly', 'Cardiff', 'Vale of Glamorgan'], 'Cardiff and Vale of Glamorgan')\n",
    "# change Cambridge to Cambridgeshire CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cambridge', 'East Cambridgeshire', 'Fenland', 'Huntingdonshire', 'South Cambridgeshire'], 'Cambridgeshire CC')\n",
    "# change Cannock Chase to Staffordshire CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Newcastle-under-Lyme', 'Cannock Chase', 'East Staffordshire', 'Lichfield', 'South Staffordshire', 'Tamworth', 'Staffordshire Moorlands', 'Stafford'], 'Staffordshire CC')\n",
    "# change Carmarthenshire to South West Wales\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Carmarthenshire', 'Pembrokeshire'], 'South West Wales')\n",
    "# change Ceredigion to Central Valleys\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Ceredigion', case=False, na=False), 'ONS Geography'] = 'Central Valleys'\n",
    "# change Cherwell to Oxfordshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cherwell', 'Oxford', 'South Oxfordshire', 'Vale of White Horse', 'West Oxfordshire'], 'Oxfordshire')\n",
    "# change Chesterfield to East Derbyshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Chesterfield', 'North East Derbyshire', 'High Peak'], 'East Derbyshire')\n",
    "# change Chorley to Chorley and West Lancashire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Chorley', 'Fylde', 'South Ribble', 'West Lancashire'], 'Chorley and West Lancashire')\n",
    "# change City of London to Camden and City of London\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['City of London', 'Camden'], 'Camden and City of London')\n",
    "# change Clackmannanshire to Clackmannanshire and Fife\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Clackmannanshire', 'Fife'], 'Clackmannanshire and Fife')\n",
    "# change Conwy to Conwy and Denbighshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Conwy', 'Denbighshire'], 'Conwy and Denbighshire')\n",
    "# change Cornwall to Cornwall and Isles of Scilly\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cornwall', 'Isles of Scilly'], 'Cornwall and Isles of Scilly')\n",
    "# change County Durham to Durham CC\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('County Durham', case=False, na=False), 'ONS Geography'] = 'Durham CC'\n",
    "# change Crawley to West Sussex\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Crawley', case=False, na=False), 'ONS Geography'] = 'West Sussex (North East)'\n",
    "# change East Ayrshire to East Ayrshire and North Ayrshire mainland\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Ayrshire', 'North Ayrshire'], 'East Ayrshire and North Ayrshire mainland')\n",
    "# change East Devon to Devon CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Devon', 'Exeter', 'Mid Devon', 'North Devon', 'South Hams', 'Teignbridge', 'Torridge', 'West Devon'], 'Devon CC')\n",
    "# change East Dunbartonshire to East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Dunbartonshire', 'West dunbartonshire', 'West Dunbartonshire'], 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond')\n",
    "# change East Hampshire to Central Hampshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Hampshire', 'Eastleigh', 'New Forest'], 'Central Hampshire')\n",
    "# change East Lothian to East Lothian and Midlothian\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Lothian', 'Midlothian'], 'East Lothian and Midlothian')\n",
    "# change East Renfrewshire to Inverclyde, East Renfrewshire and Renfrewshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Renfrewshire', 'Inverclyde', 'Renfrewshire'], 'Inverclyde, East Renfrewshire and Renfrewshire')\n",
    "# change Eastbourne to East Sussex\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Eastbourne', 'East Sussex'])\n",
    "# change Elmbridge to West Surrey\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Elmbridge', 'Epsom and Ewell', 'Guildford', 'Runnymede', 'Spelthorne', 'Woking', 'Waverley', 'Surrey Heath'], 'West Surrey')\n",
    "# change Fareham to South Hampshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Fareham', 'Gosport', 'Havant'], 'South Hampshire')\n",
    "# change Flintshire to Flintshire and Wrexham\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Flintshire', 'Wrexham'], 'Flintshire and Wrexham')\n",
    "# change Folkestone and Hythe to East Kent\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Folkestone and Hythe', 'Dover', 'Ashford', 'Canterbury'], 'East Kent')\n",
    "# change Forest of Dean to Gloucestershire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Gloucester', 'Forest of Dean', 'Cotswold', 'Cheltenham', 'Stroud', 'Tewkesbury'], 'Gloucestershire')\n",
    "# change Gateshead to Tyneside\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Newcastle upon Tyne', 'Gateshead', 'North Tyneside', 'South Tyneside'], 'Tyneside')\n",
    "# change Hackney to Hackney and Newham\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hackney', 'Newham'], 'Hackney and Newham')\n",
    "# change Hammersmith and Fulham to Kensington & Chelsea and Hammersmith & Fulham\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hammersmith and Fulham', 'Kensington and Chelsea'], 'Kensington & Chelsea and Hammersmith & Fulham')\n",
    "# change Harlow to Essex Thames Gateway\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Harlow', 'Epping Forest'], 'Essex Thames Gateway')\n",
    "# change Harrow to Harrow and Hillingdon\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Harrow', 'Hillingdon'], 'Harrow and Hillingdon')\n",
    "# change Haringey to Haringey and Islington\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Haringey', 'Islington'], 'Haringey and Islington')\n",
    "# change Hastings to East Sussex CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hastings', 'Lewes', 'Rother', 'Wealden'], 'East Sussex CC')\n",
    "# change Highland to Highlands and Islands\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Highland', case=False, na=False), 'ONS Geography'] = 'Caithness and Sutherland and Ross and Cromarty'\n",
    "# change Hounslow to Hounslow and Richmond upon Thames\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hounslow', 'Richmond upon Thames'], 'Hounslow and Richmond upon Thames')\n",
    "# change King's Lynn and West Norfolk to North and West Norfolk\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace([\"King's Lynn and West Norfolk\", 'North Norfolk'], 'North and West Norfolk')\n",
    "# change Kingston upon Thames to Merton, Kingston upon Thames and Sutton\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Kingston upon Thames', 'Merton', 'Sutton'], 'Merton, Kingston upon Thames and Sutton')\n",
    "# change Kirklees to Calderdale and Kirklees\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Kirklees', 'Calderdale'], 'Calderdale and Kirklees')\n",
    "# change Knowsley to East Merseyside\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Knowsley', 'St. Helens'], 'East Merseyside')\n",
    "# change Lancaster to Lancaster and Wyre\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lancaster', 'Wyre', 'Wyre Forest'], 'Lancaster and Wyre')\n",
    "# change Lewisham to Lewisham and Southwark\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lewisham', 'Southwark'], 'Lewisham and Southwark')\n",
    "# change Lincoln to North and North East Lincolnshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lincoln', 'North East Lincolnshire', 'North Lincolnshire', 'East Lindsey'], 'North and North East Lincolnshire')\n",
    "# change Maidstone to Medway\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace('Maidstone', 'Medway')\n",
    "# change Mansfield to Nottingham\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mansfield', 'Newark and Sherwood'], 'Nottingham')\n",
    "# change Mendip to Somerset\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mendip', 'South Somerset', 'Somerset West and Taunton', 'Sedgemoor'], 'Somerset')\n",
    "# change Mole Valley to East Surrey\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mole Valley', 'Reigate and Banstead', 'Tandridge'], 'East Surrey')\n",
    "# change Monmouthshire to Monmouthshire and Newport\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Monmouthshire', 'Newport'], 'Monmouthshire and Newport')\n",
    "# change Moray to Inverness and Nairn and Moray, Badenoch and Strathspey\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Moray'], 'Inverness and Nairn and Moray, Badenoch and Strathspey')\n",
    "# change North Warwickshire to Warwickshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Warwick', 'North Warwickshire', 'Nuneaton and Bedworth', 'Rugby', 'Stratford-on-Avon'], 'Warwickshire')\n",
    "# change Norwich to Norwich and East Norfolk\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Norwich', case=False, na=False), 'ONS Geography'] = 'Norwich and East Norfolk'\n",
    "# change Oldham to Greater Manchester North East\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Oldham', 'Rochdale', 'Salford'], 'Greater Manchester North East')\n",
    "# change Perth and Kinross to Perth and Kinross and Stirling\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Perth and Kinross', 'Stirling'], 'Perth and Kinross and Stirling')\n",
    "# change preston to Mid Lancashire\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Preston', case=False, na=False), 'ONS Geography'] = 'Mid Lancashire'\n",
    "# change 'Redcar and Cleveland' to South Teesside\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Redcar and Cleveland'], 'South Teesside')\n",
    "# change Redcar and Cleveland to North Yorkshire CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Richmondshire', 'Middlesbrough', 'Hambleton', 'Harrogate', 'Ryedale', 'Scarborough', 'Selby', 'Craven'], 'North Yorkshire CC')\n",
    "# change Redbridge to Redbridge and Waltham Forest\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Redbridge', 'Waltham Forest'], 'Redbridge and Waltham Forest')\n",
    "# change Rushcliffe to Nottinghamshire\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Rushcliffe', case=False, na=False), 'ONS Geography'] = 'South Nottinghamshire'\n",
    "# change Shropshire to Shropshire CC\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Shropshire', case=False, na=False), 'ONS Geography'] = 'Shropshire CC'\n",
    "# change Stockport to Greater Manchester South East\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Stockport', 'Tameside', 'Wigan'], 'Greater Manchester South East')\n",
    "# change 'Trafford' to Greater Manchester South West\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Trafford'], 'Greater Manchester South West')\n",
    "# change Stockton-on-Tees to Hartlepool and Stockton-on-Tees\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Stockton-on-Tees', 'Hartlepool and Stockton-on-Tees'])\n",
    "# change Tendring to Essex\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Tendring', 'Uttlesford'], 'West Essex')\n",
    "# change Test Valley to Central Hampshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Test Valley'], 'Central Hampshire')\n",
    "# change Winchester to Portsmouth\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Winchester', case=False, na=False), 'ONS Geography'] = 'Portsmouth'\n",
    "# 'Tonbridge and Malling' to west Kent\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Tonbridge and Malling', 'Tunbridge Wells', 'Sevenoaks'], 'West Kent')\n",
    "# change Tunbridge Wells to Kent Thames Gateway\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Thanet', 'Swale', 'Gravesham', 'Dartford'], 'Kent Thames Gateway')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# check which values are in ONS Geography in vehicle_removed_df but not in gdhi_population_fuel_electric_df\n",
    "remove = set(vehicle_removed_df['ONS Geography'].unique()) - set(gdhi_population_fuel_electric_df['ITL level 3'].unique())\n",
    "# remove rows with values in remove\n",
    "vehicle_removed_df = vehicle_removed_df[~vehicle_removed_df['ONS Geography'].isin(remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Battery electric', 'Total', 'Plug-in hybrid electric (diesel)',\n",
       "       'Plug-in hybrid electric (petrol)', 'Range extended electric',\n",
       "       'Diesel', 'Hybrid electric (petrol)', 'Other fuels', 'Petrol'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique values in Fuel column\n",
    "vehicle_removed_df['Fuel'].unique()\n",
    "# columns\n",
    "vehicle_removed_df.columns\n",
    "# remove ONS Code and ONS Sort columns\n",
    "vehicle_removed_df = vehicle_removed_df.drop(columns=['ONS Code', 'ONS Sort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuel types - ['Battery electric', 'Total', 'Plug-in hybrid electric (diesel)', 'Plug-in hybrid electric (petrol)', 'Range extended electric','Diesel', 'Hybrid electric (petrol)', 'Other fuels', 'Petrol']\n",
    "# create new dataframe for each fuel type\n",
    "battery_electric_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Battery electric']\n",
    "plug_in_hybrid_diesel_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Plug-in hybrid electric (diesel)']\n",
    "plug_in_hybrid_petrol_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Plug-in hybrid electric (petrol)']\n",
    "range_extended_electric_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Range extended electric']\n",
    "diesel_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Diesel']\n",
    "hybrid_petrol_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Hybrid electric (petrol)']\n",
    "other_fuels_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Other fuels']\n",
    "petrol_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Petrol']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdhi_population_fuel_electric_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# merge each fuel type dataframe with gdhi_population_fuel_electric_df\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#Y122sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m battery_electric_gdhi_df \u001b[39m=\u001b[39m gdhi_population_fuel_electric_df\u001b[39m.\u001b[39mmerge(battery_electric_df, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m, left_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mITL level 3\u001b[39m\u001b[39m'\u001b[39m], right_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mONS Geography\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#Y122sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plug_in_hybrid_diesel_gdhi_df \u001b[39m=\u001b[39m gdhi_population_fuel_electric_df\u001b[39m.\u001b[39mmerge(plug_in_hybrid_diesel_df, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m, left_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mITL level 3\u001b[39m\u001b[39m'\u001b[39m], right_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mONS Geography\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#Y122sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plug_in_hybrid_petrol_gdhi_df \u001b[39m=\u001b[39m gdhi_population_fuel_electric_df\u001b[39m.\u001b[39mmerge(plug_in_hybrid_petrol_df, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m, left_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mITL level 3\u001b[39m\u001b[39m'\u001b[39m], right_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mONS Geography\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdhi_population_fuel_electric_df' is not defined"
     ]
    }
   ],
   "source": [
    "# merge each fuel type dataframe with gdhi_population_fuel_electric_df\n",
    "battery_electric_gdhi_df = gdhi_population_fuel_electric_df.merge(battery_electric_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "plug_in_hybrid_diesel_gdhi_df = gdhi_population_fuel_electric_df.merge(plug_in_hybrid_diesel_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "plug_in_hybrid_petrol_gdhi_df = gdhi_population_fuel_electric_df.merge(plug_in_hybrid_petrol_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "range_extended_electric_gdhi_df = gdhi_population_fuel_electric_df.merge(range_extended_electric_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "diesel_gdhi_df = gdhi_population_fuel_electric_df.merge(diesel_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "hybrid_petrol_gdhi_df = gdhi_population_fuel_electric_df.merge(hybrid_petrol_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "other_fuels_gdhi_df = gdhi_population_fuel_electric_df.merge(other_fuels_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "petrol_gdhi_df = gdhi_population_fuel_electric_df.merge(petrol_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "\n",
    "# drop ONS Geography column\n",
    "battery_electric_gdhi_df = battery_electric_gdhi_df.drop(columns=['ONS Geography'])\n",
    "plug_in_hybrid_diesel_gdhi_df = plug_in_hybrid_diesel_gdhi_df.drop(columns=['ONS Geography'])\n",
    "plug_in_hybrid_petrol_gdhi_df = plug_in_hybrid_petrol_gdhi_df.drop(columns=['ONS Geography'])\n",
    "range_extended_electric_gdhi_df = range_extended_electric_gdhi_df.drop(columns=['ONS Geography'])\n",
    "diesel_gdhi_df = diesel_gdhi_df.drop(columns=['ONS Geography'])\n",
    "hybrid_petrol_gdhi_df = hybrid_petrol_gdhi_df.drop(columns=['ONS Geography'])\n",
    "other_fuels_gdhi_df = other_fuels_gdhi_df.drop(columns=['ONS Geography'])\n",
    "petrol_gdhi_df = petrol_gdhi_df.drop(columns=['ONS Geography'])\n",
    "\n",
    "# drop nan values\n",
    "battery_electric_gdhi_df = battery_electric_gdhi_df.dropna()\n",
    "plug_in_hybrid_diesel_gdhi_df = plug_in_hybrid_diesel_gdhi_df.dropna()\n",
    "plug_in_hybrid_petrol_gdhi_df = plug_in_hybrid_petrol_gdhi_df.dropna()\n",
    "range_extended_electric_gdhi_df = range_extended_electric_gdhi_df.dropna()\n",
    "diesel_gdhi_df = diesel_gdhi_df.dropna()\n",
    "hybrid_petrol_gdhi_df = hybrid_petrol_gdhi_df.dropna()\n",
    "other_fuels_gdhi_df = other_fuels_gdhi_df.dropna()\n",
    "petrol_gdhi_df = petrol_gdhi_df.dropna()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat columns with electric vehicle dataframes\n",
    "electric_vehicle_df = pd.concat([battery_electric_gdhi_df, plug_in_hybrid_diesel_gdhi_df, plug_in_hybrid_petrol_gdhi_df, range_extended_electric_gdhi_df, hybrid_petrol_gdhi_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58886828, 19)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electric_vehicle_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aberdeen City and Aberdeenshire',\n",
       " 'Angus and Dundee City',\n",
       " 'Antrim and Newtownabbey',\n",
       " 'Ards and North Down',\n",
       " 'Armagh City, Banbridge and Craigavon',\n",
       " 'Barking & Dagenham and Havering',\n",
       " 'Barnet',\n",
       " 'Barnsley, Doncaster and Rotherham',\n",
       " 'Bath and North East Somerset, North Somerset and South Gloucestershire',\n",
       " 'Bedford',\n",
       " 'Belfast',\n",
       " 'Bexley and Greenwich',\n",
       " 'Breckland and South Norfolk',\n",
       " 'Brent',\n",
       " 'Bridgend and Neath Port Talbot',\n",
       " 'Bristol, City of',\n",
       " 'Bromley',\n",
       " 'Buckinghamshire CC',\n",
       " 'Caithness and Sutherland and Ross and Cromarty',\n",
       " 'Calderdale and Kirklees',\n",
       " 'Cambridgeshire CC',\n",
       " 'Camden and City of London',\n",
       " 'Cardiff and Vale of Glamorgan',\n",
       " 'Causeway Coast and Glens',\n",
       " 'Central Hampshire',\n",
       " 'Central Valleys',\n",
       " 'Chorley and West Lancashire',\n",
       " 'Clackmannanshire and Fife',\n",
       " 'Conwy and Denbighshire',\n",
       " 'Cornwall and Isles of Scilly',\n",
       " 'Croydon',\n",
       " 'Derby',\n",
       " 'Derry City and Strabane',\n",
       " 'Devon CC',\n",
       " 'Durham CC',\n",
       " 'Ealing',\n",
       " 'East Ayrshire and North Ayrshire mainland',\n",
       " 'East Cumbria',\n",
       " 'East Derbyshire',\n",
       " 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond',\n",
       " 'East Kent',\n",
       " 'East Lancashire',\n",
       " 'East Lothian and Midlothian',\n",
       " 'East Merseyside',\n",
       " 'East Surrey',\n",
       " 'East Sussex CC',\n",
       " 'Enfield',\n",
       " 'Essex Haven Gateway',\n",
       " 'Essex Thames Gateway',\n",
       " 'Fermanagh and Omagh',\n",
       " 'Flintshire and Wrexham',\n",
       " 'Greater Manchester North East',\n",
       " 'Greater Manchester North West',\n",
       " 'Greater Manchester South East',\n",
       " 'Greater Manchester South West',\n",
       " 'Gwent Valleys',\n",
       " 'Hackney and Newham',\n",
       " 'Haringey and Islington',\n",
       " 'Harrow and Hillingdon',\n",
       " 'Heart of Essex',\n",
       " 'Herefordshire, County of',\n",
       " 'Hounslow and Richmond upon Thames',\n",
       " 'Inverclyde, East Renfrewshire and Renfrewshire',\n",
       " 'Inverness and Nairn and Moray, Badenoch and Strathspey',\n",
       " 'Kensington & Chelsea and Hammersmith & Fulham',\n",
       " 'Kent Thames Gateway',\n",
       " 'Kingston upon Hull, City of',\n",
       " 'Lancaster and Wyre',\n",
       " 'Leeds',\n",
       " 'Leicestershire CC and Rutland',\n",
       " 'Lewisham and Southwark',\n",
       " 'Lisburn and Castlereagh',\n",
       " 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute',\n",
       " 'Medway',\n",
       " 'Merton, Kingston upon Thames and Sutton',\n",
       " 'Mid Lancashire',\n",
       " 'Mid Ulster',\n",
       " 'Mid and East Antrim',\n",
       " 'Monmouthshire and Newport',\n",
       " 'Newry, Mourne and Down',\n",
       " 'North Hampshire',\n",
       " 'North Nottinghamshire',\n",
       " 'North Yorkshire CC',\n",
       " 'North and North East Lincolnshire',\n",
       " 'North and West Norfolk',\n",
       " 'Norwich and East Norfolk',\n",
       " 'Perth and Kinross and Stirling',\n",
       " 'Portsmouth',\n",
       " 'Redbridge and Waltham Forest',\n",
       " 'Sandwell',\n",
       " 'Sefton',\n",
       " 'Sheffield',\n",
       " 'Shropshire CC',\n",
       " 'Solihull',\n",
       " 'South Hampshire',\n",
       " 'South Nottinghamshire',\n",
       " 'South Teesside',\n",
       " 'South West Wales',\n",
       " 'South and West Derbyshire',\n",
       " 'Southend-on-Sea',\n",
       " 'Staffordshire CC',\n",
       " 'Stoke-on-Trent',\n",
       " 'Telford and Wrekin',\n",
       " 'Thurrock',\n",
       " 'Torbay',\n",
       " 'Tower Hamlets',\n",
       " 'Tyneside',\n",
       " 'Wandsworth',\n",
       " 'West Cumbria',\n",
       " 'West Essex',\n",
       " 'West Kent',\n",
       " 'West Northamptonshire',\n",
       " 'West Surrey',\n",
       " 'West Sussex (North East)',\n",
       " 'West Sussex (South West)',\n",
       " 'Westminster'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chargepoint df save column names in text file\n",
    "# save column names in text file\n",
    "with open('chargepoint_columns.txt', 'w') as f:\n",
    "    for item in chargepoint_df.columns:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "# show unique values in town column\n",
    "chargepoint_df['county'].unique()\n",
    "# compare values in town column with values in ONS Geography column\n",
    "# get unique values in ONS Geography column\n",
    "vehicle_removed_df['ONS Geography'].unique()\n",
    "# get unique values in town column\n",
    "chargepoint_df['county'].unique()\n",
    "# get unique values in town column that are not in ONS Geography column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aberdeen City and Aberdeenshire',\n",
       " 'Angus and Dundee City',\n",
       " 'Antrim and Newtownabbey',\n",
       " 'Ards and North Down',\n",
       " 'Armagh City, Banbridge and Craigavon',\n",
       " 'Barking & Dagenham and Havering',\n",
       " 'Barnet',\n",
       " 'Barnsley, Doncaster and Rotherham',\n",
       " 'Bath and North East Somerset, North Somerset and South Gloucestershire',\n",
       " 'Bedford',\n",
       " 'Belfast',\n",
       " 'Bexley and Greenwich',\n",
       " 'Breckland and South Norfolk',\n",
       " 'Brent',\n",
       " 'Bridgend and Neath Port Talbot',\n",
       " 'Bristol, City of',\n",
       " 'Bromley',\n",
       " 'Buckinghamshire CC',\n",
       " 'Caithness and Sutherland and Ross and Cromarty',\n",
       " 'Calderdale and Kirklees',\n",
       " 'Cambridgeshire CC',\n",
       " 'Camden and City of London',\n",
       " 'Cardiff and Vale of Glamorgan',\n",
       " 'Causeway Coast and Glens',\n",
       " 'Central Hampshire',\n",
       " 'Central Valleys',\n",
       " 'Chorley and West Lancashire',\n",
       " 'Clackmannanshire and Fife',\n",
       " 'Conwy and Denbighshire',\n",
       " 'Cornwall and Isles of Scilly',\n",
       " 'Croydon',\n",
       " 'Derby',\n",
       " 'Derry City and Strabane',\n",
       " 'Devon CC',\n",
       " 'Durham CC',\n",
       " 'Ealing',\n",
       " 'East Ayrshire and North Ayrshire mainland',\n",
       " 'East Cumbria',\n",
       " 'East Derbyshire',\n",
       " 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond',\n",
       " 'East Kent',\n",
       " 'East Lancashire',\n",
       " 'East Lothian and Midlothian',\n",
       " 'East Merseyside',\n",
       " 'East Surrey',\n",
       " 'East Sussex CC',\n",
       " 'Enfield',\n",
       " 'Essex Haven Gateway',\n",
       " 'Essex Thames Gateway',\n",
       " 'Fermanagh and Omagh',\n",
       " 'Flintshire and Wrexham',\n",
       " 'Greater Manchester North East',\n",
       " 'Greater Manchester North West',\n",
       " 'Greater Manchester South East',\n",
       " 'Greater Manchester South West',\n",
       " 'Gwent Valleys',\n",
       " 'Hackney and Newham',\n",
       " 'Haringey and Islington',\n",
       " 'Harrow and Hillingdon',\n",
       " 'Heart of Essex',\n",
       " 'Herefordshire, County of',\n",
       " 'Hounslow and Richmond upon Thames',\n",
       " 'Inverclyde, East Renfrewshire and Renfrewshire',\n",
       " 'Inverness and Nairn and Moray, Badenoch and Strathspey',\n",
       " 'Kensington & Chelsea and Hammersmith & Fulham',\n",
       " 'Kent Thames Gateway',\n",
       " 'Kingston upon Hull, City of',\n",
       " 'Lancaster and Wyre',\n",
       " 'Leeds',\n",
       " 'Leicestershire CC and Rutland',\n",
       " 'Lewisham and Southwark',\n",
       " 'Lisburn and Castlereagh',\n",
       " 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute',\n",
       " 'Medway',\n",
       " 'Merton, Kingston upon Thames and Sutton',\n",
       " 'Mid Lancashire',\n",
       " 'Mid Ulster',\n",
       " 'Mid and East Antrim',\n",
       " 'Monmouthshire and Newport',\n",
       " 'Newry, Mourne and Down',\n",
       " 'North Hampshire',\n",
       " 'North Nottinghamshire',\n",
       " 'North Yorkshire CC',\n",
       " 'North and North East Lincolnshire',\n",
       " 'North and West Norfolk',\n",
       " 'Norwich and East Norfolk',\n",
       " 'Perth and Kinross and Stirling',\n",
       " 'Portsmouth',\n",
       " 'Redbridge and Waltham Forest',\n",
       " 'Sandwell',\n",
       " 'Sefton',\n",
       " 'Sheffield',\n",
       " 'Shropshire CC',\n",
       " 'Solihull',\n",
       " 'South Hampshire',\n",
       " 'South Nottinghamshire',\n",
       " 'South Teesside',\n",
       " 'South West Wales',\n",
       " 'South and West Derbyshire',\n",
       " 'Southend-on-Sea',\n",
       " 'Staffordshire CC',\n",
       " 'Stoke-on-Trent',\n",
       " 'Telford and Wrekin',\n",
       " 'Thurrock',\n",
       " 'Torbay',\n",
       " 'Tower Hamlets',\n",
       " 'Tyneside',\n",
       " 'Wandsworth',\n",
       " 'West Cumbria',\n",
       " 'West Essex',\n",
       " 'West Kent',\n",
       " 'West Northamptonshire',\n",
       " 'West Surrey',\n",
       " 'West Sussex (North East)',\n",
       " 'West Sussex (South West)',\n",
       " 'Westminster'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(vehicle_removed_df['ONS Geography'].unique()) - set(chargepoint_df['county'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Lambeth',\n",
       " ' Newport',\n",
       " ' Somerset',\n",
       " '0',\n",
       " '07:00',\n",
       " '4',\n",
       " 'Aberdeen City',\n",
       " 'Aberdeenshire',\n",
       " 'Aberystwyth',\n",
       " 'Anglesey',\n",
       " 'Angus',\n",
       " 'Angus ',\n",
       " 'Antrim',\n",
       " 'Argyl and Bute',\n",
       " 'Argyll',\n",
       " 'Argyll & Bute',\n",
       " 'Argyll and Bute',\n",
       " 'Armagh',\n",
       " 'Attleborough',\n",
       " 'Avon',\n",
       " 'BERKSHIRE',\n",
       " 'Barnsley',\n",
       " 'Basingstoke',\n",
       " 'Basingstoke and Deane Borough Council',\n",
       " 'Bath and North East Somerset',\n",
       " 'Bedfordshire',\n",
       " 'Beds',\n",
       " 'Belfast Greater',\n",
       " 'Bilston',\n",
       " 'Blaenau Gwent',\n",
       " 'Bournemouth',\n",
       " 'Bridgend',\n",
       " 'Bristol',\n",
       " 'Buckingham',\n",
       " 'Buckinghamshire',\n",
       " 'Bucks',\n",
       " 'Burton-on-Trent',\n",
       " 'Bury',\n",
       " 'Caerphilly',\n",
       " 'Calne',\n",
       " 'Cambridgeshire',\n",
       " 'Cambs',\n",
       " 'Cardiff',\n",
       " 'Carmarthenshire',\n",
       " 'Ceredigion',\n",
       " 'Cheshire',\n",
       " 'City of Aberdeen',\n",
       " 'City of Bristol',\n",
       " 'City of Cardiff',\n",
       " 'City of Coventry',\n",
       " 'City of Glasgow',\n",
       " 'City of Leicester',\n",
       " 'City of London',\n",
       " 'City of Nottingham',\n",
       " 'City of Westminster',\n",
       " 'Cleveland',\n",
       " 'Clwyd',\n",
       " 'Co Durham',\n",
       " 'Conwy',\n",
       " 'Cornwall',\n",
       " 'County Antrim',\n",
       " 'County Armagh',\n",
       " 'County Cork',\n",
       " 'County Down',\n",
       " 'County Dublin',\n",
       " 'County Durham',\n",
       " 'County Fermanagh',\n",
       " 'County Galway',\n",
       " 'County Limerick',\n",
       " 'County Londonderry',\n",
       " 'County Tyrone',\n",
       " 'County Wicklow',\n",
       " 'County of Bristol',\n",
       " 'Cumbria',\n",
       " 'Dartford',\n",
       " 'Deeside',\n",
       " 'Denbighshire',\n",
       " 'Derbys',\n",
       " 'Derbyshire',\n",
       " 'Derbyshire ',\n",
       " 'Derry',\n",
       " 'Devon',\n",
       " 'Devon ',\n",
       " 'Doncaster',\n",
       " 'Down',\n",
       " 'Dublin',\n",
       " 'Dumfries & Galloway',\n",
       " 'Dumfriesshire',\n",
       " 'Dunbartonshire',\n",
       " 'Dundee',\n",
       " 'Dundee City',\n",
       " 'Dunstable',\n",
       " 'Durham',\n",
       " 'Dyfed',\n",
       " 'East Ayrshire',\n",
       " 'East Dunbartonshire',\n",
       " 'East Lothian',\n",
       " 'East Renfrewshire',\n",
       " 'East Sussex',\n",
       " 'East Yorkshire',\n",
       " 'Edinburgh',\n",
       " 'Eilean Siar',\n",
       " 'Essex',\n",
       " 'Exeter',\n",
       " 'Fermanagh',\n",
       " 'Fife',\n",
       " 'Flintshire',\n",
       " 'Folkestone',\n",
       " 'Galway County',\n",
       " 'Gateshead',\n",
       " 'Glamorgan',\n",
       " 'Glamorgan (Morgannwg)',\n",
       " 'Glamorganshire',\n",
       " 'Glasgow',\n",
       " 'Gloucs',\n",
       " 'Grantham',\n",
       " 'Greater London',\n",
       " 'Greater London ',\n",
       " 'Greater Manchester',\n",
       " 'Guernsey',\n",
       " 'Gwent',\n",
       " 'Hammersmith & Fulham Council',\n",
       " 'Hampshire',\n",
       " 'Hampshire ',\n",
       " 'Hants',\n",
       " 'Hartlepool',\n",
       " 'Hereford',\n",
       " 'Herefordshire',\n",
       " 'Herts',\n",
       " 'Highland',\n",
       " 'Highlands',\n",
       " 'Hull City',\n",
       " 'Inverclyde',\n",
       " 'Inverness-Shire',\n",
       " 'Inverness-shire',\n",
       " 'Isle Of Wight',\n",
       " 'Isle of Man',\n",
       " 'Islington Council',\n",
       " 'KENT',\n",
       " 'Kent',\n",
       " 'Kent ',\n",
       " 'LB Tower Hamlets',\n",
       " 'Lanarkshire',\n",
       " 'Lancashire',\n",
       " 'Lancashire ',\n",
       " 'Lancs',\n",
       " 'Langport',\n",
       " 'Leicestershire',\n",
       " 'Leics',\n",
       " 'Lincolnshire ',\n",
       " 'Lincs',\n",
       " 'Liverpool City Council',\n",
       " 'Lond',\n",
       " 'London',\n",
       " 'London ',\n",
       " 'London Borough Of Southwark',\n",
       " 'London Borough of Brent',\n",
       " 'London Borough of Brent ',\n",
       " 'London Borough of Camden',\n",
       " 'London Borough of Ealing',\n",
       " 'London Borough of Enfield',\n",
       " 'London Borough of Greenwich',\n",
       " 'London Borough of Hackney',\n",
       " 'London Borough of Hammersmith and Fulham',\n",
       " 'London Borough of Hounslow',\n",
       " 'London Borough of Islington',\n",
       " 'London Borough of Lambeth',\n",
       " 'London Borough of Lewisham',\n",
       " 'London Borough of Newham',\n",
       " 'London Borough of Richmond upon Thames',\n",
       " 'London Borough of Southwark',\n",
       " 'London Borough of Sutton',\n",
       " 'London Borough of Tower Hamlets',\n",
       " 'London Borough of Waltham Forest',\n",
       " 'London Borough of Wandsworth',\n",
       " 'London Borough of Wandsworth ',\n",
       " 'Lothian',\n",
       " 'Luton Borough Council',\n",
       " 'Maidstone',\n",
       " 'Me10 2La',\n",
       " 'Merseyside',\n",
       " 'Mersyside',\n",
       " 'Merthyr Tydfil',\n",
       " 'Mid Glamorgan',\n",
       " 'Mid Glamorgan ',\n",
       " 'Mid Sussex',\n",
       " 'Middlesborough',\n",
       " 'Middlesbrough',\n",
       " 'Middlesex',\n",
       " 'Middlesex ',\n",
       " 'Midlothian',\n",
       " 'Monmouthshire',\n",
       " 'Moray',\n",
       " 'Morpeth',\n",
       " 'Neath Port Talbot',\n",
       " 'Newcastle upon Tyne',\n",
       " 'Newport',\n",
       " 'Newry',\n",
       " 'Newtownabbey',\n",
       " 'None',\n",
       " 'Norfolk',\n",
       " 'North Ayrshire',\n",
       " 'North East Lincolnshire',\n",
       " 'North Humberside',\n",
       " 'North Lanakshire',\n",
       " 'North Lincolnshire',\n",
       " 'North Somerset',\n",
       " 'North Yorkshire',\n",
       " 'Northampton',\n",
       " 'Northampton ',\n",
       " 'Northamptonshire',\n",
       " 'Norwich',\n",
       " 'Nottinghamshire',\n",
       " 'Notts',\n",
       " 'Notts.',\n",
       " 'Oxford City Council',\n",
       " 'Oxon',\n",
       " 'Pembrokeshire',\n",
       " 'Perth & Kinross',\n",
       " 'Perth and Kinross',\n",
       " 'Perthshire',\n",
       " 'Plymoputh',\n",
       " 'Portsmouth City Council',\n",
       " 'Preston',\n",
       " 'Reading',\n",
       " 'Redcar and Cleveland',\n",
       " 'Renfewshire',\n",
       " 'Renfrewshire',\n",
       " 'Rhondda Cynon Taff',\n",
       " 'Richmond upon Thames Council',\n",
       " 'Romney Marsh',\n",
       " 'Romsey',\n",
       " 'Royal Borough of Greenwich',\n",
       " 'Royal Borough of Kensington and Chelsea',\n",
       " 'Rutland',\n",
       " 'Rutlands',\n",
       " 'SG1 1EP',\n",
       " 'Salford',\n",
       " 'Salop',\n",
       " 'Scotland',\n",
       " 'Scunthorpe',\n",
       " 'Shropshire',\n",
       " 'South Glamorgan',\n",
       " 'South Gloucestershire',\n",
       " 'South Humberside',\n",
       " 'South Norfolk',\n",
       " 'South Staffordshire',\n",
       " 'South Tyneside',\n",
       " 'South Yorkshire',\n",
       " 'Southwark',\n",
       " 'Stafford',\n",
       " 'Staffordshire',\n",
       " 'Staffs',\n",
       " 'Stirling',\n",
       " 'Stirlingshire',\n",
       " 'Stockton-on-Tees',\n",
       " 'Stourbridge',\n",
       " 'Strathclyde',\n",
       " 'Surrey',\n",
       " 'Surrey ',\n",
       " 'Sussex',\n",
       " 'Torfaen',\n",
       " 'Tyne & Wear ',\n",
       " 'Tyne and Wear',\n",
       " 'Tyne and Wear,',\n",
       " 'Tyrone',\n",
       " 'United Kingdom',\n",
       " 'Vale of Glamorgan',\n",
       " 'Vale of Glamorgan, The',\n",
       " 'Wales',\n",
       " 'Wandsworth Council',\n",
       " 'Warcs',\n",
       " 'Warks',\n",
       " 'Warwick',\n",
       " 'Waverley',\n",
       " 'West Berkshire',\n",
       " 'West Berkshire Council',\n",
       " 'West Dorset',\n",
       " 'West Dunbartonshire',\n",
       " 'West Glamorgan',\n",
       " 'West Hertfordshire',\n",
       " 'West Mdilands',\n",
       " 'West Midland',\n",
       " 'West Midlands',\n",
       " 'West Midlands ',\n",
       " 'West Sussex',\n",
       " 'West Yorkshire',\n",
       " 'Western Isles',\n",
       " 'Wexford',\n",
       " 'Wick',\n",
       " 'Wigan',\n",
       " 'Wilts',\n",
       " 'Winchester',\n",
       " 'Winchester City Council',\n",
       " 'Wokingham',\n",
       " 'Worcs',\n",
       " 'Wrexham',\n",
       " 'Yorks',\n",
       " 'Yorkshire',\n",
       " 'Yorkshire ',\n",
       " 'Yorkshire, North Riding',\n",
       " '`West Midlands',\n",
       " 'flintshire',\n",
       " 'kent ',\n",
       " 'lanarkshire',\n",
       " nan,\n",
       " 'norfolk',\n",
       " 'west Yorkshire'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(chargepoint_df['county'].unique()) - set(vehicle_removed_df['ONS Geography'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
