{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from pandas_ods_reader import read_ods\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1205791447.py:3: DtypeWarning: Columns (5,10,11,16,17,18,54,56,57,58,59,60,61,62,63,64,65,66,67,68,69,79,90,101,112,115,119,122,123,126,130,133,134,137,141,144,148,152,155) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chargepoint_df = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "# retrieve data from api on the web\n",
    "url = 'http://chargepoints.dft.gov.uk/api/retrieve/registry/format/csv'\n",
    "chargepoint_df = pd.read_csv(url)\n",
    "\n",
    "# COMBINED WITH DATA FROM OCM (OPEN CHARGE MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chargeDeviceID</th>\n",
       "      <th>reference</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>subBuildingName</th>\n",
       "      <th>buildingName</th>\n",
       "      <th>buildingNumber</th>\n",
       "      <th>thoroughfare</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>connector8Type</th>\n",
       "      <th>connector8RatedOutputKW</th>\n",
       "      <th>connector8OutputCurrent</th>\n",
       "      <th>connector8RatedVoltage</th>\n",
       "      <th>connector8ChargeMethod</th>\n",
       "      <th>connector8ChargeMode</th>\n",
       "      <th>connector8TetheredCable</th>\n",
       "      <th>connector8Status</th>\n",
       "      <th>connector8Description</th>\n",
       "      <th>connector8Validated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c911241d00294e8bb714eee2e83fa475</td>\n",
       "      <td>PP-12289</td>\n",
       "      <td>Alex F Noble &amp; Son</td>\n",
       "      <td>55.875053</td>\n",
       "      <td>-3.173333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swinton Place</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa6c94460e902005a0b660266190c8ba</td>\n",
       "      <td>PP-12295</td>\n",
       "      <td>Ancaster Nissan Dealership</td>\n",
       "      <td>51.411173</td>\n",
       "      <td>-0.055369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>Croydon Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eb1848290d5a7de9c9ccabc67fefa211</td>\n",
       "      <td>PP-12290</td>\n",
       "      <td>Beadles Nissan Ltd</td>\n",
       "      <td>51.451127</td>\n",
       "      <td>0.050619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43-53</td>\n",
       "      <td>Eltham High Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91e50fe1e39af2869d3336eaaeebdb43</td>\n",
       "      <td>PP-12292</td>\n",
       "      <td>Benfield Motors</td>\n",
       "      <td>54.978947</td>\n",
       "      <td>-1.599306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176</td>\n",
       "      <td>Portland Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65b1e92c585fd4c2159d5f33b5030ff2</td>\n",
       "      <td>PP-12198</td>\n",
       "      <td>Circus Road</td>\n",
       "      <td>51.533633</td>\n",
       "      <td>-0.172353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circus Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     chargeDeviceID reference                        name  \\\n",
       "0  c911241d00294e8bb714eee2e83fa475  PP-12289          Alex F Noble & Son   \n",
       "1  fa6c94460e902005a0b660266190c8ba  PP-12295  Ancaster Nissan Dealership   \n",
       "2  eb1848290d5a7de9c9ccabc67fefa211  PP-12290         Beadles Nissan Ltd    \n",
       "3  91e50fe1e39af2869d3336eaaeebdb43  PP-12292             Benfield Motors   \n",
       "4  65b1e92c585fd4c2159d5f33b5030ff2  PP-12198                 Circus Road   \n",
       "\n",
       "    latitude  longitude subBuildingName buildingName buildingNumber  \\\n",
       "0  55.875053  -3.173333             NaN          NaN            NaN   \n",
       "1  51.411173  -0.055369             NaN          NaN             61   \n",
       "2  51.451127   0.050619             NaN          NaN          43-53   \n",
       "3  54.978947  -1.599306             NaN          NaN            176   \n",
       "4  51.533633  -0.172353             NaN          NaN            NaN   \n",
       "\n",
       "         thoroughfare         street  ... connector8Type  \\\n",
       "0                 NaN  Swinton Place  ...            NaN   \n",
       "1        Croydon Road            NaN  ...            NaN   \n",
       "2  Eltham High Street            NaN  ...            NaN   \n",
       "3       Portland Road            NaN  ...            NaN   \n",
       "4         Circus Road            NaN  ...            NaN   \n",
       "\n",
       "  connector8RatedOutputKW connector8OutputCurrent connector8RatedVoltage  \\\n",
       "0                     NaN                     NaN                    NaN   \n",
       "1                     NaN                     NaN                    NaN   \n",
       "2                     NaN                     NaN                    NaN   \n",
       "3                     NaN                     NaN                    NaN   \n",
       "4                     NaN                     NaN                    NaN   \n",
       "\n",
       "  connector8ChargeMethod connector8ChargeMode connector8TetheredCable  \\\n",
       "0                    NaN                  NaN                     NaN   \n",
       "1                    NaN                  NaN                     NaN   \n",
       "2                    NaN                  NaN                     NaN   \n",
       "3                    NaN                  NaN                     NaN   \n",
       "4                    NaN                  NaN                     NaN   \n",
       "\n",
       "  connector8Status connector8Description connector8Validated  \n",
       "0              NaN                   NaN                 NaN  \n",
       "1              NaN                   NaN                 NaN  \n",
       "2              NaN                   NaN                 NaN  \n",
       "3              NaN                   NaN                 NaN  \n",
       "4              NaN                   NaN                 NaN  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get shape of data\n",
    "chargepoint_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31843, 158)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chargepoint_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# retreive comments from openchargemap api\n",
    "url = 'https://api.openchargemap.io/v3/poi/?output=json&countrycode=GB&maxresults=100000&compact=true&verbose=false&key=1e2b0b1e-5b1e-4b3a-8b9a-0b8b9a3a2b1e&includecomments=true'\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# convert json to dataframe\n",
    "ocm_comments_df = pd.DataFrame(data)\n",
    "ocm_comments_df.to_csv('data/ocm_comments.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocm_comments_df.head()\n",
    "# unnest the column AddressInfo and UserComments\n",
    "ocm_comments_df = pd.concat([ocm_comments_df.drop(['AddressInfo'], axis=1), ocm_comments_df['AddressInfo'].apply(pd.Series)], axis=1)\n",
    "\n",
    "# COMBINED WITH CHARGEPOINT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the two dataframes using latitude and longitude\n",
    "chargepoint_df = chargepoint_df.merge(ocm_comments_df, how='left', left_on=['latitude', 'longitude'], right_on=['Latitude', 'Longitude'])\n",
    "\n",
    "# COMBINED DATA (OCM + CHARGEPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chargeDeviceID</th>\n",
       "      <th>reference</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>subBuildingName</th>\n",
       "      <th>buildingName</th>\n",
       "      <th>buildingNumber</th>\n",
       "      <th>thoroughfare</th>\n",
       "      <th>street</th>\n",
       "      <th>...</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>AccessComments</th>\n",
       "      <th>RelatedURL</th>\n",
       "      <th>DistanceUnit</th>\n",
       "      <th>StateOrProvince</th>\n",
       "      <th>AddressLine2</th>\n",
       "      <th>ContactEmail</th>\n",
       "      <th>ContactTelephone1</th>\n",
       "      <th>ContactTelephone2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c911241d00294e8bb714eee2e83fa475</td>\n",
       "      <td>PP-12289</td>\n",
       "      <td>Alex F Noble &amp; Son</td>\n",
       "      <td>55.875053</td>\n",
       "      <td>-3.173333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swinton Place</td>\n",
       "      <td>...</td>\n",
       "      <td>55.875053</td>\n",
       "      <td>-3.173333</td>\n",
       "      <td>Charge Points Located in Customer Parking Area...</td>\n",
       "      <td>http://afnoble.nissan.co.uk/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lothian</td>\n",
       "      <td>Straiton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0131 440 5353</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa6c94460e902005a0b660266190c8ba</td>\n",
       "      <td>PP-12295</td>\n",
       "      <td>Ancaster Nissan Dealership</td>\n",
       "      <td>51.411173</td>\n",
       "      <td>-0.055369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>Croydon Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eb1848290d5a7de9c9ccabc67fefa211</td>\n",
       "      <td>PP-12290</td>\n",
       "      <td>Beadles Nissan Ltd</td>\n",
       "      <td>51.451127</td>\n",
       "      <td>0.050619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43-53</td>\n",
       "      <td>Eltham High Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91e50fe1e39af2869d3336eaaeebdb43</td>\n",
       "      <td>PP-12292</td>\n",
       "      <td>Benfield Motors</td>\n",
       "      <td>54.978947</td>\n",
       "      <td>-1.599306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176</td>\n",
       "      <td>Portland Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>54.978947</td>\n",
       "      <td>-1.599306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tyne and Wear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>020 7247 4114</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65b1e92c585fd4c2159d5f33b5030ff2</td>\n",
       "      <td>PP-12198</td>\n",
       "      <td>Circus Road</td>\n",
       "      <td>51.533633</td>\n",
       "      <td>-0.172353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circus Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     chargeDeviceID reference                        name  \\\n",
       "0  c911241d00294e8bb714eee2e83fa475  PP-12289          Alex F Noble & Son   \n",
       "1  fa6c94460e902005a0b660266190c8ba  PP-12295  Ancaster Nissan Dealership   \n",
       "2  eb1848290d5a7de9c9ccabc67fefa211  PP-12290         Beadles Nissan Ltd    \n",
       "3  91e50fe1e39af2869d3336eaaeebdb43  PP-12292             Benfield Motors   \n",
       "4  65b1e92c585fd4c2159d5f33b5030ff2  PP-12198                 Circus Road   \n",
       "\n",
       "    latitude  longitude subBuildingName buildingName buildingNumber  \\\n",
       "0  55.875053  -3.173333             NaN          NaN            NaN   \n",
       "1  51.411173  -0.055369             NaN          NaN             61   \n",
       "2  51.451127   0.050619             NaN          NaN          43-53   \n",
       "3  54.978947  -1.599306             NaN          NaN            176   \n",
       "4  51.533633  -0.172353             NaN          NaN            NaN   \n",
       "\n",
       "         thoroughfare         street  ...   Latitude Longitude  \\\n",
       "0                 NaN  Swinton Place  ...  55.875053 -3.173333   \n",
       "1        Croydon Road            NaN  ...        NaN       NaN   \n",
       "2  Eltham High Street            NaN  ...        NaN       NaN   \n",
       "3       Portland Road            NaN  ...  54.978947 -1.599306   \n",
       "4         Circus Road            NaN  ...        NaN       NaN   \n",
       "\n",
       "                                      AccessComments  \\\n",
       "0  Charge Points Located in Customer Parking Area...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                     RelatedURL DistanceUnit StateOrProvince AddressLine2  \\\n",
       "0  http://afnoble.nissan.co.uk/          0.0         Lothian     Straiton   \n",
       "1                           NaN          NaN             NaN          NaN   \n",
       "2                           NaN          NaN             NaN          NaN   \n",
       "3                           NaN          0.0   Tyne and Wear          NaN   \n",
       "4                           NaN          NaN             NaN          NaN   \n",
       "\n",
       "  ContactEmail ContactTelephone1 ContactTelephone2  \n",
       "0          NaN     0131 440 5353               NaN  \n",
       "1          NaN               NaN               NaN  \n",
       "2          NaN               NaN               NaN  \n",
       "3          NaN     020 7247 4114               NaN  \n",
       "4          NaN               NaN               NaN  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# save the data to csv\n",
    "chargepoint_df.to_csv('data/chargepoint.csv')\n",
    "\n",
    "chargepoint_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>PES area</th>\n",
       "      <th>Average variable unit price (Â£/kWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Northern Scotland</td>\n",
       "      <td>0.118306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>0.147227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>0.113377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>South East</td>\n",
       "      <td>0.109783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>South Wales</td>\n",
       "      <td>0.122350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           PES area  Average variable unit price (Â£/kWh)\n",
       "0  2010  Northern Scotland                             0.118306\n",
       "1  2010   Northern Ireland                             0.147227\n",
       "2  2010      West Midlands                             0.113377\n",
       "3  2010         South East                             0.109783\n",
       "4  2010        South Wales                             0.122350"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get electricity data with only sheet name \"2.2.4\" and skipping first 12 rows\n",
    "electricity_df = pd.read_excel('data/table_224.xlsx', sheet_name='2.2.4', skiprows=12)\n",
    "# rename the columns\n",
    "electricity_df.columns = ['Year', 'Region', 'PES area', '1', '2', '3', '4', '5', '6', 'Average variable unit price (Â£/kWh)', '7']\n",
    "# drop columns 1-7\n",
    "electricity_df = electricity_df.drop(['1', '2', '3', '4', '5', '6', '7'], axis=1)\n",
    "# drop Region column\n",
    "electricity_df = electricity_df.drop(['Region'], axis=1)\n",
    "electricity_df.head()\n",
    "\n",
    "# COMBINED WITH FUEL PRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Northern Scotland', 'Northern Ireland', 'West Midlands',\n",
       "       'South East', 'South Wales', 'Southern Scotland', 'Eastern',\n",
       "       'Yorkshire', 'Merseyside & North Wales', 'London', 'North West',\n",
       "       'North East', 'East Midlands', 'South West', 'Southern',\n",
       "       'United Kingdom', 'North Scotland', 'South Scotland'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show unique values in PES area\n",
    "electricity_df['PES area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['North Scotland', 'Northern Ireland', 'West Midlands',\n",
       "       'South East', 'South Wales', 'South Scotland', 'Eastern',\n",
       "       'Yorkshire', 'Merseyside & North Wales', 'London', 'North West',\n",
       "       'North East', 'East Midlands', 'South West', 'Southern',\n",
       "       'United Kingdom'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace PES area values with the correct names\n",
    "\n",
    "electricity_df['PES area'] = electricity_df['PES area'].replace(['Northern Scotland'], 'North Scotland')\n",
    "electricity_df['PES area'] = electricity_df['PES area'].replace(['Southern Scotland'], 'South Scotland')\n",
    "# check if the values are replaced\n",
    "electricity_df['PES area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region name</th>\n",
       "      <th>ITL level</th>\n",
       "      <th>ITL code</th>\n",
       "      <th>Year</th>\n",
       "      <th>gdhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>UK</td>\n",
       "      <td>UK</td>\n",
       "      <td>1997</td>\n",
       "      <td>10757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>Other</td>\n",
       "      <td>TLB</td>\n",
       "      <td>1997</td>\n",
       "      <td>11016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North East</td>\n",
       "      <td>ITL1</td>\n",
       "      <td>TLC</td>\n",
       "      <td>1997</td>\n",
       "      <td>9253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tees Valley and Durham</td>\n",
       "      <td>ITL2</td>\n",
       "      <td>TLC1</td>\n",
       "      <td>1997</td>\n",
       "      <td>9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hartlepool and Stockton-on-Tees</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLC11</td>\n",
       "      <td>1997</td>\n",
       "      <td>9264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Region name ITL level ITL code  Year   gdhi\n",
       "0                   United Kingdom        UK       UK  1997  10757\n",
       "1                          England     Other      TLB  1997  11016\n",
       "2                       North East      ITL1      TLC  1997   9253\n",
       "3           Tees Valley and Durham      ITL2     TLC1  1997   9200\n",
       "4  Hartlepool and Stockton-on-Tees      ITL3    TLC11  1997   9264"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gdhi data\n",
    "gdhi_df = pd.read_excel(\"data/regionalgrossdisposablehouseholdincomeallitlregions.xls\", sheet_name=\"Table 3\", skiprows=1)\n",
    "# melt the dataframe\n",
    "gdhi_df = pd.melt(gdhi_df, id_vars=['Region name', 'ITL level','ITL code'], var_name='Year', value_vars=['1997', '1998', \n",
    "                                                                                                         '1999', '2000', '2001', '2002', \n",
    "                                                                                                         '2003','2004', '2005', '2006', \n",
    "                                                                                                         '2007', '2008', '2009', '2010',\n",
    "                                                                                                         '2011', '2012', '2013', '2014', \n",
    "                                                                                                         '2015', '2016', '2017','2018', \n",
    "                                                                                                         '2019', '2020'])\n",
    "# rename the column value to gdhi\n",
    "gdhi_df = gdhi_df.rename(columns={'value': 'gdhi'})\n",
    "gdhi_df.head()\n",
    "\n",
    "# COMBINED WITH POPULATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population data\n",
    "population_df = pd.read_csv('data/ukdetailedtimeseries2001to2020/MYEB1_detailed_population_estimates_series_UK_(2020_geog21).csv')\n",
    "# remove word \"population\" from column names\n",
    "population_df.columns = population_df.columns.str.replace('population_', '')\n",
    "\n",
    "# melt the dataframe\n",
    "population_df = pd.melt(population_df, id_vars=['ladcode21', 'laname21','country','sex','age'], var_name='Year', \n",
    "                        value_vars=['2001', '2002', '2003', '2004', '2005', '2006', '2007','2008', '2009', '2010', '2011', '2012', \n",
    "                                    '2013','2014', '2015', '2016', '2017', '2018', '2019', '2020'])\n",
    "# rename the column value to population\n",
    "population_df = population_df.rename(columns={'value': 'population'})\n",
    "\n",
    "# remove ladcode21 column\n",
    "population_df = population_df.drop(['ladcode21','country'], axis=1)\n",
    "\n",
    "# COMBINED WITH GDHI DATA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the values in laname21 column to match the values in gdhi data \"Region name\" columns\n",
    "# change Barking and Dagenham to \"Barking & Dagenham and Havering\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Barking and Dagenham', 'Havering'], 'Barking & Dagenham and Havering')\n",
    "# change \"Angus\" to \"Angus and Dundee City\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Angus', 'Dundee City'], 'Angus and Dundee City')\n",
    "# change Maldon to Heart of Essex\n",
    "population_df.loc[population_df['laname21'].str.contains('Maldon', case=False, na=False), 'laname21'] = 'Heart of Essex'\n",
    "# change the values in laname21 column to match the values in gdhi data \"Region name\" columns\n",
    "# change \"Hartlepool\" to \"Durham CC\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hartlepool'], 'Hartlepool and Stockton-on-Tees')\n",
    "# change \"Aberdeen City\" to \"Aberdeen City and Aberdeenshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Aberdeen City'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Aberdeenshire\" to \"Aberdeen City and Aberdeenshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Aberdeenshire'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Adur\" to \"West Sussex (South West)\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Worthing', 'Adur', 'Arun', 'Chichester', 'Horsham', 'Mid Sussex'], 'West Sussex (South West)')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Allerdale', 'Barrow-in-Furness', 'Carlisle', 'Copeland'], 'West Cumbria')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Eden', 'South Lakeland'], 'East Cumbria')\n",
    "# change \"Argyll and Bute\" to \"Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Argyll and Bute','Argyl and Bute'], 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute')\n",
    "# change Ashfield to \"North Nottinghamshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Ashfield', 'Bassetlaw', 'Bolsover', 'Gedling'], 'North Nottinghamshire')\n",
    "# change Babergh to \"Suffolk\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Babergh', 'East Suffolk', 'Ipswich', 'Mid Suffolk', 'West Suffolk'], 'Suffolk')\n",
    "# change Barnsley to \"Barnsley, Doncaster and Rotherham\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Barnsley', 'Doncaster', 'Rotherham'], 'Barnsley, Doncaster and Rotherham')\n",
    "# change Basildon to \"Thurrock\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Basildon'], 'Thurrock')\n",
    "# change Basingstoke and Deane to \"North Hampshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Basingstoke and Deane', 'Hart', 'Rushmoor'], 'North Hampshire')\n",
    "# change Bath and North East Somerset to \"Bath and North East Somerset, North Somerset and South Gloucestershire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bath and North East Somerset', 'North Somerset', 'South Gloucestershire'], 'Bath and North East Somerset, North Somerset and South Gloucestershire')\n",
    "# change Bexley to \"Bexley and Greenwich\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bexley', 'Greenwich'], 'Bexley and Greenwich')\n",
    "# change Blaby to \"Leicestershire CC and Rutland\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Blaby', 'Charnwood', 'Harborough', 'Hinckley and Bosworth', 'Melton', 'North West Leicestershire', 'Oadby and Wigston', 'Rutland'], 'Leicestershire CC and Rutland')\n",
    "# change Blaenau Gwent to \"Gwent Valleys\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Blaenau Gwent', 'Torfaen'], 'Gwent Valleys')\n",
    "# change Bolton to \"Greater Manchester North West\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bolton', 'Bury'], 'Greater Manchester North West')\n",
    "# change Boston to \"Lincolnshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Boston', 'North Kesteven', 'West Lindsey', 'South Kesteven', 'South Holland'], 'Lincolnshire')\n",
    "# change Bracknell Forest to \"Berkshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bracknell Forest', 'Reading', 'Slough', 'West Berkshire', 'Windsor and Maidenhead', 'Wokingham'], 'Berkshire')\n",
    "# change Braintree to \"Essex Haven Gateway\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Braintree', 'Brentwood', 'Castle Point', 'Colchester', 'Chelmsford', 'Rochford'], 'Essex Haven Gateway')\n",
    "# change Breckland to \"Breckland and South Norfolk\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Breckland', 'Broadland', 'Great Yarmouth', 'South Norfolk'], 'Breckland and South Norfolk')\n",
    "# change Bridgend to \"Bridgend and Neath Port Talbot\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bridgend', 'Merthyr Tydfil', 'Neath Port Talbot', 'Rhondda Cynon Taf'], 'Bridgend and Neath Port Talbot')\n",
    "#  change Bromsgrove to \"Worcestershire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Bromsgrove', 'Malvern Hills', 'Redditch', 'Worcester', 'Wychavon'], 'Worcestershire')\n",
    "# change Broxbourne to \"Hertfordshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Watford', 'Stevenage', 'St Albans', 'Three Rivers', 'Welwyn Hatfield', 'North Hertfordshire', 'Broxbourne', 'East Hertfordshire', 'Dacorum', 'Hertsmere'], 'Hertfordshire')\n",
    "# change Broxtowe to \"South and West Derbyshire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Broxtowe', 'Amber Valley', 'Derbyshire Dales', 'Erewash', 'South Derbyshire'], 'South and West Derbyshire')\n",
    "# change Buckinghamshire to \"Buckinghamshire CC\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Buckinghamshire'], 'Buckinghamshire CC')\n",
    "# change Burnley to \"East Lancashire\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Burnley', 'Hyndburn', 'Pendle', 'Ribble Valley', 'Rossendale'], 'East Lancashire')\n",
    "# change Caerphilly to \"Cardiff and Vale of Glamorgan\"\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Caerphilly', 'Cardiff', 'Vale of Glamorgan'], 'Cardiff and Vale of Glamorgan')\n",
    "# change Cambridge to Cambridgeshire CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Cambridge', 'East Cambridgeshire', 'Fenland', 'Huntingdonshire', 'South Cambridgeshire', 'Cambridgeshire'], 'Cambridgeshire CC')\n",
    "# change Cannock Chase to Staffordshire CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Newcastle-under-Lyme', 'Cannock Chase', 'East Staffordshire', 'Lichfield', 'South Staffordshire', 'Tamworth', 'Staffordshire Moorlands', 'Stafford'], 'Staffordshire CC')\n",
    "# change Carmarthenshire to South West Wales\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Carmarthenshire', 'Pembrokeshire'], 'South West Wales')\n",
    "# change Ceredigion to Central Valleys\n",
    "population_df.loc[population_df['laname21'].str.contains('Ceredigion', case=False, na=False), 'laname21'] = 'Central Valleys'\n",
    "# change Cherwell to Oxfordshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Cherwell', 'Oxford', 'South Oxfordshire', 'Vale of White Horse', 'West Oxfordshire'], 'Oxfordshire')\n",
    "# change Chesterfield to East Derbyshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Chesterfield', 'North East Derbyshire', 'High Peak'], 'East Derbyshire')\n",
    "# change Chorley to Chorley and West Lancashire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Chorley', 'Fylde', 'South Ribble', 'West Lancashire'], 'Chorley and West Lancashire')\n",
    "# change City of London to Camden and City of London\n",
    "population_df['laname21'] = population_df['laname21'].replace(['City of London', 'Camden'], 'Camden and City of London')\n",
    "# change Clackmannanshire to Clackmannanshire and Fife\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Clackmannanshire', 'Fife'], 'Clackmannanshire and Fife')\n",
    "# change Conwy to Conwy and Denbighshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Conwy', 'Denbighshire'], 'Conwy and Denbighshire')\n",
    "# change Cornwall to Cornwall and Isles of Scilly\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Cornwall', 'Isles of Scilly'], 'Cornwall and Isles of Scilly')\n",
    "# change County Durham to Durham CC\n",
    "population_df.loc[population_df['laname21'].str.contains('County Durham', case=False, na=False), 'laname21'] = 'Durham CC'\n",
    "# change Crawley to West Sussex\n",
    "population_df.loc[population_df['laname21'].str.contains('Crawley', case=False, na=False), 'laname21'] = 'West Sussex (North East)'\n",
    "# change East Ayrshire to East Ayrshire and North Ayrshire mainland\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Ayrshire', 'North Ayrshire'], 'East Ayrshire and North Ayrshire mainland')\n",
    "# change East Devon to Devon CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Devon', 'Exeter', 'Mid Devon', 'North Devon', 'South Hams', 'Teignbridge', 'Torridge', 'West Devon'], 'Devon CC')\n",
    "# change East Dunbartonshire to East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Dunbartonshire', 'West dunbartonshire', 'West Dunbartonshire'], 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond')\n",
    "# change East Hampshire to Central Hampshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Hampshire', 'Eastleigh', 'New Forest'], 'Central Hampshire')\n",
    "# change East Lothian to East Lothian and Midlothian\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Lothian', 'Midlothian'], 'East Lothian and Midlothian')\n",
    "# change East Renfrewshire to Inverclyde, East Renfrewshire and Renfrewshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['East Renfrewshire', 'Inverclyde', 'Renfrewshire'], 'Inverclyde, East Renfrewshire and Renfrewshire')\n",
    "# change Eastbourne to East Sussex\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Eastbourne', 'East Sussex'])\n",
    "# change Elmbridge to West Surrey\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Elmbridge', 'Epsom and Ewell', 'Guildford', 'Runnymede', 'Spelthorne', 'Woking', 'Waverley', 'Surrey Heath'], 'West Surrey')\n",
    "# change Fareham to South Hampshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Fareham', 'Gosport', 'Havant'], 'South Hampshire')\n",
    "# change Flintshire to Flintshire and Wrexham\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Flintshire', 'Wrexham'], 'Flintshire and Wrexham')\n",
    "# change Folkestone and Hythe to East Kent\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Folkestone and Hythe', 'Dover', 'Ashford', 'Canterbury'], 'East Kent')\n",
    "# change Forest of Dean to Gloucestershire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Gloucester', 'Forest of Dean', 'Cotswold', 'Cheltenham', 'Stroud', 'Tewkesbury'], 'Gloucestershire')\n",
    "# change Gateshead to Tyneside\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Newcastle upon Tyne', 'Gateshead', 'North Tyneside', 'South Tyneside'], 'Tyneside')\n",
    "# change Hackney to Hackney and Newham\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hackney', 'Newham'], 'Hackney and Newham')\n",
    "# change Hammersmith and Fulham to Kensington & Chelsea and Hammersmith & Fulham\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hammersmith and Fulham', 'Kensington and Chelsea'], 'Kensington & Chelsea and Hammersmith & Fulham')\n",
    "# change Harlow to Essex Thames Gateway\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Harlow', 'Epping Forest'], 'Essex Thames Gateway')\n",
    "# change Harrow to Harrow and Hillingdon\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Harrow', 'Hillingdon'], 'Harrow and Hillingdon')\n",
    "# change Haringey to Haringey and Islington\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Haringey', 'Islington'], 'Haringey and Islington')\n",
    "# change Hastings to East Sussex CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hastings', 'Lewes', 'Rother', 'Wealden'], 'East Sussex CC')\n",
    "# change Highland to Highlands and Islands\n",
    "population_df.loc[population_df['laname21'].str.contains('Highland', case=False, na=False), 'laname21'] = 'Caithness and Sutherland and Ross and Cromarty'\n",
    "# change Hounslow to Hounslow and Richmond upon Thames\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Hounslow', 'Richmond upon Thames'], 'Hounslow and Richmond upon Thames')\n",
    "# change King's Lynn and West Norfolk to North and West Norfolk\n",
    "population_df['laname21'] = population_df['laname21'].replace([\"King's Lynn and West Norfolk\", 'North Norfolk'], 'North and West Norfolk')\n",
    "# change Kingston upon Thames to Merton, Kingston upon Thames and Sutton\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Kingston upon Thames', 'Merton', 'Sutton'], 'Merton, Kingston upon Thames and Sutton')\n",
    "# change Kirklees to Calderdale and Kirklees\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Kirklees', 'Calderdale'], 'Calderdale and Kirklees')\n",
    "# change Knowsley to East Merseyside\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Knowsley', 'St. Helens'], 'East Merseyside')\n",
    "# change Lancaster to Lancaster and Wyre\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Lancaster', 'Wyre', 'Wyre Forest'], 'Lancaster and Wyre')\n",
    "# change Lewisham to Lewisham and Southwark\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Lewisham', 'Southwark'], 'Lewisham and Southwark')\n",
    "# change Lincoln to North and North East Lincolnshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Lincoln', 'North East Lincolnshire', 'North Lincolnshire', 'East Lindsey'], 'North and North East Lincolnshire')\n",
    "# change Maidstone to Medway\n",
    "population_df['laname21'] = population_df['laname21'].replace('Maidstone', 'Medway')\n",
    "# change Mansfield to Nottingham\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Mansfield', 'Newark and Sherwood'], 'Nottingham')\n",
    "# change Mendip to Somerset\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Mendip', 'South Somerset', 'Somerset West and Taunton', 'Sedgemoor'], 'Somerset')\n",
    "# change Mole Valley to East Surrey\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Mole Valley', 'Reigate and Banstead', 'Tandridge'], 'East Surrey')\n",
    "# change Monmouthshire to Monmouthshire and Newport\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Monmouthshire', 'Newport'], 'Monmouthshire and Newport')\n",
    "# change Moray to Inverness and Nairn and Moray, Badenoch and Strathspey\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Inverness-Shire','Moray'], 'Inverness and Nairn and Moray, Badenoch and Strathspey')\n",
    "# change North Warwickshire to Warwickshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Warwick', 'North Warwickshire', 'Nuneaton and Bedworth', 'Rugby', 'Stratford-on-Avon'], 'Warwickshire')\n",
    "# change Norwich to Norwich and East Norfolk\n",
    "population_df.loc[population_df['laname21'].str.contains('Norwich', case=False, na=False), 'laname21'] = 'Norwich and East Norfolk'\n",
    "# change Oldham to Greater Manchester North East\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Oldham', 'Rochdale', 'Salford'], 'Greater Manchester North East')\n",
    "# change Perth and Kinross to Perth and Kinross and Stirling\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Perth and Kinross', 'Stirling'], 'Perth and Kinross and Stirling')\n",
    "# change preston to Mid Lancashire\n",
    "population_df.loc[population_df['laname21'].str.contains('Preston', case=False, na=False), 'laname21'] = 'Mid Lancashire'\n",
    "# change 'Redcar and Cleveland' to South Teesside\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Redcar and Cleveland'], 'South Teesside')\n",
    "# change Redcar and Cleveland to North Yorkshire CC\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Richmondshire', 'Middlesbrough', 'Hambleton', 'Harrogate', 'Ryedale', 'Scarborough', 'Selby', 'Craven'], 'North Yorkshire CC')\n",
    "# change Redbridge to Redbridge and Waltham Forest\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Redbridge', 'Waltham Forest'], 'Redbridge and Waltham Forest')\n",
    "# change Rushcliffe to Nottinghamshire\n",
    "population_df.loc[population_df['laname21'].str.contains('Rushcliffe', case=False, na=False), 'laname21'] = 'South Nottinghamshire'\n",
    "# change Shropshire to Shropshire CC\n",
    "population_df.loc[population_df['laname21'].str.contains('Shropshire', case=False, na=False), 'laname21'] = 'Shropshire CC'\n",
    "# change Stockport to Greater Manchester South East\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Stockport', 'Tameside', 'Wigan'], 'Greater Manchester South East')\n",
    "# change 'Trafford' to Greater Manchester South West\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Trafford'], 'Greater Manchester South West')\n",
    "# change Stockton-on-Tees to Hartlepool and Stockton-on-Tees\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Stockton-on-Tees', 'Hartlepool and Stockton-on-Tees'])\n",
    "# change Tendring to Essex\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Tendring', 'Uttlesford'], 'West Essex')\n",
    "# change Test Valley to Central Hampshire\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Test Valley'], 'Central Hampshire')\n",
    "# change Winchester to Portsmouth\n",
    "population_df.loc[population_df['laname21'].str.contains('Winchester', case=False, na=False), 'laname21'] = 'Portsmouth'\n",
    "# 'Tonbridge and Malling' to west Kent\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Tonbridge and Malling', 'Tunbridge Wells', 'Sevenoaks'], 'West Kent')\n",
    "# change Tunbridge Wells to Kent Thames Gateway\n",
    "population_df['laname21'] = population_df['laname21'].replace(['Thanet', 'Swale', 'Gravesham', 'Dartford'], 'Kent Thames Gateway')\n",
    "\n",
    "# group the population data by year, laname21, sex and age and sum the population\n",
    "population_df = population_df.groupby(['Year', 'laname21', 'sex', 'age'])['population'].sum().reset_index()\n",
    "\n",
    "# check if population data and gdhi data have the same laname21 and Region name and save as text file\n",
    "set_pop = set(gdhi_df['Region name'].unique()) - set(population_df['laname21'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>ITL level</th>\n",
       "      <th>ITL code</th>\n",
       "      <th>Year</th>\n",
       "      <th>gdhi</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "      <th>ITL level 1</th>\n",
       "      <th>ITL level 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2267</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2373</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2445</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2481</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2001</td>\n",
       "      <td>12622.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2569</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ITL level 3 ITL level ITL code  Year     gdhi  sex  \\\n",
       "0  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "1  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "2  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "3  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "4  Aberdeen City and Aberdeenshire      ITL3    TLM50  2001  12622.0    1   \n",
       "\n",
       "   age  population ITL level 1             ITL level 2  \n",
       "0    0        2267    Scotland  North Eastern Scotland  \n",
       "1    1        2373    Scotland  North Eastern Scotland  \n",
       "2    2        2445    Scotland  North Eastern Scotland  \n",
       "3    3        2481    Scotland  North Eastern Scotland  \n",
       "4    4        2569    Scotland  North Eastern Scotland  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the dataframes gdhi_df and population_df on laname21 and Year\n",
    "gdhi_population_df = gdhi_df.merge(population_df, how='right', left_on=['Region name', 'Year'], right_on=['laname21', 'Year'])\n",
    "gdhi_population_df\n",
    "\n",
    "# rename Region name to ITL level 3\n",
    "gdhi_population_df = gdhi_population_df.rename(columns={'Region name': 'ITL level 3'})\n",
    "\n",
    "# drop laname21 column\n",
    "gdhi_population_df = gdhi_population_df.drop(['laname21'], axis=1)\n",
    "\n",
    "# remove all rows with ITL2\n",
    "gdhi_population_df = gdhi_population_df[gdhi_population_df['ITL level'] == 'ITL3']\n",
    "\n",
    "# Create a new column ITL level 1 such that it is the first 3 letters of ITL code are TLC then value is North East, \n",
    "# if TLD then value is North West, \n",
    "# if TLE then value is Yorkshire and The Humber, \n",
    "# if TLF then value is East Midlands, \n",
    "# if TLG then value is West Midlands, \n",
    "# if TLH then value is East of England, \n",
    "# if TLI then value is London, \n",
    "# if TLJ then value is South East, \n",
    "# if TLK then value is South West, \n",
    "# if TLM then value is Wales, \n",
    "# if TLN then value is Scotland, \n",
    "# if TLP then value is Northern Ireland\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL code'].str[:3]\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLC'], 'North East')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLD'], 'North West')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLE'], 'Yorkshire and The Humber')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLF'], 'East Midlands')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLG'], 'West Midlands')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLH'], 'East of England')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLI'], 'London')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLJ'], 'South East')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLK'], 'South West')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLL'], 'Wales')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLM'], 'Scotland')\n",
    "gdhi_population_df['ITL level 1'] = gdhi_population_df['ITL level 1'].replace(['TLN'], 'Northern Ireland')\n",
    "\n",
    "# create a new column ITL level 2 such that it is the first 4 letters of ITL code are TLC1 then value is Tees Valley and Durham,\n",
    "# if TLC2 then value is Northumberland and Tyne and Wear,\n",
    "# if TLD1 then value is Cumbria,\n",
    "# if TLD3 then value is Greater Manchester,\n",
    "# if TLD4 then value is Lancashire,\n",
    "# if TLD6 then value is Cheshire,\n",
    "# if TLD7 then value is Merseyside,\n",
    "# if TLE1 then value is East Yorkshire and Northern Lincolnshire,\n",
    "# if TLE2 then value is North Yorkshire,\n",
    "# if TLE3 then value is South Yorkshire,\n",
    "# if TLE4 then value is West Yorkshire,\n",
    "# if TLF1 then value is Derbyshire and Nottinghamshire,\n",
    "# if TLF2 then value is Leicestershire, Rutland and Northamptonshire,\n",
    "# if TLF3 then value is Lincolnshire,\n",
    "# if TLG1 then value is Herefordshire, Worcestershire and Warwickshire,\n",
    "# if TLG2 then value is Shropshire and Staffordshire,\n",
    "# if TLG3 then value is West Midlands,\n",
    "# if TLH1 then value is East Anglia,\n",
    "# if TLH2 then value is Bedfordshire and Hertfordshire,\n",
    "# if TLH3 then value is Essex,\n",
    "# if TLI3 then value is Inner London - West,\n",
    "# if TLI4 then value is Inner London - East,\n",
    "# if TLI5 then value is Outer London - East and North East,\n",
    "# if TLI6 then value is Outer London - South,\n",
    "# if TLI7 then value is Outer London - West and North West,\n",
    "# if TLJ1 then value is Berkshire, Buckinghamshire and Oxfordshire,\n",
    "# if TLJ2 then value is Surrey, East and West Sussex,\n",
    "# if TLJ3 then value is Hampshire and Isle of Wight,\n",
    "# if TLJ4 then value is Kent,\n",
    "# if TLK1 then value is Gloucestershire, Wiltshire and Bristol/Bath area,\n",
    "# if TLK2 then value is Dorset and Somerset,\n",
    "# if TLK3 then value is Cornwall and Isles of Scilly,\n",
    "# if TLK4 then value is Devon,\n",
    "# if TLL1 then value is West Wales and The Valleys,\n",
    "# if TLL2 then value is East Wales,\n",
    "# if TLM5 then value is North Eastern Scotland,\n",
    "# if TLM6 then value is Highlands and Islands,\n",
    "# if TLM7 then value is Eastern Scotland,\n",
    "# if TLM8 then value is West Central Scotland,\n",
    "# if TLM9 then value is Southern Scotland,\n",
    "# if TLN0 then value is Northern Ireland\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL code'].str[:4]\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLC1'], 'Tees Valley and Durham')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLC2'], 'Northumberland and Tyne and Wear')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD1'], 'Cumbria')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD3'], 'Greater Manchester')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD4'], 'Lancashire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD6'], 'Cheshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLD7'], 'Merseyside')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLE1'], 'East Yorkshire and Northern Lincolnshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLE2'], 'North Yorkshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLE3'], 'South Yorkshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLE4'], 'West Yorkshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLF1'], 'Derbyshire and Nottinghamshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLF2'], 'Leicestershire, Rutland and Northamptonshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLF3'], 'Lincolnshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLG1'], 'Herefordshire, Worcestershire and Warwickshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLG2'], 'Shropshire and Staffordshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLG3'], 'West Midlands')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLH1'], 'East Anglia')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLH2'], 'Bedfordshire and Hertfordshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLH3'], 'Essex')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI3'], 'Inner London - West')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI4'], 'Inner London - East')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI5'], 'Outer London - East and North East')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI6'], 'Outer London - South')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLI7'], 'Outer London - West and North West')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLJ1'], 'Berkshire, Buckinghamshire and Oxfordshire')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLJ2'], 'Surrey, East and West Sussex')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLJ3'], 'Hampshire and Isle of Wight')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLJ4'], 'Kent')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLK1'], 'Gloucestershire, Wiltshire and Bristol/Bath area')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLK2'], 'Dorset and Somerset')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLK3'], 'Cornwall and Isles of Scilly')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLK4'], 'Devon')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLL1'], 'West Wales and The Valleys')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLL2'], 'East Wales')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM5'], 'North Eastern Scotland')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM6'], 'Highlands and Islands')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM7'], 'Eastern Scotland')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM8'], 'West Central Scotland')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLM9'], 'Southern Scotland')\n",
    "gdhi_population_df['ITL level 2'] = gdhi_population_df['ITL level 2'].replace(['TLN0'], 'Northern Ireland')\n",
    "\n",
    "\n",
    "gdhi_population_df.head()\n",
    "\n",
    "# COMBINED GDHI AND POPULATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scotland', 'Northern Ireland', 'London',\n",
       "       'Yorkshire and The Humber', 'South West', 'East of England',\n",
       "       'South East', 'West Midlands', 'North West', 'Wales', 'North East',\n",
       "       'East Midlands'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show unique values in ITL level 1\n",
    "gdhi_population_df['ITL level 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Units</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>ONS Sort</th>\n",
       "      <th>ONS Code</th>\n",
       "      <th>ONS Geography</th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>1.0</td>\n",
       "      <td>K02000001</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>110.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>2.0</td>\n",
       "      <td>K03000001</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>106.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>3.0</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>90.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>4.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Company</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>2022 Q4</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Units           BodyType    Fuel Keepership ONS Sort   ONS Code  \\\n",
       "0  Thousands  Buses and coaches  Diesel    Company      1.0  K02000001   \n",
       "1  Thousands  Buses and coaches  Diesel    Company      2.0  K03000001   \n",
       "2  Thousands  Buses and coaches  Diesel    Company      3.0  E92000001   \n",
       "3  Thousands  Buses and coaches  Diesel    Company      4.0  E12000001   \n",
       "4  Thousands  Buses and coaches  Diesel    Company      5.0  E06000047   \n",
       "\n",
       "      ONS Geography     Year Number of vehicles  \n",
       "0    United Kingdom  2022 Q4            110.929  \n",
       "1     Great Britain  2022 Q4            106.768  \n",
       "2           England  2022 Q4              90.01  \n",
       "3        North East  2022 Q4              4.103  \n",
       "4     County Durham  2022 Q4              0.608  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/veh0105.ods\"\n",
    "\n",
    "# load a sheet based on its index (1 based)\n",
    "sheet_idx = 4\n",
    "vehicle_fuel_df = read_ods(path, sheet_idx)\n",
    "\n",
    "# make third row the header\n",
    "vehicle_fuel_df.columns = vehicle_fuel_df.iloc[3]\n",
    "# drop first 4 rows\n",
    "vehicle_fuel_df = vehicle_fuel_df.iloc[4:]\n",
    "vehicle_fuel_df.head()\n",
    "\n",
    "# renumber index\n",
    "vehicle_fuel_df = vehicle_fuel_df.reset_index(drop=True)\n",
    "\n",
    "# melt the dataframe\n",
    "vehicle_fuel_df = pd.melt(vehicle_fuel_df, id_vars=['Units', 'BodyType', 'Fuel [note 2]', 'Keepership [note 3]', 'ONS Sort [note 6]', \n",
    "                                                    'ONS Code [note 6]', 'ONS Geography [note 6]'], var_name='Year', \n",
    "                                                    value_vars = ['2022 Q4', '2022 Q3', '2022 Q2', '2022 Q1', '2021 Q4', '2021 Q3', \n",
    "                                                                  '2021 Q2', '2021 Q1', '2020 Q4', '2020 Q3', '2020 Q2', '2020 Q1', \n",
    "                                                                  '2019 Q4', '2019 Q3', '2019 Q2', '2019 Q1', '2018 Q4', '2018 Q3', \n",
    "                                                                  '2018 Q2', '2018 Q1', '2017 Q4', '2017 Q3', '2017 Q2', '2017 Q1', \n",
    "                                                                  '2016 Q4', '2016 Q3', '2016 Q2', '2016 Q1', '2015 Q4', '2015 Q3', \n",
    "                                                                  '2015 Q2', '2015 Q1', '2014 Q4', '2014 Q3', '2014 Q2', '2014 Q1', \n",
    "                                                                  '2013 Q4', '2013 Q3', '2013 Q2', '2013 Q1', '2012 Q4', '2012 Q3', \n",
    "                                                                  '2012 Q2', '2012 Q1', '2011 Q4', '2011 Q3', '2011 Q2', '2011 Q1', \n",
    "                                                                  '2010 Q4', '2010 Q3', '2010 Q2', '2010 Q1', '2009 Q4'])\n",
    "# rename the column value to number of vehicles\n",
    "vehicle_fuel_df = vehicle_fuel_df.rename(columns={'value': 'Number of vehicles'})\n",
    "# rename the columns to remove the square brackets\n",
    "vehicle_fuel_df = vehicle_fuel_df.rename(columns={'Fuel [note 2]': 'Fuel', 'Keepership [note 3]': 'Keepership',\n",
    "                                                    'ONS Sort [note 6]': 'ONS Sort', 'ONS Code [note 6]': 'ONS Code',\n",
    "                                                    'ONS Geography [note 6]': 'ONS Geography'})\n",
    "vehicle_fuel_df.head()\n",
    "\n",
    "# COMBINED WITH ELECTRIC VEHICLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Units</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>ONS Sort</th>\n",
       "      <th>ONS Code</th>\n",
       "      <th>ONS Geography</th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>1.0</td>\n",
       "      <td>K02000001</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>1808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>2.0</td>\n",
       "      <td>K03000001</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>1702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>3.0</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>1343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>2022 Q3</td>\n",
       "      <td>[c]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Units           BodyType              Fuel Keepership ONS Sort   ONS Code  \\\n",
       "0  Number  Buses and coaches  Battery electric    Company      1.0  K02000001   \n",
       "1  Number  Buses and coaches  Battery electric    Company      2.0  K03000001   \n",
       "2  Number  Buses and coaches  Battery electric    Company      3.0  E92000001   \n",
       "3  Number  Buses and coaches  Battery electric    Company      4.0  E12000001   \n",
       "4  Number  Buses and coaches  Battery electric    Company      5.0  E06000047   \n",
       "\n",
       "      ONS Geography     Year Number of vehicles  \n",
       "0    United Kingdom  2022 Q3             1808.0  \n",
       "1     Great Britain  2022 Q3             1702.0  \n",
       "2           England  2022 Q3             1343.0  \n",
       "3        North East  2022 Q3               21.0  \n",
       "4     County Durham  2022 Q3                [c]  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/veh0142.ods\"\n",
    "\n",
    "# load a sheet based on its index (1 based)\n",
    "sheet_idx = 4\n",
    "vehicle_electricity_df = read_ods(path, sheet_idx)\n",
    "\n",
    "# make third row the header\n",
    "vehicle_electricity_df.columns = vehicle_electricity_df.iloc[3]\n",
    "# drop first 4 rows\n",
    "vehicle_electricity_df = vehicle_electricity_df.iloc[4:]\n",
    "vehicle_electricity_df.head()\n",
    "\n",
    "# renumber index\n",
    "vehicle_electricity_df = vehicle_electricity_df.reset_index(drop=True)\n",
    "# melt the dataframe\n",
    "vehicle_electricity_df = pd.melt(vehicle_electricity_df, id_vars=['Units', 'BodyType', 'Fuel', 'Keepership [note 3]', \n",
    "                                                                  'ONS Sort [note 6]', 'ONS Code [note 6]', 'ONS Geography [note 6]'], \n",
    "                                                                  var_name='Year', \n",
    "                                                                  value_vars = ['2022 Q3', '2022 Q2', '2022 Q1', '2021 Q4', '2021 Q3', \n",
    "                                                                                '2021 Q2', '2021 Q1', '2020 Q4', '2020 Q3', '2020 Q2',\n",
    "                                                                                '2020 Q1', '2019 Q4', '2019 Q3', '2019 Q2', '2019 Q1', \n",
    "                                                                                '2018 Q4', '2018 Q3', '2018 Q2', '2018 Q1', '2017 Q4', \n",
    "                                                                                '2017 Q3', '2017 Q2', '2017 Q1', '2016 Q4', '2016 Q3', \n",
    "                                                                                '2016 Q2', '2016 Q1', '2015 Q4', '2015 Q3', '2015 Q2', \n",
    "                                                                                '2015 Q1', '2014 Q4', '2014 Q3', '2014 Q2', '2014 Q1', \n",
    "                                                                                '2013 Q4', '2013 Q3', '2013 Q2', '2013 Q1', '2012 Q4', \n",
    "                                                                                '2012 Q3', '2012 Q2', '2012 Q1', '2011 Q4', '2011 Q3', \n",
    "                                                                                '2011 Q2', '2011 Q1', '2010 Q4', '2010 Q3', '2010 Q2', \n",
    "                                                                                '2010 Q1', '2009 Q4'])\n",
    "# rename the column value to \"Number of vehicles\"\n",
    "vehicle_electricity_df = vehicle_electricity_df.rename(columns={'value': 'Number of vehicles'})\n",
    "# rename the columns to remove the square brackets\n",
    "vehicle_electricity_df = vehicle_electricity_df.rename(columns={'Keepership [note 3]': 'Keepership',\n",
    "                                                                'ONS Sort [note 6]': 'ONS Sort',\n",
    "                                                                'ONS Code [note 6]': 'ONS Code',\n",
    "                                                                'ONS Geography [note 6]': 'ONS Geography'})\n",
    "vehicle_electricity_df.head()\n",
    "\n",
    "# COMBINED WITH OTHER VEHICLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Units</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>ONS Sort</th>\n",
       "      <th>ONS Code</th>\n",
       "      <th>ONS Geography</th>\n",
       "      <th>Number of vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>1.0</td>\n",
       "      <td>K02000001</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>2.0</td>\n",
       "      <td>K03000001</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>3.0</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299769</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>462.0</td>\n",
       "      <td>N09000010</td>\n",
       "      <td>Newry, Mourne and Down</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299770</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>463.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Local Authority unknown within Northern Ire...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299771</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>464.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Vehicle under disposal, previously GB</td>\n",
       "      <td>2914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299772</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>465.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Vehicle under disposal, previously NI</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299773</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>466.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Region or county unknown</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1299774 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year      Units           BodyType              Fuel Keepership  \\\n",
       "0        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "1        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "2        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "3        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "4        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "...       ...        ...                ...               ...        ...   \n",
       "1299769  2022  Thousands              Total             Total      Total   \n",
       "1299770  2022  Thousands              Total             Total      Total   \n",
       "1299771  2022  Thousands              Total             Total      Total   \n",
       "1299772  2022  Thousands              Total             Total      Total   \n",
       "1299773  2022  Thousands              Total             Total      Total   \n",
       "\n",
       "         ONS Sort   ONS Code  \\\n",
       "0             1.0  K02000001   \n",
       "1             2.0  K03000001   \n",
       "2             3.0  E92000001   \n",
       "3             4.0  E12000001   \n",
       "4             5.0  E06000047   \n",
       "...           ...        ...   \n",
       "1299769     462.0  N09000010   \n",
       "1299770     463.0        [z]   \n",
       "1299771     464.0        [z]   \n",
       "1299772     465.0        [z]   \n",
       "1299773     466.0        [z]   \n",
       "\n",
       "                                             ONS Geography  Number of vehicles  \n",
       "0                                           United Kingdom                   0  \n",
       "1                                            Great Britain                  38  \n",
       "2                                                  England                  36  \n",
       "3                                               North East                   0  \n",
       "4                                            County Durham                   0  \n",
       "...                                                    ...                 ...  \n",
       "1299769                             Newry, Mourne and Down                 494  \n",
       "1299770     Local Authority unknown within Northern Ire...                  14  \n",
       "1299771              Vehicle under disposal, previously GB                2914  \n",
       "1299772              Vehicle under disposal, previously NI                  56  \n",
       "1299773                           Region or county unknown                  14  \n",
       "\n",
       "[1299774 rows x 9 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two vehicle dataframes\n",
    "vehicle_df = pd.concat([vehicle_fuel_df, vehicle_electricity_df])\n",
    "# remove last 3 characters from year column\n",
    "vehicle_df['Year'] = vehicle_df['Year'].str[:-3]\n",
    "# convert year column to integer\n",
    "vehicle_df['Year'] = vehicle_df['Year'].astype(int)\n",
    "# replace any text in number of vehicles column with 0\n",
    "vehicle_df['Number of vehicles'] = vehicle_df['Number of vehicles'].replace('[x]', 0)\n",
    "vehicle_df['Number of vehicles'] = vehicle_df['Number of vehicles'].replace('[c]', 0)\n",
    "# if number of vehicles is NaN or not a number, set to 0\n",
    "vehicle_df['Number of vehicles'] = vehicle_df['Number of vehicles'].fillna(0)\n",
    "# convert number of vehicles column to integer\n",
    "vehicle_df['Number of vehicles'] = vehicle_df['Number of vehicles'].astype(int)\n",
    "# aggregate the number of vehicles by year\n",
    "vehicle_df = vehicle_df.groupby(['Year', 'Units', 'BodyType', 'Fuel', 'Keepership', 'ONS Sort', 'ONS Code', 'ONS Geography']).agg({'Number of vehicles': 'sum'}).reset_index()\n",
    "vehicle_df\n",
    "\n",
    "# COMBINED DATAFRAME (VEHICLE AND EV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Units', 'BodyType', 'Fuel', 'Keepership', 'ONS Sort',\n",
       "       'ONS Code', 'ONS Geography', 'Number of vehicles'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique values in Fuel column\n",
    "vehicle_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Make</th>\n",
       "      <th>GenModel</th>\n",
       "      <th>Model</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Number of vehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>AIXAM</td>\n",
       "      <td>AIXAM MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>ALBION</td>\n",
       "      <td>ALBION MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>ALBION</td>\n",
       "      <td>ALBION MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>ALEXANDER DENNIS</td>\n",
       "      <td>ALEXANDER DENNIS MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994Q4</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>ALEXANDER DENNIS</td>\n",
       "      <td>ALEXANDER DENNIS MODEL MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year           BodyType              Make  \\\n",
       "0  1994Q4  Buses and coaches             AIXAM   \n",
       "1  1994Q4  Buses and coaches            ALBION   \n",
       "2  1994Q4  Buses and coaches            ALBION   \n",
       "3  1994Q4  Buses and coaches  ALEXANDER DENNIS   \n",
       "4  1994Q4  Buses and coaches  ALEXANDER DENNIS   \n",
       "\n",
       "                         GenModel    Model              Fuel  \\\n",
       "0             AIXAM MODEL MISSING  MISSING            Diesel   \n",
       "1            ALBION MODEL MISSING  MISSING            Diesel   \n",
       "2            ALBION MODEL MISSING  MISSING            Petrol   \n",
       "3  ALEXANDER DENNIS MODEL MISSING  MISSING  Battery electric   \n",
       "4  ALEXANDER DENNIS MODEL MISSING  MISSING            Diesel   \n",
       "\n",
       "   Number of vehicles  \n",
       "0                   0  \n",
       "1                  26  \n",
       "2                   7  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a sheet with car models bought and quarter they were purchased\n",
    "car_models_df = pd.read_csv('data/vehicle-licensing-statistics-2022-data-files/df_VEH0120_GB.csv')\n",
    "# melt the dataframe\n",
    "car_models_df = pd.melt(car_models_df, id_vars=['BodyType', 'Make', 'GenModel', 'Model', 'Fuel'], var_name='Year', \n",
    "                        value_vars = ['2022Q3', '2022Q2', '2022Q1', '2021Q4', '2021Q3', '2021Q2', '2021Q1', '2020Q4', '2020Q3',\n",
    "                                        '2020Q2', '2020Q1', '2019Q4', '2019Q3', '2019Q2', '2019Q1', '2018Q4', '2018Q3', '2018Q2',\n",
    "                                        '2018Q1', '2017Q4', '2017Q3', '2017Q2', '2017Q1', '2016Q4', '2016Q3', '2016Q2', '2016Q1',\n",
    "                                        '2015Q4', '2015Q3', '2015Q2', '2015Q1', '2014Q4', '2014Q3', '2014Q2', '2014Q1', '2013Q4',\n",
    "                                        '2013Q3', '2013Q2', '2013Q1', '2012Q4', '2012Q3', '2012Q2', '2012Q1', '2011Q4', '2011Q3',\n",
    "                                        '2011Q2', '2011Q1', '2010Q4', '2010Q3', '2010Q2', '2010Q1', '2009Q4', '2009Q3', '2009Q2',\n",
    "                                        '2009Q1', '2008Q4', '2008Q3', '2007Q4', '2006Q4', '2005Q4', '2004Q4', '2003Q4', '2002Q4', \n",
    "                                        '2001Q4', '2000Q4', '1999Q4', '1998Q4', '1997Q4', '1996Q4', '1995Q4', '1994Q4'])\n",
    "# aggregate the number of cars bought by year, make, genmodel, model, fuel and year\n",
    "# fill the NaN values with 0\n",
    "car_models_df['value'] = car_models_df['value'].fillna(0)\n",
    "car_models_df = car_models_df.groupby(['Year', 'BodyType', 'Make', 'GenModel', 'Model', 'Fuel']).agg({'value': 'sum'}).reset_index()\n",
    "# rename the column value to \"Number of vehicles\"\n",
    "car_models_df = car_models_df.rename(columns={'value': 'Number of vehicles'})\n",
    "car_models_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ULSP:  Pump price (p/litre)</th>\n",
       "      <th>ULSD: Pump price (p/litre)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>75.330148</td>\n",
       "      <td>77.139578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>80.254930</td>\n",
       "      <td>81.894003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>86.796860</td>\n",
       "      <td>90.820266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>91.395871</td>\n",
       "      <td>95.179094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>94.384374</td>\n",
       "      <td>96.984666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>107.001178</td>\n",
       "      <td>117.556702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>99.593804</td>\n",
       "      <td>104.146614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011</td>\n",
       "      <td>133.412774</td>\n",
       "      <td>138.805382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012</td>\n",
       "      <td>135.761462</td>\n",
       "      <td>142.171851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>134.312143</td>\n",
       "      <td>140.624926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>127.418609</td>\n",
       "      <td>133.474037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015</td>\n",
       "      <td>111.033772</td>\n",
       "      <td>114.996870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>108.949773</td>\n",
       "      <td>110.420045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>117.512806</td>\n",
       "      <td>120.206574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>125.001226</td>\n",
       "      <td>129.945303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>124.816777</td>\n",
       "      <td>131.664396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021</td>\n",
       "      <td>131.396517</td>\n",
       "      <td>135.037887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>164.641685</td>\n",
       "      <td>177.778373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>146.352737</td>\n",
       "      <td>162.737857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year   ULSP:  Pump price (p/litre)  ULSD: Pump price (p/litre)\n",
       "0   2003                     75.330148                   77.139578\n",
       "1   2004                     80.254930                   81.894003\n",
       "2   2005                     86.796860                   90.820266\n",
       "3   2006                     91.395871                   95.179094\n",
       "4   2007                     94.384374                   96.984666\n",
       "5   2008                    107.001178                  117.556702\n",
       "6   2009                     99.593804                  104.146614\n",
       "7   2010                    116.904146                  119.234615\n",
       "8   2011                    133.412774                  138.805382\n",
       "9   2012                    135.761462                  142.171851\n",
       "10  2013                    134.312143                  140.624926\n",
       "11  2014                    127.418609                  133.474037\n",
       "12  2015                    111.033772                  114.996870\n",
       "13  2016                    108.949773                  110.420045\n",
       "14  2017                    117.512806                  120.206574\n",
       "15  2018                    125.001226                  129.945303\n",
       "16  2019                    124.816777                  131.664396\n",
       "17  2020                    114.092268                  119.455858\n",
       "18  2021                    131.396517                  135.037887\n",
       "19  2022                    164.641685                  177.778373\n",
       "20  2023                    146.352737                  162.737857"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data with fuel prices\n",
    "fuel_prices_df = pd.read_excel('data/Weekly_Fuel_Prices_120623.xlsx', sheet_name='All years', skiprows=7)\n",
    "# keep columns 1, 2, 7\n",
    "fuel_prices_df = fuel_prices_df.iloc[:, [0, 1, 6]]\n",
    "# aggregate by quarter and get mean\n",
    "fuel_prices_df = fuel_prices_df.groupby(fuel_prices_df['Date'].dt.to_period(\"Q\")).mean()\n",
    "# aggregate by year and get mean\n",
    "fuel_prices_df = fuel_prices_df.groupby(fuel_prices_df.index.year).mean()\n",
    "# reset index\n",
    "fuel_prices_df = fuel_prices_df.reset_index()\n",
    "# rename column Date to Year\n",
    "fuel_prices_df = fuel_prices_df.rename(columns={'Date': 'Year'})\n",
    "fuel_prices_df\n",
    "\n",
    "# COMBINED WITH ELECTRICITY PRICES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['East Midlands', 'East of England', 'London', 'North East',\n",
       "       'North West', 'Northern Ireland', 'Scotland', 'South East',\n",
       "       'South West', 'Wales', 'West Midlands', 'Yorkshire and The Humber'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine electric and fuel prices dataframes by year and left join fuel to electric\n",
    "fuel_electric_prices_df = pd.merge(electricity_df, fuel_prices_df, on='Year', how='left')\n",
    "fuel_electric_prices_df\n",
    "\n",
    "# combine North Scotland and South Scotland into Scotland and rename\n",
    "fuel_electric_prices_df.loc[fuel_electric_prices_df['PES area'].str.contains('North Scotland', case=False, na=False), 'PES area'] = 'Scotland'\n",
    "fuel_electric_prices_df.loc[fuel_electric_prices_df['PES area'].str.contains('South Scotland', case=False, na=False), 'PES area'] = 'Scotland'\n",
    "# combine Merseyside & North Wales and South Wales into Wales and rename\n",
    "fuel_electric_prices_df.loc[fuel_electric_prices_df['PES area'].str.contains('Merseyside & North Wales', case=False, na=False), 'PES area'] = 'Wales'\n",
    "fuel_electric_prices_df.loc[fuel_electric_prices_df['PES area'].str.contains('South Wales', case=False, na=False), 'PES area'] = 'Wales'\n",
    "# replace Eastern with East of England\n",
    "fuel_electric_prices_df['PES area'] = fuel_electric_prices_df['PES area'].replace('Eastern', 'East of England')\n",
    "# replace Yorkshire with Yorkshire and The Humber\n",
    "fuel_electric_prices_df['PES area'] = fuel_electric_prices_df['PES area'].replace('Yorkshire', 'Yorkshire and The Humber')\n",
    "# drop rows with PES area as \"United Kingdom\" and \"Southern\"\n",
    "fuel_electric_prices_df = fuel_electric_prices_df[fuel_electric_prices_df['PES area'] != 'United Kingdom']\n",
    "fuel_electric_prices_df = fuel_electric_prices_df[fuel_electric_prices_df['PES area'] != 'Southern']\n",
    "\n",
    "# aggregate all the data by year and PES area and get the mean\n",
    "fuel_electric_prices_df = fuel_electric_prices_df.groupby(['Year', 'PES area']).mean().reset_index()\n",
    "\n",
    "# show unique values in PES Area column\n",
    "fuel_electric_prices_df['PES area'].unique()\n",
    "# COMBINED DATAFRAME (FUEL + ELECTRICITY PRICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>ITL level</th>\n",
       "      <th>ITL code</th>\n",
       "      <th>Year</th>\n",
       "      <th>gdhi</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "      <th>ITL level 1</th>\n",
       "      <th>ITL level 2</th>\n",
       "      <th>PES area</th>\n",
       "      <th>Average variable unit price (Â£/kWh)</th>\n",
       "      <th>ULSP:  Pump price (p/litre)</th>\n",
       "      <th>ULSD: Pump price (p/litre)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2762</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2741</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2596</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLM50</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2501</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354349</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>768</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354350</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>621</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354351</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>586</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354352</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>451</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354353</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>ITL3</td>\n",
       "      <td>TLF24</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2140</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354354 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ITL level 3 ITL level ITL code  Year     gdhi  \\\n",
       "0       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "1       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "2       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "3       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "4       Aberdeen City and Aberdeenshire      ITL3    TLM50  2010  18736.0   \n",
       "...                                 ...       ...      ...   ...      ...   \n",
       "354349            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "354350            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "354351            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "354352            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "354353            West Northamptonshire      ITL3    TLF24  2020  22354.0   \n",
       "\n",
       "        sex  age  population    ITL level 1  \\\n",
       "0         1    0        2801       Scotland   \n",
       "1         1    1        2762       Scotland   \n",
       "2         1    2        2741       Scotland   \n",
       "3         1    3        2596       Scotland   \n",
       "4         1    4        2501       Scotland   \n",
       "...     ...  ...         ...            ...   \n",
       "354349    2   86         768  East Midlands   \n",
       "354350    2   87         621  East Midlands   \n",
       "354351    2   88         586  East Midlands   \n",
       "354352    2   89         451  East Midlands   \n",
       "354353    2   90        2140  East Midlands   \n",
       "\n",
       "                                         ITL level 2       PES area  \\\n",
       "0                             North Eastern Scotland       Scotland   \n",
       "1                             North Eastern Scotland       Scotland   \n",
       "2                             North Eastern Scotland       Scotland   \n",
       "3                             North Eastern Scotland       Scotland   \n",
       "4                             North Eastern Scotland       Scotland   \n",
       "...                                              ...            ...   \n",
       "354349  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "354350  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "354351  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "354352  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "354353  Leicestershire, Rutland and Northamptonshire  East Midlands   \n",
       "\n",
       "        Average variable unit price (Â£/kWh)   ULSP:  Pump price (p/litre)  \\\n",
       "0                                  0.117261                    116.904146   \n",
       "1                                  0.117261                    116.904146   \n",
       "2                                  0.117261                    116.904146   \n",
       "3                                  0.117261                    116.904146   \n",
       "4                                  0.117261                    116.904146   \n",
       "...                                     ...                           ...   \n",
       "354349                             0.166876                    114.092268   \n",
       "354350                             0.166876                    114.092268   \n",
       "354351                             0.166876                    114.092268   \n",
       "354352                             0.166876                    114.092268   \n",
       "354353                             0.166876                    114.092268   \n",
       "\n",
       "        ULSD: Pump price (p/litre)  \n",
       "0                       119.234615  \n",
       "1                       119.234615  \n",
       "2                       119.234615  \n",
       "3                       119.234615  \n",
       "4                       119.234615  \n",
       "...                            ...  \n",
       "354349                  119.455858  \n",
       "354350                  119.455858  \n",
       "354351                  119.455858  \n",
       "354352                  119.455858  \n",
       "354353                  119.455858  \n",
       "\n",
       "[354354 rows x 14 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set Year to integer\n",
    "fuel_electric_prices_df['Year'] = fuel_electric_prices_df['Year'].astype(int)\n",
    "gdhi_population_df['Year'] = gdhi_population_df['Year'].astype(int)\n",
    "# add fuel_electric_prices_df to gdhi_population_df\n",
    "gdhi_population_fuel_electric_df = gdhi_population_df.merge(fuel_electric_prices_df, how='inner', left_on=['Year', 'ITL level 1'], right_on=['Year', 'PES area'])\n",
    "gdhi_population_fuel_electric_df\n",
    "# drop PES area column\n",
    "\n",
    "# COMBINED DATAFRAME (GDHI + POPULATION + FUEL + ELECTRICITY PRICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].str.strip()\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Barking and Dagenham', 'Havering'], 'Barking & Dagenham and Havering')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Angus', 'Dundee City'], 'Angus and Dundee City')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hartlepool'], 'Hartlepool and Stockton-on-Tees')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Aberdeen City'], 'Aberdeen City and Aberdeenshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Aberdeenshire'], 'Aberdeen City and Aberdeenshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Worthing', 'Adur', 'Arun', 'Chichester', 'Horsham', 'Mid Sussex'], 'West Sussex (South West)')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Allerdale', 'Barrow-in-Furness', 'Carlisle', 'Copeland'], 'West Cumbria')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Eden', 'South Lakeland'], 'East Cumbria')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Argyll and Bute'], 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Ashfield', 'Bassetlaw', 'Bolsover', 'Gedling'], 'North Nottinghamshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Babergh', 'East Suffolk', 'Ipswich', 'Mid Suffolk', 'West Suffolk'], 'Suffolk')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Barnsley', 'Doncaster', 'Rotherham'], 'Barnsley, Doncaster and Rotherham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Basildon'], 'Thurrock')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Basingstoke and Deane', 'Hart', 'Rushmoor'], 'North Hampshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bath and North East Somerset', 'North Somerset', 'South Gloucestershire'], 'Bath and North East Somerset, North Somerset and South Gloucestershire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bexley', 'Greenwich'], 'Bexley and Greenwich')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Blaby', 'Charnwood', 'Harborough', 'Hinckley and Bosworth', 'Melton', 'North West Leicestershire', 'Oadby and Wigston', 'Rutland'], 'Leicestershire CC and Rutland')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Blaenau Gwent', 'Torfaen'], 'Gwent Valleys')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bolton', 'Bury'], 'Greater Manchester North West')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Boston', 'North Kesteven', 'West Lindsey', 'South Kesteven', 'South Holland'], 'Lincolnshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bracknell Forest', 'Reading', 'Slough', 'West Berkshire', 'Windsor and Maidenhead', 'Wokingham'], 'Berkshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Braintree', 'Brentwood', 'Castle Point', 'Colchester', 'Chelmsford', 'Rochford'], 'Essex Haven Gateway')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Breckland', 'Broadland', 'Great Yarmouth', 'South Norfolk'], 'Breckland and South Norfolk')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bridgend', 'Merthyr Tydfil', 'Neath Port Talbot', 'Rhondda Cynon Taf'], 'Bridgend and Neath Port Talbot')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bromsgrove', 'Malvern Hills', 'Redditch', 'Worcester', 'Wychavon'], 'Worcestershire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Watford', 'Stevenage', 'St Albans', 'Three Rivers', 'Welwyn Hatfield', 'North Hertfordshire', 'Broxbourne', 'East Hertfordshire', 'Dacorum', 'Hertsmere'], 'Hertfordshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Broxtowe', 'Amber Valley', 'Derbyshire Dales', 'Erewash', 'South Derbyshire'], 'South and West Derbyshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Buckinghamshire'], 'Buckinghamshire CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Burnley', 'Hyndburn', 'Pendle', 'Ribble Valley', 'Rossendale'], 'East Lancashire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Caerphilly', 'Cardiff', 'Vale of Glamorgan'], 'Cardiff and Vale of Glamorgan')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cambridge', 'East Cambridgeshire', 'Fenland', 'Huntingdonshire', 'South Cambridgeshire'], 'Cambridgeshire CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Newcastle-under-Lyme', 'Cannock Chase', 'East Staffordshire', 'Lichfield', 'South Staffordshire', 'Tamworth', 'Staffordshire Moorlands', 'Stafford'], 'Staffordshire CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Carmarthenshire', 'Pembrokeshire'], 'South West Wales')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cherwell', 'Oxford', 'South Oxfordshire', 'Vale of White Horse', 'West Oxfordshire'], 'Oxfordshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Chesterfield', 'North East Derbyshire', 'High Peak'], 'East Derbyshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Chorley', 'Fylde', 'South Ribble', 'West Lancashire'], 'Chorley and West Lancashire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['City of London', 'Camden'], 'Camden and City of London')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Clackmannanshire', 'Fife'], 'Clackmannanshire and Fife')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Conwy', 'Denbighshire'], 'Conwy and Denbighshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cornwall', 'Isles of Scilly'], 'Cornwall and Isles of Scilly')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Ayrshire', 'North Ayrshire'], 'East Ayrshire and North Ayrshire mainland')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Devon', 'Exeter', 'Mid Devon', 'North Devon', 'South Hams', 'Teignbridge', 'Torridge', 'West Devon'], 'Devon CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Dunbartonshire', 'West dunbartonshire', 'West Dunbartonshire'], 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Hampshire', 'Eastleigh', 'New Forest'], 'Central Hampshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Lothian', 'Midlothian'], 'East Lothian and Midlothian')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Renfrewshire', 'Inverclyde', 'Renfrewshire'], 'Inverclyde, East Renfrewshire and Renfrewshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Eastbourne', 'East Sussex'])\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Elmbridge', 'Epsom and Ewell', 'Guildford', 'Runnymede', 'Spelthorne', 'Woking', 'Waverley', 'Surrey Heath'], 'West Surrey')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Fareham', 'Gosport', 'Havant'], 'South Hampshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Flintshire', 'Wrexham'], 'Flintshire and Wrexham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Folkestone and Hythe', 'Dover', 'Ashford', 'Canterbury'], 'East Kent')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Gloucester', 'Forest of Dean', 'Cotswold', 'Cheltenham', 'Stroud', 'Tewkesbury'], 'Gloucestershire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Newcastle upon Tyne', 'Gateshead', 'North Tyneside', 'South Tyneside'], 'Tyneside')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hackney', 'Newham'], 'Hackney and Newham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hammersmith and Fulham', 'Kensington and Chelsea'], 'Kensington & Chelsea and Hammersmith & Fulham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Harlow', 'Epping Forest'], 'Essex Thames Gateway')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Harrow', 'Hillingdon'], 'Harrow and Hillingdon')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:129: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Haringey', 'Islington'], 'Haringey and Islington')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hastings', 'Lewes', 'Rother', 'Wealden'], 'East Sussex CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hounslow', 'Richmond upon Thames'], 'Hounslow and Richmond upon Thames')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace([\"King's Lynn and West Norfolk\", 'North Norfolk'], 'North and West Norfolk')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Kingston upon Thames', 'Merton', 'Sutton'], 'Merton, Kingston upon Thames and Sutton')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Kirklees', 'Calderdale'], 'Calderdale and Kirklees')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Knowsley', 'St. Helens'], 'East Merseyside')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lancaster', 'Wyre', 'Wyre Forest'], 'Lancaster and Wyre')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lewisham', 'Southwark'], 'Lewisham and Southwark')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lincoln', 'North East Lincolnshire', 'North Lincolnshire', 'East Lindsey'], 'North and North East Lincolnshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace('Maidstone', 'Medway')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mansfield', 'Newark and Sherwood'], 'Nottingham')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mendip', 'South Somerset', 'Somerset West and Taunton', 'Sedgemoor'], 'Somerset')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mole Valley', 'Reigate and Banstead', 'Tandridge'], 'East Surrey')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Monmouthshire', 'Newport'], 'Monmouthshire and Newport')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Moray'], 'Inverness and Nairn and Moray, Badenoch and Strathspey')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Warwick', 'North Warwickshire', 'Nuneaton and Bedworth', 'Rugby', 'Stratford-on-Avon'], 'Warwickshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Oldham', 'Rochdale', 'Salford'], 'Greater Manchester North East')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Perth and Kinross', 'Stirling'], 'Perth and Kinross and Stirling')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Redcar and Cleveland'], 'South Teesside')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Richmondshire', 'Middlesbrough', 'Hambleton', 'Harrogate', 'Ryedale', 'Scarborough', 'Selby', 'Craven'], 'North Yorkshire CC')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Redbridge', 'Waltham Forest'], 'Redbridge and Waltham Forest')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Stockport', 'Tameside', 'Wigan'], 'Greater Manchester South East')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Trafford'], 'Greater Manchester South West')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Stockton-on-Tees', 'Hartlepool and Stockton-on-Tees'])\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Tendring', 'Uttlesford'], 'West Essex')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Test Valley'], 'Central Hampshire')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:195: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Tonbridge and Malling', 'Tunbridge Wells', 'Sevenoaks'], 'West Kent')\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/1121752590.py:197: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Thanet', 'Swale', 'Gravesham', 'Dartford'], 'Kent Thames Gateway')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# remove all rows with ONS Geography 'Vehicle under disposal, previously GB','Vehicle under disposal, previously NI','Region or county unknown'\n",
    "vehicle_removed_df = vehicle_df[~vehicle_df['ONS Geography'].isin(['Vehicle under disposal, previously NI','Region or county unknown'])]\n",
    "# strip whitespace from ONS Geography column from front and back\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].str.strip()\n",
    "\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Barking and Dagenham', 'Havering'], 'Barking & Dagenham and Havering')\n",
    "# change \"Angus\" to \"Angus and Dundee City\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Angus', 'Dundee City'], 'Angus and Dundee City')\n",
    "# change Maldon to Heart of Essex\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Maldon', case=False, na=False), 'ONS Geography'] = 'Heart of Essex'\n",
    "# change the values in laname21 column to match the values in gdhi data \"Region name\" columns\n",
    "# change \"Hartlepool\" to \"Durham CC\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hartlepool'], 'Hartlepool and Stockton-on-Tees')\n",
    "# change \"Aberdeen City\" to \"Aberdeen City and Aberdeenshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Aberdeen City'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Aberdeenshire\" to \"Aberdeen City and Aberdeenshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Aberdeenshire'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Adur\" to \"West Sussex (South West)\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Worthing', 'Adur', 'Arun', 'Chichester', 'Horsham', 'Mid Sussex'], 'West Sussex (South West)')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Allerdale', 'Barrow-in-Furness', 'Carlisle', 'Copeland'], 'West Cumbria')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Eden', 'South Lakeland'], 'East Cumbria')\n",
    "# change \"Argyll and Bute\" to \"Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Argyll and Bute'], 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute')\n",
    "# change Ashfield to \"North Nottinghamshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Ashfield', 'Bassetlaw', 'Bolsover', 'Gedling'], 'North Nottinghamshire')\n",
    "# change Babergh to \"Suffolk\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Babergh', 'East Suffolk', 'Ipswich', 'Mid Suffolk', 'West Suffolk'], 'Suffolk')\n",
    "# change Barnsley to \"Barnsley, Doncaster and Rotherham\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Barnsley', 'Doncaster', 'Rotherham'], 'Barnsley, Doncaster and Rotherham')\n",
    "# change Basildon to \"Thurrock\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Basildon'], 'Thurrock')\n",
    "# change Basingstoke and Deane to \"North Hampshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Basingstoke and Deane', 'Hart', 'Rushmoor'], 'North Hampshire')\n",
    "# change Bath and North East Somerset to \"Bath and North East Somerset, North Somerset and South Gloucestershire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bath and North East Somerset', 'North Somerset', 'South Gloucestershire'], 'Bath and North East Somerset, North Somerset and South Gloucestershire')\n",
    "# change Bexley to \"Bexley and Greenwich\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bexley', 'Greenwich'], 'Bexley and Greenwich')\n",
    "# change Blaby to \"Leicestershire CC and Rutland\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Blaby', 'Charnwood', 'Harborough', 'Hinckley and Bosworth', 'Melton', 'North West Leicestershire', 'Oadby and Wigston', 'Rutland'], 'Leicestershire CC and Rutland')\n",
    "# change Blaenau Gwent to \"Gwent Valleys\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Blaenau Gwent', 'Torfaen'], 'Gwent Valleys')\n",
    "# change Bolton to \"Greater Manchester North West\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bolton', 'Bury'], 'Greater Manchester North West')\n",
    "# change Boston to \"Lincolnshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Boston', 'North Kesteven', 'West Lindsey', 'South Kesteven', 'South Holland'], 'Lincolnshire')\n",
    "# change Bracknell Forest to \"Berkshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bracknell Forest', 'Reading', 'Slough', 'West Berkshire', 'Windsor and Maidenhead', 'Wokingham'], 'Berkshire')\n",
    "# change Braintree to \"Essex Haven Gateway\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Braintree', 'Brentwood', 'Castle Point', 'Colchester', 'Chelmsford', 'Rochford'], 'Essex Haven Gateway')\n",
    "# change Breckland to \"Breckland and South Norfolk\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Breckland', 'Broadland', 'Great Yarmouth', 'South Norfolk'], 'Breckland and South Norfolk')\n",
    "# change Bridgend to \"Bridgend and Neath Port Talbot\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bridgend', 'Merthyr Tydfil', 'Neath Port Talbot', 'Rhondda Cynon Taf'], 'Bridgend and Neath Port Talbot')\n",
    "#  change Bromsgrove to \"Worcestershire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Bromsgrove', 'Malvern Hills', 'Redditch', 'Worcester', 'Wychavon'], 'Worcestershire')\n",
    "# change Broxbourne to \"Hertfordshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Watford', 'Stevenage', 'St Albans', 'Three Rivers', 'Welwyn Hatfield', 'North Hertfordshire', 'Broxbourne', 'East Hertfordshire', 'Dacorum', 'Hertsmere'], 'Hertfordshire')\n",
    "# change Broxtowe to \"South and West Derbyshire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Broxtowe', 'Amber Valley', 'Derbyshire Dales', 'Erewash', 'South Derbyshire'], 'South and West Derbyshire')\n",
    "# change Buckinghamshire to \"Buckinghamshire CC\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Buckinghamshire'], 'Buckinghamshire CC')\n",
    "# change Burnley to \"East Lancashire\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Burnley', 'Hyndburn', 'Pendle', 'Ribble Valley', 'Rossendale'], 'East Lancashire')\n",
    "# change Caerphilly to \"Cardiff and Vale of Glamorgan\"\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Caerphilly', 'Cardiff', 'Vale of Glamorgan'], 'Cardiff and Vale of Glamorgan')\n",
    "# change Cambridge to Cambridgeshire CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cambridge', 'East Cambridgeshire', 'Fenland', 'Huntingdonshire', 'South Cambridgeshire'], 'Cambridgeshire CC')\n",
    "# change Cannock Chase to Staffordshire CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Newcastle-under-Lyme', 'Cannock Chase', 'East Staffordshire', 'Lichfield', 'South Staffordshire', 'Tamworth', 'Staffordshire Moorlands', 'Stafford'], 'Staffordshire CC')\n",
    "# change Carmarthenshire to South West Wales\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Carmarthenshire', 'Pembrokeshire'], 'South West Wales')\n",
    "# change Ceredigion to Central Valleys\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Ceredigion', case=False, na=False), 'ONS Geography'] = 'Central Valleys'\n",
    "# change Cherwell to Oxfordshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cherwell', 'Oxford', 'South Oxfordshire', 'Vale of White Horse', 'West Oxfordshire'], 'Oxfordshire')\n",
    "# change Chesterfield to East Derbyshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Chesterfield', 'North East Derbyshire', 'High Peak'], 'East Derbyshire')\n",
    "# change Chorley to Chorley and West Lancashire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Chorley', 'Fylde', 'South Ribble', 'West Lancashire'], 'Chorley and West Lancashire')\n",
    "# change City of London to Camden and City of London\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['City of London', 'Camden'], 'Camden and City of London')\n",
    "# change Clackmannanshire to Clackmannanshire and Fife\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Clackmannanshire', 'Fife'], 'Clackmannanshire and Fife')\n",
    "# change Conwy to Conwy and Denbighshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Conwy', 'Denbighshire'], 'Conwy and Denbighshire')\n",
    "# change Cornwall to Cornwall and Isles of Scilly\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Cornwall', 'Isles of Scilly'], 'Cornwall and Isles of Scilly')\n",
    "# change County Durham to Durham CC\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('County Durham', case=False, na=False), 'ONS Geography'] = 'Durham CC'\n",
    "# change Crawley to West Sussex\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Crawley', case=False, na=False), 'ONS Geography'] = 'West Sussex (North East)'\n",
    "# change East Ayrshire to East Ayrshire and North Ayrshire mainland\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Ayrshire', 'North Ayrshire'], 'East Ayrshire and North Ayrshire mainland')\n",
    "# change East Devon to Devon CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Devon', 'Exeter', 'Mid Devon', 'North Devon', 'South Hams', 'Teignbridge', 'Torridge', 'West Devon'], 'Devon CC')\n",
    "# change East Dunbartonshire to East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Dunbartonshire', 'West dunbartonshire', 'West Dunbartonshire'], 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond')\n",
    "# change East Hampshire to Central Hampshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Hampshire', 'Eastleigh', 'New Forest'], 'Central Hampshire')\n",
    "# change East Lothian to East Lothian and Midlothian\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Lothian', 'Midlothian'], 'East Lothian and Midlothian')\n",
    "# change East Renfrewshire to Inverclyde, East Renfrewshire and Renfrewshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['East Renfrewshire', 'Inverclyde', 'Renfrewshire'], 'Inverclyde, East Renfrewshire and Renfrewshire')\n",
    "# change Eastbourne to East Sussex\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Eastbourne', 'East Sussex'])\n",
    "# change Elmbridge to West Surrey\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Elmbridge', 'Epsom and Ewell', 'Guildford', 'Runnymede', 'Spelthorne', 'Woking', 'Waverley', 'Surrey Heath'], 'West Surrey')\n",
    "# change Fareham to South Hampshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Fareham', 'Gosport', 'Havant'], 'South Hampshire')\n",
    "# change Flintshire to Flintshire and Wrexham\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Flintshire', 'Wrexham'], 'Flintshire and Wrexham')\n",
    "# change Folkestone and Hythe to East Kent\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Folkestone and Hythe', 'Dover', 'Ashford', 'Canterbury'], 'East Kent')\n",
    "# change Forest of Dean to Gloucestershire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Gloucester', 'Forest of Dean', 'Cotswold', 'Cheltenham', 'Stroud', 'Tewkesbury'], 'Gloucestershire')\n",
    "# change Gateshead to Tyneside\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Newcastle upon Tyne', 'Gateshead', 'North Tyneside', 'South Tyneside'], 'Tyneside')\n",
    "# change Hackney to Hackney and Newham\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hackney', 'Newham'], 'Hackney and Newham')\n",
    "# change Hammersmith and Fulham to Kensington & Chelsea and Hammersmith & Fulham\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hammersmith and Fulham', 'Kensington and Chelsea'], 'Kensington & Chelsea and Hammersmith & Fulham')\n",
    "# change Harlow to Essex Thames Gateway\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Harlow', 'Epping Forest'], 'Essex Thames Gateway')\n",
    "# change Harrow to Harrow and Hillingdon\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Harrow', 'Hillingdon'], 'Harrow and Hillingdon')\n",
    "# change Haringey to Haringey and Islington\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Haringey', 'Islington'], 'Haringey and Islington')\n",
    "# change Hastings to East Sussex CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hastings', 'Lewes', 'Rother', 'Wealden'], 'East Sussex CC')\n",
    "# change Highland to Highlands and Islands\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Highland', case=False, na=False), 'ONS Geography'] = 'Caithness and Sutherland and Ross and Cromarty'\n",
    "# change Hounslow to Hounslow and Richmond upon Thames\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Hounslow', 'Richmond upon Thames'], 'Hounslow and Richmond upon Thames')\n",
    "# change King's Lynn and West Norfolk to North and West Norfolk\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace([\"King's Lynn and West Norfolk\", 'North Norfolk'], 'North and West Norfolk')\n",
    "# change Kingston upon Thames to Merton, Kingston upon Thames and Sutton\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Kingston upon Thames', 'Merton', 'Sutton'], 'Merton, Kingston upon Thames and Sutton')\n",
    "# change Kirklees to Calderdale and Kirklees\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Kirklees', 'Calderdale'], 'Calderdale and Kirklees')\n",
    "# change Knowsley to East Merseyside\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Knowsley', 'St. Helens'], 'East Merseyside')\n",
    "# change Lancaster to Lancaster and Wyre\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lancaster', 'Wyre', 'Wyre Forest'], 'Lancaster and Wyre')\n",
    "# change Lewisham to Lewisham and Southwark\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lewisham', 'Southwark'], 'Lewisham and Southwark')\n",
    "# change Lincoln to North and North East Lincolnshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Lincoln', 'North East Lincolnshire', 'North Lincolnshire', 'East Lindsey'], 'North and North East Lincolnshire')\n",
    "# change Maidstone to Medway\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace('Maidstone', 'Medway')\n",
    "# change Mansfield to Nottingham\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mansfield', 'Newark and Sherwood'], 'Nottingham')\n",
    "# change Mendip to Somerset\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mendip', 'South Somerset', 'Somerset West and Taunton', 'Sedgemoor'], 'Somerset')\n",
    "# change Mole Valley to East Surrey\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Mole Valley', 'Reigate and Banstead', 'Tandridge'], 'East Surrey')\n",
    "# change Monmouthshire to Monmouthshire and Newport\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Monmouthshire', 'Newport'], 'Monmouthshire and Newport')\n",
    "# change Moray to Inverness and Nairn and Moray, Badenoch and Strathspey\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Moray'], 'Inverness and Nairn and Moray, Badenoch and Strathspey')\n",
    "# change North Warwickshire to Warwickshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Warwick', 'North Warwickshire', 'Nuneaton and Bedworth', 'Rugby', 'Stratford-on-Avon'], 'Warwickshire')\n",
    "# change Norwich to Norwich and East Norfolk\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Norwich', case=False, na=False), 'ONS Geography'] = 'Norwich and East Norfolk'\n",
    "# change Oldham to Greater Manchester North East\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Oldham', 'Rochdale', 'Salford'], 'Greater Manchester North East')\n",
    "# change Perth and Kinross to Perth and Kinross and Stirling\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Perth and Kinross', 'Stirling'], 'Perth and Kinross and Stirling')\n",
    "# change preston to Mid Lancashire\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Preston', case=False, na=False), 'ONS Geography'] = 'Mid Lancashire'\n",
    "# change 'Redcar and Cleveland' to South Teesside\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Redcar and Cleveland'], 'South Teesside')\n",
    "# change Redcar and Cleveland to North Yorkshire CC\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Richmondshire', 'Middlesbrough', 'Hambleton', 'Harrogate', 'Ryedale', 'Scarborough', 'Selby', 'Craven'], 'North Yorkshire CC')\n",
    "# change Redbridge to Redbridge and Waltham Forest\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Redbridge', 'Waltham Forest'], 'Redbridge and Waltham Forest')\n",
    "# change Rushcliffe to Nottinghamshire\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Rushcliffe', case=False, na=False), 'ONS Geography'] = 'South Nottinghamshire'\n",
    "# change Shropshire to Shropshire CC\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Shropshire', case=False, na=False), 'ONS Geography'] = 'Shropshire CC'\n",
    "# change Stockport to Greater Manchester South East\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Stockport', 'Tameside', 'Wigan'], 'Greater Manchester South East')\n",
    "# change 'Trafford' to Greater Manchester South West\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Trafford'], 'Greater Manchester South West')\n",
    "# change Stockton-on-Tees to Hartlepool and Stockton-on-Tees\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Stockton-on-Tees', 'Hartlepool and Stockton-on-Tees'])\n",
    "# change Tendring to Essex\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Tendring', 'Uttlesford'], 'West Essex')\n",
    "# change Test Valley to Central Hampshire\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Test Valley'], 'Central Hampshire')\n",
    "# change Winchester to Portsmouth\n",
    "vehicle_removed_df.loc[vehicle_removed_df['ONS Geography'].str.contains('Winchester', case=False, na=False), 'ONS Geography'] = 'Portsmouth'\n",
    "# 'Tonbridge and Malling' to west Kent\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Tonbridge and Malling', 'Tunbridge Wells', 'Sevenoaks'], 'West Kent')\n",
    "# change Tunbridge Wells to Kent Thames Gateway\n",
    "vehicle_removed_df['ONS Geography'] = vehicle_removed_df['ONS Geography'].replace(['Thanet', 'Swale', 'Gravesham', 'Dartford'], 'Kent Thames Gateway')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# check which values are in ONS Geography in vehicle_removed_df but not in gdhi_population_fuel_electric_df\n",
    "remove = set(vehicle_removed_df['ONS Geography'].unique()) - set(gdhi_population_fuel_electric_df['ITL level 3'].unique())\n",
    "# remove rows with values in remove\n",
    "vehicle_removed_df = vehicle_removed_df[~vehicle_removed_df['ONS Geography'].isin(remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values in Fuel column\n",
    "vehicle_removed_df['Fuel'].unique()\n",
    "# columns\n",
    "vehicle_removed_df.columns\n",
    "# remove ONS Code and ONS Sort columns\n",
    "vehicle_removed_df = vehicle_removed_df.drop(columns=['ONS Code', 'ONS Sort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuel types - ['Battery electric', 'Total', 'Plug-in hybrid electric (diesel)', 'Plug-in hybrid electric (petrol)', 'Range extended electric','Diesel', 'Hybrid electric (petrol)', 'Other fuels', 'Petrol']\n",
    "# create new dataframe for each fuel type\n",
    "battery_electric_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Battery electric']\n",
    "plug_in_hybrid_diesel_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Plug-in hybrid electric (diesel)']\n",
    "plug_in_hybrid_petrol_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Plug-in hybrid electric (petrol)']\n",
    "range_extended_electric_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Range extended electric']\n",
    "diesel_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Diesel']\n",
    "hybrid_petrol_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Hybrid electric (petrol)']\n",
    "other_fuels_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Other fuels']\n",
    "petrol_df = vehicle_removed_df[vehicle_removed_df['Fuel'] == 'Petrol']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge each fuel type dataframe with gdhi_population_fuel_electric_df\n",
    "battery_electric_gdhi_df = gdhi_population_fuel_electric_df.merge(battery_electric_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "plug_in_hybrid_diesel_gdhi_df = gdhi_population_fuel_electric_df.merge(plug_in_hybrid_diesel_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "plug_in_hybrid_petrol_gdhi_df = gdhi_population_fuel_electric_df.merge(plug_in_hybrid_petrol_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "range_extended_electric_gdhi_df = gdhi_population_fuel_electric_df.merge(range_extended_electric_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "diesel_gdhi_df = gdhi_population_fuel_electric_df.merge(diesel_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "hybrid_petrol_gdhi_df = gdhi_population_fuel_electric_df.merge(hybrid_petrol_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "other_fuels_gdhi_df = gdhi_population_fuel_electric_df.merge(other_fuels_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "petrol_gdhi_df = gdhi_population_fuel_electric_df.merge(petrol_df, how='inner', left_on=['Year', 'ITL level 3'], right_on=['Year', 'ONS Geography'])\n",
    "\n",
    "# drop ONS Geography column\n",
    "battery_electric_gdhi_df = battery_electric_gdhi_df.drop(columns=['ONS Geography'])\n",
    "plug_in_hybrid_diesel_gdhi_df = plug_in_hybrid_diesel_gdhi_df.drop(columns=['ONS Geography'])\n",
    "plug_in_hybrid_petrol_gdhi_df = plug_in_hybrid_petrol_gdhi_df.drop(columns=['ONS Geography'])\n",
    "range_extended_electric_gdhi_df = range_extended_electric_gdhi_df.drop(columns=['ONS Geography'])\n",
    "diesel_gdhi_df = diesel_gdhi_df.drop(columns=['ONS Geography'])\n",
    "hybrid_petrol_gdhi_df = hybrid_petrol_gdhi_df.drop(columns=['ONS Geography'])\n",
    "other_fuels_gdhi_df = other_fuels_gdhi_df.drop(columns=['ONS Geography'])\n",
    "petrol_gdhi_df = petrol_gdhi_df.drop(columns=['ONS Geography'])\n",
    "\n",
    "# drop nan values\n",
    "battery_electric_gdhi_df = battery_electric_gdhi_df.dropna()\n",
    "plug_in_hybrid_diesel_gdhi_df = plug_in_hybrid_diesel_gdhi_df.dropna()\n",
    "plug_in_hybrid_petrol_gdhi_df = plug_in_hybrid_petrol_gdhi_df.dropna()\n",
    "range_extended_electric_gdhi_df = range_extended_electric_gdhi_df.dropna()\n",
    "diesel_gdhi_df = diesel_gdhi_df.dropna()\n",
    "hybrid_petrol_gdhi_df = hybrid_petrol_gdhi_df.dropna()\n",
    "other_fuels_gdhi_df = other_fuels_gdhi_df.dropna()\n",
    "petrol_gdhi_df = petrol_gdhi_df.dropna()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargepoint_number_df = chargepoint_df\n",
    "# drop rows with na value for dateCreated\n",
    "chargepoint_number_df = chargepoint_number_df.dropna(subset=['dateCreated'])\n",
    "# drop rows with 0000-00-00 00:00:00 value for dateCreated\n",
    "chargepoint_number_df = chargepoint_number_df[chargepoint_number_df['dateCreated'] != '0000-00-00 00:00:00']\n",
    "# drop rows with 230 value for dateCreated\n",
    "chargepoint_number_df = chargepoint_number_df[chargepoint_number_df['dateCreated'] != '230']\n",
    "# convert dateCreated to datetime\n",
    "chargepoint_number_df['dateCreated'] = pd.to_datetime(chargepoint_number_df['dateCreated'],format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# extract year from dateCreated\n",
    "chargepoint_number_df['Year'] = chargepoint_number_df['dateCreated'].dt.year\n",
    "\n",
    "# get number of chargepoints per year in each county and show sum of number of rows in each year\n",
    "chargepoint_number_df = chargepoint_number_df.groupby(['Year', 'county']).size().reset_index(name='Number of Chargepoints').sort_values(by=['Year', 'county'])\n",
    "\n",
    "# rename county column to ITL level 3\n",
    "chargepoint_number_df = chargepoint_number_df.rename(columns={'county': 'ITL level 3'})\n",
    "\n",
    "# remove rows with values 0, 4\n",
    "chargepoint_number_df = chargepoint_number_df[~chargepoint_number_df['ITL level 3'].isin(['0', '4', 'County Cork','County Dublin', \n",
    "                                                                                          'Dublin', 'Guernsey', 'Me10 2La', 'Notts.', 'Notts', \n",
    "                                                                                          'Oxon', 'SG1 1EP', 'Staffs', 'Warcs', 'Warks', \n",
    "                                                                                           'Wick','Wilts', 'Worcs', 'Yorks', '`West Midlands',\n",
    "                                                                                            'United Kingdom', 'None', 'Lincs', 'Leics', 'Lancs', \n",
    "                                                                                             'Gwent','Herts', 'Hants', 'Gloucs', 'Derbys',\n",
    "                                                                                             'County Galway','Galway County', 'County Limerick',\n",
    "                                                                                             'West Midland','West Midlands','West Mdilands',\n",
    "                                                                                            'County Wicklow'])]\n",
    "# strip whitespace from ITL level 3 column from front and back\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].str.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Barking and Dagenham', 'Havering'], 'Barking & Dagenham and Havering')\n",
    "# change \"Angus\" to \"Angus and Dundee City\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Angus', 'Dundee City','Dundee'], 'Angus and Dundee City')\n",
    "# change Maldon to Heart of Essex\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Maldon', case=False, na=False), 'ITL level 3'] = 'Heart of Essex'\n",
    "# change the values in laname21 column to match the values in gdhi data \"Region name\" columns\n",
    "# change \"Hartlepool\" to \"Durham CC\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Hartlepool'], 'Hartlepool and Stockton-on-Tees')\n",
    "# change \"Aberdeen City\" to \"Aberdeen City and Aberdeenshire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Aberdeen City'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Aberdeenshire\" to \"Aberdeen City and Aberdeenshire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['City of Aberdeen','Aberdeenshire'], 'Aberdeen City and Aberdeenshire')\n",
    "# change \"Adur\" to \"West Sussex (South West)\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Worthing', 'Adur', 'Arun', 'Chichester', 'Horsham', 'Mid Sussex'], 'West Sussex (South West)')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Cumbria','Allerdale', 'Barrow-in-Furness', 'Carlisle', 'Copeland'], 'West Cumbria')\n",
    "# change \"Allerdale\" to \"West Cumbria\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Eden', 'South Lakeland'], 'East Cumbria')\n",
    "# change \"Argyll and Bute\" to \"Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Argyll and Bute', 'Argyl and Bute', 'Argyll', 'Argyll & Bute'], 'Lochaber, Skye and Lochalsh, Arran and Cumbrae and Argyll and Bute')\n",
    "# change Ashfield to \"North Nottinghamshire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Ashfield', 'Bassetlaw', 'Bolsover', 'Gedling'], 'North Nottinghamshire')\n",
    "# change Babergh to \"Suffolk\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Babergh', 'East Suffolk', 'Ipswich', 'Mid Suffolk', 'West Suffolk'], 'Suffolk')\n",
    "# change Barnsley to \"Barnsley, Doncaster and Rotherham\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Barnsley', 'Doncaster', 'Rotherham'], 'Barnsley, Doncaster and Rotherham')\n",
    "# change Basildon to \"Thurrock\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Basildon'], 'Thurrock')\n",
    "# change Basingstoke and Deane to \"North Hampshire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Basingstoke','Basingstoke and Deane Borough Council','Basingstoke and Deane', 'Hart', 'Rushmoor'], 'North Hampshire')\n",
    "# change Bath and North East Somerset to \"Bath and North East Somerset, North Somerset and South Gloucestershire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bath and North East Somerset', 'North Somerset', 'South Gloucestershire'], 'Bath and North East Somerset, North Somerset and South Gloucestershire')\n",
    "# change Bexley to \"Bexley and Greenwich\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bexley', 'Greenwich'], 'Bexley and Greenwich')\n",
    "# change Blaby to \"Leicestershire CC and Rutland\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Blaby', 'Rutlands', 'Charnwood', 'Harborough', 'Hinckley and Bosworth', 'Melton','City of Leicester', 'Leicestershire', 'North West Leicestershire', 'Oadby and Wigston', 'Rutland'], 'Leicestershire CC and Rutland')\n",
    "# change Blaenau Gwent to \"Gwent Valleys\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Blaenau Gwent', 'Torfaen'], 'Gwent Valleys')\n",
    "# change Bolton to \"Greater Manchester North West\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bolton', 'Greater Manchester', 'Bury'], 'Greater Manchester North West')\n",
    "# change Boston to \"Lincolnshire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Boston', 'Grantham', 'North Kesteven', 'West Lindsey', 'South Kesteven', 'South Holland'], 'Lincolnshire')\n",
    "# change Bracknell Forest to \"Berkshire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bracknell Forest', 'Reading', 'Slough', 'West Berkshire', 'Windsor and Maidenhead', 'Wokingham', 'BERKSHIRE', 'West Berkshire Council'], 'Berkshire')\n",
    "# change Braintree to \"Essex Haven Gateway\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Braintree', 'Brentwood', 'Castle Point', 'Colchester', 'Chelmsford', 'Rochford'], 'Essex Haven Gateway')\n",
    "# change Breckland to \"Breckland and South Norfolk\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Breckland', 'Broadland', 'Great Yarmouth', 'South Norfolk'], 'Breckland and South Norfolk')\n",
    "# change Bridgend to \"Bridgend and Neath Port Talbot\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bridgend', 'Merthyr Tydfil', 'Neath Port Talbot', 'Rhondda Cynon Taf'], 'Bridgend and Neath Port Talbot')\n",
    "#  change Bromsgrove to \"Worcestershire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bromsgrove', 'Malvern Hills', 'Redditch', 'Worcester', 'Wychavon'], 'Worcestershire')\n",
    "# change Broxbourne to \"Hertfordshire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Watford', 'Stevenage', 'St Albans', 'Three Rivers', 'Welwyn Hatfield', 'North Hertfordshire', 'Broxbourne', 'East Hertfordshire', 'Dacorum', 'Hertsmere' 'Hereford','Herefordshire',], 'Hertfordshire')\n",
    "# change Broxtowe to \"South and West Derbyshire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Broxtowe', 'Amber Valley', 'Derbyshire Dales', 'Erewash', 'South Derbyshire'], 'South and West Derbyshire')\n",
    "# change Buckinghamshire to \"Buckinghamshire CC\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['City of Westminster', 'Buckinghamshire','Buckingham','Bucks'], 'Buckinghamshire CC')\n",
    "# change Burnley to \"East Lancashire\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Burnley', 'Hyndburn', 'Pendle', 'Ribble Valley', 'Rossendale'], 'East Lancashire')\n",
    "# change Caerphilly to \"Cardiff and Vale of Glamorgan\"\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['City of Cardiff', 'Glamorgan','Glamorgan (Morgannwg)',\n",
    "                                                                                     'Glamorganshire','Caerphilly', 'Cardiff', 'Vale of Glamorgan',\n",
    "                                                                                     'Vale of Glamorgan, The',  'West Glamorgan', 'Mid Glamorgan', \n",
    "                                                                                     'South Glamorgan'], 'Cardiff and Vale of Glamorgan')\n",
    "# change Cambridge to Cambridgeshire CC\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Cambridge','Cambs', 'East Cambridgeshire', 'Fenland', 'Huntingdonshire', 'South Cambridgeshire','Cambridgeshire'], 'Cambridgeshire CC')\n",
    "# change Cannock Chase to Staffordshire CC\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Burton-on-Trent','Newcastle-under-Lyme', 'Cannock Chase', 'East Staffordshire', 'Lichfield', 'South Staffordshire', 'Tamworth', 'Staffordshire Moorlands', 'Stafford'], 'Staffordshire CC')\n",
    "# change Carmarthenshire to South West Wales\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Carmarthenshire', 'Pembrokeshire'], 'South West Wales')\n",
    "# change Aberystwyth to Ceredigion\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Aberystwyth'], 'Ceredigion')\n",
    "# change Ceredigion to Central Valleys\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Ceredigion', case=False, na=False), 'ITL level 3'] = 'Central Valleys'\n",
    "# change Cherwell to Oxfordshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Oxford City Council','Cherwell', 'Oxford', 'South Oxfordshire', 'Vale of White Horse', 'West Oxfordshire'], 'Oxfordshire')\n",
    "# change Chesterfield to East Derbyshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Chesterfield', 'North East Derbyshire', 'High Peak','Derbyshire'], 'East Derbyshire')\n",
    "# change Chorley to Chorley and West Lancashire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Chorley', 'Fylde', 'South Ribble', 'West Lancashire','Lancashire'], 'Chorley and West Lancashire')\n",
    "# change City of London to Camden and City of London\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['City of London', 'Camden', 'Lond','London','London Borough Of Southwark',\n",
    "                                                               'London Borough of Brent', 'London Borough of Camden','London Borough of Ealing',\n",
    "                                                               'London Borough of Enfield','London Borough of Greenwich', 'Royal Borough of Greenwich',\n",
    "                                                               'London Borough of Hackney','London Borough of Hammersmith and Fulham',\n",
    "                                                               'London Borough of Hounslow', 'London Borough of Islington',\n",
    "                                                               'London Borough of Lambeth','London Borough of Lewisham',\n",
    "                                                               'London Borough of Newham','London Borough of Richmond upon Thames',\n",
    "                                                               'London Borough of Southwark','London Borough of Sutton',\n",
    "                                                               'London Borough of Tower Hamlets','London Borough of Waltham Forest',\n",
    "                                                               'London Borough of Wandsworth','Greater London'], 'Camden and City of London')\n",
    "# change Clackmannanshire to Clackmannanshire and Fife\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Clackmannanshire', 'Fife'], 'Clackmannanshire and Fife')\n",
    "# change Conwy to Conwy and Denbighshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Conwy', 'Denbighshire'], 'Conwy and Denbighshire')\n",
    "# change Cornwall to Cornwall and Isles of Scilly\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Cornwall', 'Isles of Scilly'], 'Cornwall and Isles of Scilly')\n",
    "# change County Durham to Durham CC\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('County Durham', case=False, na=False), 'ITL level 3'] = 'Durham CC'\n",
    "# change Durham to Durham CC\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Durham','Co Durham'], 'Durham CC')\n",
    "# change Crawley to West Sussex\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Crawley', case=False, na=False), 'ITL level 3'] = 'West Sussex (North East)'\n",
    "# change East Ayrshire to East Ayrshire and North Ayrshire mainland\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['East Ayrshire', 'North Ayrshire'], 'East Ayrshire and North Ayrshire mainland')\n",
    "# change East Devon to Devon CC\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['East Devon', 'Exeter', 'Mid Devon', 'North Devon', 'South Hams', 'Teignbridge', 'Torridge', 'West Devon','Devon'], 'Devon CC')\n",
    "# change East Dunbartonshire to East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['East Dunbartonshire', 'West dunbartonshire', 'West Dunbartonshire'], 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond')\n",
    "# change East Hampshire to Central Hampshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['East Hampshire', 'Eastleigh', 'New Forest'], 'Central Hampshire')\n",
    "# change East Lothian to East Lothian and Midlothian\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['East Lothian', 'Midlothian'], 'East Lothian and Midlothian')\n",
    "# change East Renfrewshire to Inverclyde, East Renfrewshire and Renfrewshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['East Renfrewshire', 'Renfewshire', 'Inverclyde', 'Renfrewshire'], 'Inverclyde, East Renfrewshire and Renfrewshire')\n",
    "# change Eastbourne to East Sussex\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Eastbourne', 'East Sussex'])\n",
    "# change Elmbridge to West Surrey\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Elmbridge', 'Epsom and Ewell', 'Guildford', 'Runnymede', 'Spelthorne', 'Woking', 'Waverley', 'Surrey Heath'], 'West Surrey')\n",
    "# change Fareham to South Hampshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Fareham', 'Gosport', 'Havant', 'Hampshire'], 'South Hampshire')\n",
    "# change Flintshire to Flintshire and Wrexham\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Flintshire', 'Wrexham'], 'Flintshire and Wrexham')\n",
    "# change Folkestone and Hythe to East Kent\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Folkestone and Hythe', 'Dover', 'Ashford', 'Canterbury',\n",
    "                                                                                     'KENT','Kent','kent'], 'East Kent')\n",
    "# change Forest of Dean to Gloucestershire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Gloucester', 'Forest of Dean', 'Cotswold', 'Cheltenham', 'Stroud', 'Tewkesbury'], 'Gloucestershire')\n",
    "# change Gateshead to Tyneside\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Newcastle upon Tyne', 'Gateshead', 'North Tyneside', 'South Tyneside', 'Tyne & Wear', 'Tyne and Wear', 'Tyne and Wear,'], 'Tyneside')\n",
    "# change Hackney to Hackney and Newham\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Hackney', 'Newham'], 'Hackney and Newham')\n",
    "# change Hammersmith and Fulham to Kensington & Chelsea and Hammersmith & Fulham\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Hammersmith and Fulham', 'Hammersmith & Fulham Council', 'Kensington and Chelsea'], 'Kensington & Chelsea and Hammersmith & Fulham')\n",
    "# change Harlow to Essex Thames Gateway\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Harlow', 'Epping Forest'], 'Essex Thames Gateway')\n",
    "# change Harrow to Harrow and Hillingdon\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Harrow', 'Hillingdon'], 'Harrow and Hillingdon')\n",
    "# change Haringey to Haringey and Islington\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Haringey', 'Islington'], 'Haringey and Islington')\n",
    "# change Hastings to East Sussex CC\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Hastings', 'Lewes', 'Rother', 'Wealden','Sussex'], 'East Sussex CC')\n",
    "# change Highland to Highlands and Islands\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Highland', case=False, na=False), 'ITL level 3'] = 'Caithness and Sutherland and Ross and Cromarty'\n",
    "# change Hounslow to Hounslow and Richmond upon Thames\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Hounslow', 'Richmond upon Thames'], 'Hounslow and Richmond upon Thames')\n",
    "# change King's Lynn and West Norfolk to North and West Norfolk\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace([\"King's Lynn and West Norfolk\", 'North Norfolk', 'norfolk'], 'North and West Norfolk')\n",
    "# change Kingston upon Thames to Merton, Kingston upon Thames and Sutton\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Kingston upon Thames', 'Merton', 'Sutton'], 'Merton, Kingston upon Thames and Sutton')\n",
    "# change Kirklees to Calderdale and Kirklees\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Kirklees', 'Calderdale'], 'Calderdale and Kirklees')\n",
    "# change Knowsley to East Merseyside\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Knowsley', 'St. Helens'], 'East Merseyside')\n",
    "# change Lancaster to Lancaster and Wyre\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Lancaster', 'Wyre', 'Wyre Forest'], 'Lancaster and Wyre')\n",
    "# change Lewisham to Lewisham and Southwark\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Lewisham', 'Southwark'], 'Lewisham and Southwark')\n",
    "# change Lincoln to North and North East Lincolnshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Lincoln', 'North East Lincolnshire', 'North Lincolnshire', 'East Lindsey'], 'North and North East Lincolnshire')\n",
    "# change Maidstone to Medway\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace('Maidstone', 'Medway')\n",
    "# change Mansfield to Nottingham\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Mansfield', 'Newark and Sherwood','Nottinghamshire','City of Nottingham'], 'Nottingham')\n",
    "# change Mendip to Somerset\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Mendip', 'South Somerset', 'Somerset West and Taunton', 'Sedgemoor'], 'Somerset')\n",
    "# change Mole Valley to East Surrey\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Mole Valley', 'Reigate and Banstead', 'Tandridge'], 'East Surrey')\n",
    "# change Monmouthshire to Monmouthshire and Newport\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Monmouthshire', 'Newport'], 'Monmouthshire and Newport')\n",
    "# change Moray to Inverness and Nairn and Moray, Badenoch and Strathspey\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Moray'], 'Inverness and Nairn and Moray, Badenoch and Strathspey')\n",
    "# change North Warwickshire to Warwickshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Warwick', 'North Warwickshire', 'Nuneaton and Bedworth', 'Rugby', 'Stratford-on-Avon'], 'Warwickshire')\n",
    "# change Norwich to Norwich and East Norfolk\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Norwich', case=False, na=False), 'ITL level 3'] = 'Norwich and East Norfolk'\n",
    "# change Oldham to Greater Manchester North East\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Oldham', 'Rochdale', 'Salford'], 'Greater Manchester North East')\n",
    "# change Perth and Kinross to Perth and Kinross and Stirling\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Perth and Kinross', 'Perth & Kinross', 'Perthshire', 'Stirling'], 'Perth and Kinross and Stirling')\n",
    "# change preston to Mid Lancashire\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Preston', case=False, na=False), 'ITL level 3'] = 'Mid Lancashire'\n",
    "# change 'Redcar and Cleveland' to South Teesside\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Redcar and Cleveland','Cleveland'], 'South Teesside')\n",
    "# change Redcar and Cleveland to North Yorkshire CC\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace([ 'Yorkshire', 'North Yorkshire', 'South Yorkshire', 'West Yorkshire', 'west Yorkshire', 'Yorkshire, North Riding','Richmondshire', 'Middlesbrough', 'Hambleton', 'Harrogate', 'Ryedale', 'Scarborough','East Yorkshire', 'Selby', 'Craven'], 'North Yorkshire CC')\n",
    "# change Redbridge to Redbridge and Waltham Forest\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Redbridge', 'Waltham Forest'], 'Redbridge and Waltham Forest')\n",
    "# change Rushcliffe to Nottinghamshire\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Rushcliffe', case=False, na=False), 'ITL level 3'] = 'South Nottinghamshire'\n",
    "# change Shropshire to Shropshire CC\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Shropshire', case=False, na=False), 'ITL level 3'] = 'Shropshire CC'\n",
    "# change Stockport to Greater Manchester South East\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Stockport', 'Tameside', 'Wigan'], 'Greater Manchester South East')\n",
    "# change 'Trafford' to Greater Manchester South West\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Trafford'], 'Greater Manchester South West')\n",
    "# change Stockton-on-Tees to Hartlepool and Stockton-on-Tees\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Stockton-on-Tees', 'Hartlepool and Stockton-on-Tees'])\n",
    "# change Tendring to Essex\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Essex','Tendring', 'Uttlesford'], 'West Essex')\n",
    "# change Test Valley to Central Hampshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Isle Of Wight','Test Valley'], 'Central Hampshire')\n",
    "# change Winchester to Portsmouth\n",
    "chargepoint_number_df.loc[chargepoint_number_df['ITL level 3'].str.contains('Winchester', case=False, na=False), 'ITL level 3'] = 'Portsmouth'\n",
    "# change  'Portsmouth City Council' to Portsmouth\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Portsmouth City Council'], 'Portsmouth')\n",
    "# 'Tonbridge and Malling' to west Kent\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Folkestone','Tonbridge and Malling', 'Tunbridge Wells', 'Sevenoaks'], 'West Kent')\n",
    "# change Tunbridge Wells to Kent Thames Gateway\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Thanet', 'Swale', 'Gravesham', 'Dartford'], 'Kent Thames Gateway')\n",
    "# change Anglesey to Isle of Anglesey\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Anglesey'], 'Isle of Anglesey')\n",
    "# change Antrim to Antrim and Newtownabbey\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Antrim', 'Newtownabbey', 'County Antrim'], 'Antrim and Newtownabbey')\n",
    "# change Armagh to Armagh City, Banbridge and Craigavon\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Armagh', 'County Armagh'], 'Armagh City, Banbridge and Craigavon')\n",
    "# change Attleborough to Breckland and South Norfolk\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Attleborough'], 'Breckland and South Norfolk')\n",
    "# change Avon to City of, Bristol\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['County of Bristol','Avon', 'Bristol', 'City of Bristol'], 'Bristol, City of')\n",
    "# change Bedfordshire to Central Bedfordshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bedfordshire', 'Beds','Dunstable'], 'Central Bedfordshire')\n",
    "# change Belfast Greater to Belfast\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Belfast Greater'], 'Belfast')\n",
    "# change Bilston to Wolverhampton\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bilston'], 'Wolverhampton')\n",
    "# change Bournemouth to Bournemouth, Christchurch and Poole\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Bournemouth'], 'Bournemouth, Christchurch and Poole')\n",
    "# change Calne to Wiltshire\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Calne'], 'Wiltshire')\n",
    "# change carmarhenshire to South West Wales\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Carmarhenshire','Dyfed'], 'South West Wales')\n",
    "# change Cheshire to Cheshire East\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Cheshire','Deeside'], 'Cheshire East')\n",
    "# change Coventry to City of Coventry\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['City of Coventry'], 'Coventry')\n",
    "# change City of Glasgow to Glasgow City\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['City of Glasgow','Glasgow'], 'Glasgow City')\n",
    "# change Dumfries & Galloway to Dumfries and Galloway\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Dumfries & Galloway'], 'Dumfries and Galloway')\n",
    "# change Clwyd to Flintshire and Wrexham\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Clwyd'], 'Flintshire and Wrexham')\n",
    "# change County Down to Newry, Mourne and Down\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['County Down','Down'], 'Newry, Mourne and Down')  \n",
    "# change County Fermanagh to Fermanagh and Omagh\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['County Fermanagh','Fermanagh'], 'Fermanagh and Omagh')\n",
    "# change County Londonderry to Derry City and Strabane\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['County Londonderry','Londonderry'], 'Derry City and Strabane')\n",
    "# change County Tyrone to Mid Ulster\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['County Tyrone','Tyrone'], 'Mid Ulster')\n",
    "# change Derry to Derry City and Strabane\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Derry'], 'Derry City and Strabane')\n",
    "# change Dumfriesshire to Dumfries and Galloway\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Dumfriesshire'], 'Dumfries and Galloway')\n",
    "# change Dunbartonshire to East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Dunbartonshire'], 'East Dunbartonshire, West Dunbartonshire and Helensburgh and Lomond')\n",
    "# change Edinburgh to City of Edinburgh\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Edinburgh'], 'City of Edinburgh')\n",
    "# change Eilean Siar to Na h-Eileanan Siar\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Eilean Siar'], 'Na h-Eileanan Siar')\n",
    "# change  Hull City to Kingston upon Hull, City of\n",
    "chargepoint_number_df['ITL level 3'] = chargepoint_number_df['ITL level 3'].replace(['Hull City'], 'Kingston upon Hull, City of')\n",
    "\n",
    "\n",
    "\n",
    "# check which values are in ITL level 3 in chargepoint_number_df but not in gdhi_population_fuel_electric_df\n",
    "remove_rows = set(chargepoint_number_df['ITL level 3'].unique()) - set(gdhi_population_fuel_electric_df['ITL level 3'].unique())\n",
    "\n",
    "# remove rows with values in ITL level 3 in chargepoint_number_df but not in gdhi_population_fuel_electric_df\n",
    "chargepoint_number_df = chargepoint_number_df[~chargepoint_number_df['ITL level 3'].isin(remove_rows)]\n",
    "\n",
    "# group by and aggregate by sum and year\n",
    "chargepoint_number_df = chargepoint_number_df.groupby(['ITL level 3', 'Year']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of Chargepoints</th>\n",
       "      <th>Sum of Chargepoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Angus and Dundee City</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Angus and Dundee City</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Angus and Dundee City</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Angus and Dundee City</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Angus and Dundee City</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Angus and Dundee City</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Angus and Dundee City</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Angus and Dundee City</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Antrim and Newtownabbey</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Antrim and Newtownabbey</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Antrim and Newtownabbey</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Antrim and Newtownabbey</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Antrim and Newtownabbey</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ITL level 3    Year  Number of Chargepoints  \\\n",
       "0   Aberdeen City and Aberdeenshire  2015.0                    36.0   \n",
       "1   Aberdeen City and Aberdeenshire  2016.0                    12.0   \n",
       "2   Aberdeen City and Aberdeenshire  2017.0                     2.0   \n",
       "3   Aberdeen City and Aberdeenshire  2018.0                     1.0   \n",
       "4   Aberdeen City and Aberdeenshire  2019.0                     4.0   \n",
       "5   Aberdeen City and Aberdeenshire  2021.0                    18.0   \n",
       "6   Aberdeen City and Aberdeenshire  2023.0                     1.0   \n",
       "7             Angus and Dundee City  2013.0                     3.0   \n",
       "8             Angus and Dundee City  2015.0                    34.0   \n",
       "9             Angus and Dundee City  2017.0                     5.0   \n",
       "10            Angus and Dundee City  2018.0                     2.0   \n",
       "11            Angus and Dundee City  2019.0                     2.0   \n",
       "12            Angus and Dundee City  2020.0                     2.0   \n",
       "13            Angus and Dundee City  2021.0                     9.0   \n",
       "14            Angus and Dundee City  2022.0                    15.0   \n",
       "15          Antrim and Newtownabbey  2012.0                    13.0   \n",
       "16          Antrim and Newtownabbey  2013.0                    49.0   \n",
       "17          Antrim and Newtownabbey  2015.0                    15.0   \n",
       "18          Antrim and Newtownabbey  2016.0                     1.0   \n",
       "19          Antrim and Newtownabbey  2022.0                    23.0   \n",
       "\n",
       "    Sum of Chargepoints  \n",
       "0                  36.0  \n",
       "1                  48.0  \n",
       "2                  50.0  \n",
       "3                  51.0  \n",
       "4                  55.0  \n",
       "5                  73.0  \n",
       "6                  74.0  \n",
       "7                   3.0  \n",
       "8                  37.0  \n",
       "9                  42.0  \n",
       "10                 44.0  \n",
       "11                 46.0  \n",
       "12                 48.0  \n",
       "13                 57.0  \n",
       "14                 72.0  \n",
       "15                 13.0  \n",
       "16                 62.0  \n",
       "17                 77.0  \n",
       "18                 78.0  \n",
       "19                101.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new empty column called Sum of Chargepoints\n",
    "chargepoint_number_df['Sum of Chargepoints'] = 0\n",
    "\n",
    "# Sort by 'ITL level 3' and 'Year'\n",
    "chargepoint_number_df.sort_values(by=['ITL level 3', 'Year'], inplace=True)\n",
    "\n",
    "# Reset the index of dataframe to handle index issues while using .shift()\n",
    "chargepoint_number_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Group by ITL level 3\n",
    "grouped = chargepoint_number_df.groupby('ITL level 3')\n",
    "\n",
    "# Iterate over groups\n",
    "for name, group in grouped:\n",
    "    # Create a new column in the group dataframe for the cumulative sum of 'Number of Chargepoints'\n",
    "    group['Sum of Chargepoints'] = group['Number of Chargepoints'].cumsum()\n",
    "\n",
    "    # Update the original dataframe\n",
    "    chargepoint_number_df.update(group)\n",
    "\n",
    "chargepoint_number_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>Year</th>\n",
       "      <th>Number of Chargepoints</th>\n",
       "      <th>Sum of Chargepoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>York</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>York</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ITL level 3    Year  Number of Chargepoints  \\\n",
       "0    Aberdeen City and Aberdeenshire  2015.0                    36.0   \n",
       "1    Aberdeen City and Aberdeenshire  2016.0                    12.0   \n",
       "2    Aberdeen City and Aberdeenshire  2017.0                     2.0   \n",
       "3    Aberdeen City and Aberdeenshire  2018.0                     1.0   \n",
       "4    Aberdeen City and Aberdeenshire  2019.0                     4.0   \n",
       "..                               ...     ...                     ...   \n",
       "665                   Worcestershire  2021.0                    19.0   \n",
       "666                   Worcestershire  2022.0                     2.0   \n",
       "667                   Worcestershire  2023.0                    10.0   \n",
       "668                             York  2018.0                     3.0   \n",
       "669                             York  2021.0                     1.0   \n",
       "\n",
       "     Sum of Chargepoints  \n",
       "0                   36.0  \n",
       "1                   48.0  \n",
       "2                   50.0  \n",
       "3                   51.0  \n",
       "4                   55.0  \n",
       "..                   ...  \n",
       "665                 63.0  \n",
       "666                 65.0  \n",
       "667                 75.0  \n",
       "668                  3.0  \n",
       "669                  4.0  \n",
       "\n",
       "[670 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check Year column values\n",
    "chargepoint_number_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(frames), batch_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     batch_frames \u001b[39m=\u001b[39m frames[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     concatenated_batch \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(batch_frames)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     concatenated_df\u001b[39m.\u001b[39mappend(concatenated_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/smritibhat/Documents/UoB/ARP-main/Data_clean.ipynb#X43sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# concatenate the batches into a final dataframe\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/reshape/concat.py:360\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39malong the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    347\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    348\u001b[0m     objs,\n\u001b[1;32m    349\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    358\u001b[0m )\n\u001b[0;32m--> 360\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/reshape/concat.py:595\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    591\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    593\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 595\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    596\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    597\u001b[0m )\n\u001b[1;32m    598\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[1;32m    599\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/internals/concat.py:209\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    204\u001b[0m mgrs_indexers \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[1;32m    206\u001b[0m \u001b[39m# Assertion disabled for performance\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m# assert all(not x[1] for x in mgrs_indexers)\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m concat_plans \u001b[39m=\u001b[39m [_get_mgr_concatenation_plan(mgr) \u001b[39mfor\u001b[39;00m mgr, _ \u001b[39min\u001b[39;00m mgrs_indexers]\n\u001b[1;32m    210\u001b[0m concat_plan \u001b[39m=\u001b[39m _combine_concat_plans(concat_plans)\n\u001b[1;32m    211\u001b[0m blocks \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/internals/concat.py:209\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    204\u001b[0m mgrs_indexers \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[1;32m    206\u001b[0m \u001b[39m# Assertion disabled for performance\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m# assert all(not x[1] for x in mgrs_indexers)\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m concat_plans \u001b[39m=\u001b[39m [_get_mgr_concatenation_plan(mgr) \u001b[39mfor\u001b[39;00m mgr, _ \u001b[39min\u001b[39;00m mgrs_indexers]\n\u001b[1;32m    210\u001b[0m concat_plan \u001b[39m=\u001b[39m _combine_concat_plans(concat_plans)\n\u001b[1;32m    211\u001b[0m blocks \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/internals/concat.py:377\u001b[0m, in \u001b[0;36m_get_mgr_concatenation_plan\u001b[0;34m(mgr)\u001b[0m\n\u001b[1;32m    358\u001b[0m unit_no_ax0_reindexing \u001b[39m=\u001b[39m (\n\u001b[1;32m    359\u001b[0m     \u001b[39mlen\u001b[39m(placements) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(blk\u001b[39m.\u001b[39mmgr_locs)\n\u001b[1;32m    360\u001b[0m     \u001b[39mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m     )\n\u001b[1;32m    373\u001b[0m )\n\u001b[1;32m    375\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m unit_no_ax0_reindexing:\n\u001b[1;32m    376\u001b[0m     \u001b[39m# create block from subset of columns\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     blk \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mgetitem_block(ax0_blk_indexer)\n\u001b[1;32m    379\u001b[0m \u001b[39m# Assertions disabled for performance\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# assert blk._mgr_locs.as_slice == placements.as_slice\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# assert blk.shape[0] == shape[0]\u001b[39;00m\n\u001b[1;32m    382\u001b[0m unit \u001b[39m=\u001b[39m JoinUnit(blk, shape)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/internals/blocks.py:325\u001b[0m, in \u001b[0;36mBlock.getitem_block\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    322\u001b[0m axis0_slicer \u001b[39m=\u001b[39m slicer[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(slicer, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m slicer\n\u001b[1;32m    323\u001b[0m new_mgr_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr_locs[axis0_slicer]\n\u001b[0;32m--> 325\u001b[0m new_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slice(slicer)\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m new_values\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mndim:\n\u001b[1;32m    328\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly same dim slicing is allowed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/internals/blocks.py:313\u001b[0m, in \u001b[0;36mBlock._slice\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_slice\u001b[39m(\u001b[39mself\u001b[39m, slicer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ArrayLike:\n\u001b[1;32m    311\u001b[0m     \u001b[39m\"\"\"return a slice of my values\"\"\"\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues[slicer]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define the list of dataframes\n",
    "frames = [battery_electric_gdhi_df, plug_in_hybrid_diesel_gdhi_df, plug_in_hybrid_petrol_gdhi_df, range_extended_electric_gdhi_df, hybrid_petrol_gdhi_df]\n",
    "\n",
    "# define the batch size for concatenation\n",
    "batch_size = 10000\n",
    "\n",
    "# initialize an empty list to store the concatenated dataframes\n",
    "concatenated_df = []\n",
    "\n",
    "# iterate over the frames in batches and concatenate\n",
    "for i in range(0, len(frames), batch_size):\n",
    "    batch_frames = frames[i:i+batch_size]\n",
    "    concatenated_batch = pd.concat(batch_frames)\n",
    "    concatenated_df.append(concatenated_batch)\n",
    "\n",
    "# concatenate the batches into a final dataframe\n",
    "all_vehicles_electric__df = pd.concat(concatenated_df)\n",
    "\n",
    "# if Units column contains values other than 'Number', multiply the value of \"Number of vehicles\" by 1000 using dictionary\n",
    "all_vehicles_electric__df['Number of vehicles'] = np.where(all_vehicles_electric__df['Units'] != 'Number', all_vehicles_electric__df['Number of vehicles'] * 1000, all_vehicles_electric__df['Number of vehicles'])\n",
    "\n",
    "# drop Units column\n",
    "all_vehicles_electric__df.drop(['Units'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called 'Sum of Chargepoints' and set it to 0\n",
    "all_vehicles_electric__df['Sum of Chargepoints'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with ITL level 3 and Year as key and sum of chargepoints as value\n",
    "chargepoint_dict = chargepoint_number_df.set_index(['ITL level 3', 'Year'])['Sum of Chargepoints'].to_dict()\n",
    "\n",
    "# Apply the dictionary to the all_vehicles_electric__df dataframe\n",
    "all_vehicles_electric__df['Sum of Chargepoints'] = all_vehicles_electric__df.set_index(['ITL level 3', 'Year']).index.map(chargepoint_dict).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ITL level 3', 'Year', 'gdhi', 'sex', 'age', 'population',\n",
       "       'ITL level 1', 'ITL level 2', 'Average variable unit price (Â£/kWh)',\n",
       "       ' ULSP:  Pump price (p/litre)', 'ULSD: Pump price (p/litre)',\n",
       "       'BodyType', 'Fuel', 'Keepership', 'Number of vehicles',\n",
       "       'Sum of Chargepoints'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop PES area\n",
    "all_vehicles_electric__df.drop(['PES area','ITL level'], axis=1, inplace=True)\n",
    "# drop column ITL code\n",
    "all_vehicles_electric__df.drop(['ITL code'], axis=1, inplace=True)\n",
    "all_vehicles_electric__df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map value 1 in sex to Male and 2 in sex to Female in all_vehicles_electric__df\n",
    "sex_mapping = {1: 'Male', 2: 'Female'}\n",
    "all_vehicles_electric__df['sex'] = all_vehicles_electric__df['sex'].map(sex_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/3994235140.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  education_df_2010 = education_df_2010.append(pd.DataFrame({'ITL level 1': regions}), ignore_index=True)\n",
      "/var/folders/j9/0qd6cw014pgb7rk0v_28prrh0000gn/T/ipykernel_65812/3994235140.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  education_df_2010 = education_df_2010.append(pd.DataFrame({'ITL level 1': regions}), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITL level 1</th>\n",
       "      <th>NQF level 4 or above</th>\n",
       "      <th>NQF level 3 or above</th>\n",
       "      <th>NQF level 2 or above</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wales</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scotland</td>\n",
       "      <td>37.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>31.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yorkshire and The Humber</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South West</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>East of England</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>South East</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Midlands</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>North West</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>North East</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>East Midlands</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>London</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yorkshire and The Humber</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>South West</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>East of England</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>South East</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>West Midlands</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>North West</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>North East</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>East Midlands</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ITL level 1  NQF level 4 or above  NQF level 3 or above  \\\n",
       "0                    England                  38.0                  59.0   \n",
       "1                      Wales                  32.0                  53.0   \n",
       "2                   Scotland                  37.0                  58.0   \n",
       "3           Northern Ireland                  31.0                  51.0   \n",
       "4                     London                  38.0                  59.0   \n",
       "5   Yorkshire and The Humber                  38.0                  59.0   \n",
       "6                 South West                  38.0                  59.0   \n",
       "7            East of England                  38.0                  59.0   \n",
       "8                 South East                  38.0                  59.0   \n",
       "9              West Midlands                  38.0                  59.0   \n",
       "10                North West                  38.0                  59.0   \n",
       "11                North East                  38.0                  59.0   \n",
       "12             East Midlands                  38.0                  59.0   \n",
       "13                    London                  38.0                  59.0   \n",
       "14  Yorkshire and The Humber                  38.0                  59.0   \n",
       "15                South West                  38.0                  59.0   \n",
       "16           East of England                  38.0                  59.0   \n",
       "17                South East                  38.0                  59.0   \n",
       "18             West Midlands                  38.0                  59.0   \n",
       "19                North West                  38.0                  59.0   \n",
       "20                North East                  38.0                  59.0   \n",
       "21             East Midlands                  38.0                  59.0   \n",
       "\n",
       "    NQF level 2 or above  Year  \n",
       "0                   78.0  2010  \n",
       "1                   74.0  2010  \n",
       "2                   77.0  2010  \n",
       "3                   71.0  2010  \n",
       "4                   78.0  2010  \n",
       "5                   78.0  2010  \n",
       "6                   78.0  2010  \n",
       "7                   78.0  2010  \n",
       "8                   78.0  2010  \n",
       "9                   78.0  2010  \n",
       "10                  78.0  2010  \n",
       "11                  78.0  2010  \n",
       "12                  78.0  2010  \n",
       "13                  78.0  2010  \n",
       "14                  78.0  2010  \n",
       "15                  78.0  2010  \n",
       "16                  78.0  2010  \n",
       "17                  78.0  2010  \n",
       "18                  78.0  2010  \n",
       "19                  78.0  2010  \n",
       "20                  78.0  2010  \n",
       "21                  78.0  2010  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get education data from csv file \n",
    "education_df_2010 = pd.read_excel('data/Education/vol02_2011c3.xls', sheet_name='3.8', skiprows=11)\n",
    "# drop first 3 columns\n",
    "education_df_2010.drop(education_df_2010.columns[:3], axis=1, inplace=True)\n",
    "# drop only rows with NaN values\n",
    "education_df_2010.dropna(axis=0, how='all', inplace=True)\n",
    "# drop columns with NaN values\n",
    "education_df_2010.dropna(axis=1, how='all', inplace=True)\n",
    "# drop rows with NaN values in column 1\n",
    "education_df_2010.dropna(subset=education_df_2010.columns[0], inplace=True)\n",
    "# rename first column to 'ITL level 1'\n",
    "education_df_2010.rename(columns={education_df_2010.columns[0]: 'ITL level 1'}, inplace=True)\n",
    "# drop 2nd and 5th columns\n",
    "education_df_2010.drop(education_df_2010.columns[[1,4]], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# rename columns\n",
    "education_df_2010.rename(columns={'NQF level 4 or above2': 'NQF level 4 or above', \n",
    "                             'NQF level 3 or above3': 'NQF level 3 or above', 'NQF level 2 or above4': 'NQF level 2 or above'}, \n",
    "                             inplace=True)\n",
    "regions = ['London', 'Yorkshire and The Humber', 'South West', 'East of England', 'South East', 'West Midlands', 'North West', 'North East', 'East Midlands']\n",
    "# create new rows for regions\n",
    "education_df_2010 = education_df_2010.append(pd.DataFrame({'ITL level 1': regions}), ignore_index=True)\n",
    "# set values for NQF level 4 or above for regions with England value\n",
    "education_df_2010.loc[education_df_2010['ITL level 1'].isin(regions), 'NQF level 4 or above'] = education_df_2010.loc[education_df_2010['ITL level 1'] == 'England', 'NQF level 4 or above'].values[0]\n",
    "# set values for NQF level 3 or above for regions with England value\n",
    "education_df_2010.loc[education_df_2010['ITL level 1'].isin(regions), 'NQF level 3 or above'] = education_df_2010.loc[education_df_2010['ITL level 1'] == 'England', 'NQF level 3 or above'].values[0]\n",
    "# set values for NQF level 2 or above for regions with England value\n",
    "education_df_2010.loc[education_df_2010['ITL level 1'].isin(regions), 'NQF level 2 or above'] = education_df_2010.loc[education_df_2010['ITL level 1'] == 'England', 'NQF level 2 or above'].values[0]\n",
    "# add year column\n",
    "education_df_2010['Year'] = 2010\n",
    "# rename columns\n",
    "education_df_2010.rename(columns={'NQF level 4 or above2': 'NQF level 4 or above', \n",
    "                             'NQF level 3 or above3': 'NQF level 3 or above', 'NQF level 2 or above4': 'NQF level 2 or above'}, \n",
    "                             inplace=True)\n",
    "regions = ['London', 'Yorkshire and The Humber', 'South West', 'East of England', 'South East', 'West Midlands', 'North West', 'North East', 'East Midlands']\n",
    "# create new rows for regions\n",
    "education_df_2010 = education_df_2010.append(pd.DataFrame({'ITL level 1': regions}), ignore_index=True)\n",
    "# set values for NQF level 4 or above for regions with England value\n",
    "education_df_2010.loc[education_df_2010['ITL level 1'].isin(regions), 'NQF level 4 or above'] = education_df_2010.loc[education_df_2010['ITL level 1'] == 'England', 'NQF level 4 or above'].values[0]\n",
    "# set values for NQF level 3 or above for regions with England value\n",
    "education_df_2010.loc[education_df_2010['ITL level 1'].isin(regions), 'NQF level 3 or above'] = education_df_2010.loc[education_df_2010['ITL level 1'] == 'England', 'NQF level 3 or above'].values[0]\n",
    "# set values for NQF level 2 or above for regions with England value\n",
    "education_df_2010.loc[education_df_2010['ITL level 1'].isin(regions), 'NQF level 2 or above'] = education_df_2010.loc[education_df_2010['ITL level 1'] == 'England', 'NQF level 2 or above'].values[0]\n",
    "# add year column\n",
    "education_df_2010['Year'] = 2010\n",
    "education_df_2010\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITL level 3</th>\n",
       "      <th>Year</th>\n",
       "      <th>gdhi</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "      <th>ITL level 1</th>\n",
       "      <th>ITL level 2</th>\n",
       "      <th>Average variable unit price (Â£/kWh)</th>\n",
       "      <th>ULSP:  Pump price (p/litre)</th>\n",
       "      <th>ULSD: Pump price (p/litre)</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>Number of vehicles</th>\n",
       "      <th>Sum of Chargepoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Total</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "      <td>Cars</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aberdeen City and Aberdeenshire</td>\n",
       "      <td>2010</td>\n",
       "      <td>18736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2801</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>North Eastern Scotland</td>\n",
       "      <td>0.117261</td>\n",
       "      <td>116.904146</td>\n",
       "      <td>119.234615</td>\n",
       "      <td>Cars</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16824803</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2140</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "      <td>Other vehicles</td>\n",
       "      <td>Hybrid electric (petrol)</td>\n",
       "      <td>Total</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16824804</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2140</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "      <td>Total</td>\n",
       "      <td>Hybrid electric (petrol)</td>\n",
       "      <td>Company</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16824805</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2140</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "      <td>Total</td>\n",
       "      <td>Hybrid electric (petrol)</td>\n",
       "      <td>Disposal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16824806</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2140</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "      <td>Total</td>\n",
       "      <td>Hybrid electric (petrol)</td>\n",
       "      <td>Private</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16824807</th>\n",
       "      <td>West Northamptonshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>2140</td>\n",
       "      <td>East Midlands</td>\n",
       "      <td>Leicestershire, Rutland and Northamptonshire</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>114.092268</td>\n",
       "      <td>119.455858</td>\n",
       "      <td>Total</td>\n",
       "      <td>Hybrid electric (petrol)</td>\n",
       "      <td>Total</td>\n",
       "      <td>12000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33212998 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ITL level 3  Year     gdhi  sex  age  \\\n",
       "0         Aberdeen City and Aberdeenshire  2010  18736.0    1    0   \n",
       "2         Aberdeen City and Aberdeenshire  2010  18736.0    1    0   \n",
       "4         Aberdeen City and Aberdeenshire  2010  18736.0    1    0   \n",
       "6         Aberdeen City and Aberdeenshire  2010  18736.0    1    0   \n",
       "8         Aberdeen City and Aberdeenshire  2010  18736.0    1    0   \n",
       "...                                   ...   ...      ...  ...  ...   \n",
       "16824803            West Northamptonshire  2020  22354.0    2   90   \n",
       "16824804            West Northamptonshire  2020  22354.0    2   90   \n",
       "16824805            West Northamptonshire  2020  22354.0    2   90   \n",
       "16824806            West Northamptonshire  2020  22354.0    2   90   \n",
       "16824807            West Northamptonshire  2020  22354.0    2   90   \n",
       "\n",
       "          population    ITL level 1  \\\n",
       "0               2801       Scotland   \n",
       "2               2801       Scotland   \n",
       "4               2801       Scotland   \n",
       "6               2801       Scotland   \n",
       "8               2801       Scotland   \n",
       "...              ...            ...   \n",
       "16824803        2140  East Midlands   \n",
       "16824804        2140  East Midlands   \n",
       "16824805        2140  East Midlands   \n",
       "16824806        2140  East Midlands   \n",
       "16824807        2140  East Midlands   \n",
       "\n",
       "                                           ITL level 2  \\\n",
       "0                               North Eastern Scotland   \n",
       "2                               North Eastern Scotland   \n",
       "4                               North Eastern Scotland   \n",
       "6                               North Eastern Scotland   \n",
       "8                               North Eastern Scotland   \n",
       "...                                                ...   \n",
       "16824803  Leicestershire, Rutland and Northamptonshire   \n",
       "16824804  Leicestershire, Rutland and Northamptonshire   \n",
       "16824805  Leicestershire, Rutland and Northamptonshire   \n",
       "16824806  Leicestershire, Rutland and Northamptonshire   \n",
       "16824807  Leicestershire, Rutland and Northamptonshire   \n",
       "\n",
       "          Average variable unit price (Â£/kWh)   ULSP:  Pump price (p/litre)  \\\n",
       "0                                    0.117261                    116.904146   \n",
       "2                                    0.117261                    116.904146   \n",
       "4                                    0.117261                    116.904146   \n",
       "6                                    0.117261                    116.904146   \n",
       "8                                    0.117261                    116.904146   \n",
       "...                                       ...                           ...   \n",
       "16824803                             0.166876                    114.092268   \n",
       "16824804                             0.166876                    114.092268   \n",
       "16824805                             0.166876                    114.092268   \n",
       "16824806                             0.166876                    114.092268   \n",
       "16824807                             0.166876                    114.092268   \n",
       "\n",
       "          ULSD: Pump price (p/litre)           BodyType  \\\n",
       "0                         119.234615  Buses and coaches   \n",
       "2                         119.234615  Buses and coaches   \n",
       "4                         119.234615  Buses and coaches   \n",
       "6                         119.234615               Cars   \n",
       "8                         119.234615               Cars   \n",
       "...                              ...                ...   \n",
       "16824803                  119.455858     Other vehicles   \n",
       "16824804                  119.455858              Total   \n",
       "16824805                  119.455858              Total   \n",
       "16824806                  119.455858              Total   \n",
       "16824807                  119.455858              Total   \n",
       "\n",
       "                              Fuel Keepership  Number of vehicles  \\\n",
       "0                 Battery electric    Company                   0   \n",
       "2                 Battery electric    Private                   0   \n",
       "4                 Battery electric      Total                   0   \n",
       "6                 Battery electric    Company                   0   \n",
       "8                 Battery electric    Private                   0   \n",
       "...                            ...        ...                 ...   \n",
       "16824803  Hybrid electric (petrol)      Total                   0   \n",
       "16824804  Hybrid electric (petrol)    Company                   0   \n",
       "16824805  Hybrid electric (petrol)   Disposal                   0   \n",
       "16824806  Hybrid electric (petrol)    Private               10000   \n",
       "16824807  Hybrid electric (petrol)      Total               12000   \n",
       "\n",
       "          Sum of Chargepoints  \n",
       "0                           0  \n",
       "2                           0  \n",
       "4                           0  \n",
       "6                           0  \n",
       "8                           0  \n",
       "...                       ...  \n",
       "16824803                    0  \n",
       "16824804                    0  \n",
       "16824805                    0  \n",
       "16824806                    0  \n",
       "16824807                    0  \n",
       "\n",
       "[33212998 rows x 16 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates\n",
    "all_vehicles_electric__df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scotland', 'Northern Ireland', 'London',\n",
       "       'Yorkshire and The Humber', 'South West', 'East of England',\n",
       "       'South East', 'West Midlands', 'North West', 'Wales', 'North East',\n",
       "       'East Midlands'], dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vehicles_electric__df['ITL level 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe for chargepoints, gdhi, population, ownership, sex, age to do analysis\n",
    "all_vehicles_electric__df\n",
    "# save the dataframe as a porquet file\n",
    "all_vehicles_electric__df.to_parquet('data/Cleaned data/all_vehicles_electric__df.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "      <th>Year</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>BodyType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>30% ZEV sales in M/HDVs by 2030, 100% by 2040</td>\n",
       "      <td>M/HDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heavy goods vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2022</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2022</td>\n",
       "      <td>Plug-in hybrid electric (diesel)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2022</td>\n",
       "      <td>Plug-in hybrid electric (petrol)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2022</td>\n",
       "      <td>Range extended electric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2022</td>\n",
       "      <td>Hybrid electric (petrol)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>30% ZEV sales in M/HDVs by 2030, 100% by 2040</td>\n",
       "      <td>M/HDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heavy goods vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Proposal</td>\n",
       "      <td>End the sale of non-ZEV HDVs under 26t gross v...</td>\n",
       "      <td>M/HDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heavy goods vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Legislation</td>\n",
       "      <td>Grant schemes for EV charging infrastructure i...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2016</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Legislation</td>\n",
       "      <td>Grant schemes for EV charging infrastructure i...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2016</td>\n",
       "      <td>Plug-in hybrid electric (diesel)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Legislation</td>\n",
       "      <td>Grant schemes for EV charging infrastructure i...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2016</td>\n",
       "      <td>Plug-in hybrid electric (petrol)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Legislation</td>\n",
       "      <td>Grant schemes for EV charging infrastructure i...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2016</td>\n",
       "      <td>Range extended electric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Legislation</td>\n",
       "      <td>Grant schemes for EV charging infrastructure i...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2016</td>\n",
       "      <td>Hybrid electric (petrol)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Legislation</td>\n",
       "      <td>A grant of 20% available for vehicles with at ...</td>\n",
       "      <td>M/HDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heavy goods vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Legislation</td>\n",
       "      <td>Grants towards the purchase of LCVs and taxis</td>\n",
       "      <td>LDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Light goods vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Phase out date for the sale of new petrol and ...</td>\n",
       "      <td>LDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Light goods vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Proposal</td>\n",
       "      <td>Net Zero Strategy: Plans to introduce an LDV Z...</td>\n",
       "      <td>LDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Light goods vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Purchase of 4 000 ZEV buses as part of the Bus...</td>\n",
       "      <td>Bus</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buses and coaches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Regulations in 2021 to mandate EV charge point...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2021</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Regulations in 2021 to mandate EV charge point...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2021</td>\n",
       "      <td>Plug-in hybrid electric (diesel)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Regulations in 2021 to mandate EV charge point...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2021</td>\n",
       "      <td>Plug-in hybrid electric (petrol)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Regulations in 2021 to mandate EV charge point...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2021</td>\n",
       "      <td>Range extended electric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>Regulations in 2021 to mandate EV charge point...</td>\n",
       "      <td>EVSE</td>\n",
       "      <td>2021</td>\n",
       "      <td>Hybrid electric (petrol)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ambition</td>\n",
       "      <td>30% ZEV sales in M/HDVs by 2030, 100% by 2040</td>\n",
       "      <td>M/HDV</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heavy goods vehicles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type                                        Description Category  \\\n",
       "0      Ambition      30% ZEV sales in M/HDVs by 2030, 100% by 2040    M/HDV   \n",
       "2      Ambition  Electric vehicle infrastructure strategy: Arou...     EVSE   \n",
       "3      Ambition  Electric vehicle infrastructure strategy: Arou...     EVSE   \n",
       "4      Ambition  Electric vehicle infrastructure strategy: Arou...     EVSE   \n",
       "5      Ambition  Electric vehicle infrastructure strategy: Arou...     EVSE   \n",
       "6      Ambition  Electric vehicle infrastructure strategy: Arou...     EVSE   \n",
       "7      Ambition      30% ZEV sales in M/HDVs by 2030, 100% by 2040    M/HDV   \n",
       "9      Proposal  End the sale of non-ZEV HDVs under 26t gross v...    M/HDV   \n",
       "12  Legislation  Grant schemes for EV charging infrastructure i...     EVSE   \n",
       "13  Legislation  Grant schemes for EV charging infrastructure i...     EVSE   \n",
       "14  Legislation  Grant schemes for EV charging infrastructure i...     EVSE   \n",
       "15  Legislation  Grant schemes for EV charging infrastructure i...     EVSE   \n",
       "16  Legislation  Grant schemes for EV charging infrastructure i...     EVSE   \n",
       "17  Legislation  A grant of 20% available for vehicles with at ...    M/HDV   \n",
       "18  Legislation      Grants towards the purchase of LCVs and taxis      LDV   \n",
       "19     Ambition  Phase out date for the sale of new petrol and ...      LDV   \n",
       "20     Proposal  Net Zero Strategy: Plans to introduce an LDV Z...      LDV   \n",
       "21     Ambition  Purchase of 4 000 ZEV buses as part of the Bus...      Bus   \n",
       "22     Ambition  Regulations in 2021 to mandate EV charge point...     EVSE   \n",
       "23     Ambition  Regulations in 2021 to mandate EV charge point...     EVSE   \n",
       "24     Ambition  Regulations in 2021 to mandate EV charge point...     EVSE   \n",
       "25     Ambition  Regulations in 2021 to mandate EV charge point...     EVSE   \n",
       "26     Ambition  Regulations in 2021 to mandate EV charge point...     EVSE   \n",
       "27     Ambition      30% ZEV sales in M/HDVs by 2030, 100% by 2040    M/HDV   \n",
       "\n",
       "    Year                              Fuel              BodyType  \n",
       "0   2021                               NaN  Heavy goods vehicles  \n",
       "2   2022                  Battery electric                   NaN  \n",
       "3   2022  Plug-in hybrid electric (diesel)                   NaN  \n",
       "4   2022  Plug-in hybrid electric (petrol)                   NaN  \n",
       "5   2022           Range extended electric                   NaN  \n",
       "6   2022          Hybrid electric (petrol)                   NaN  \n",
       "7   2021                               NaN  Heavy goods vehicles  \n",
       "9   2021                               NaN  Heavy goods vehicles  \n",
       "12  2016                  Battery electric                   NaN  \n",
       "13  2016  Plug-in hybrid electric (diesel)                   NaN  \n",
       "14  2016  Plug-in hybrid electric (petrol)                   NaN  \n",
       "15  2016           Range extended electric                   NaN  \n",
       "16  2016          Hybrid electric (petrol)                   NaN  \n",
       "17  2021                               NaN  Heavy goods vehicles  \n",
       "18  2021                               NaN  Light goods vehicles  \n",
       "19  2021                               NaN  Light goods vehicles  \n",
       "20  2021                               NaN  Light goods vehicles  \n",
       "21  2021                               NaN     Buses and coaches  \n",
       "22  2021                  Battery electric                   NaN  \n",
       "23  2021  Plug-in hybrid electric (diesel)                   NaN  \n",
       "24  2021  Plug-in hybrid electric (petrol)                   NaN  \n",
       "25  2021           Range extended electric                   NaN  \n",
       "26  2021          Hybrid electric (petrol)                   NaN  \n",
       "27  2021                               NaN  Heavy goods vehicles  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in government_policy csv\n",
    "government_policy_df = pd.read_csv('data/government_policy.csv')\n",
    "government_policy_df\n",
    "# delete columns\n",
    "government_policy_df.drop(['Source', 'Country','Region','Scope'], axis=1, inplace=True)\n",
    "# create a new column called Fuel Type and set it to 'Electric' for rows where Category contains \"EV\"\n",
    "government_policy_df.loc[government_policy_df['Category'].str.contains('EV', case=False, na=False), 'Fuel'] = 'electric'\n",
    "# Create a new dataframe with the desired fuel types\n",
    "fuel_types_df = pd.DataFrame({\n",
    "    'Fuel2': ['Battery electric', 'Plug-in hybrid electric (diesel)', 'Plug-in hybrid electric (petrol)',\n",
    "             'Range extended electric', 'Hybrid electric (petrol)']\n",
    "})\n",
    "\n",
    "fuel_types_df[\"Fuel\"] = \"electric\"\n",
    "\n",
    "# Merge the fuel_types_df with government_policy_df\n",
    "government_policy_df = government_policy_df.merge(fuel_types_df, how='left', on='Fuel')\n",
    "\n",
    "# if fuel is 'electric' then make multiple rows for fuel2 where values are 'Battery electric', 'Plug-in hybrid electric (diesel)', 'Plug-in hybrid electric (petrol)', 'Range extended electric' and 'Hybrid electric (petrol)'\n",
    "\n",
    "# set the row to Diesel for rows where Category contains \"DV\"\n",
    "government_policy_df.loc[government_policy_df['Category'].str.contains('DV', case=False, na=False), 'Fuel'] = 'diesel'\n",
    "# set the row to \"Light goods vehicles\" for rows were Category contains \"LDV\"\n",
    "government_policy_df.loc[government_policy_df['Category'].str.contains('LDV', case=False, na=False), 'BodyType'] = 'Light goods vehicles'\n",
    "# set the row to \"Heavy goods vehicles\" for rows were Category contains \"HDV\"\n",
    "government_policy_df.loc[government_policy_df['Category'].str.contains('HDV', case=False, na=False), 'BodyType'] = 'Heavy goods vehicles'\n",
    "# set the row to \"Buses and coaches\" for rows were Category contains \"Bus\"\n",
    "government_policy_df.loc[government_policy_df['Category'].str.contains('Bus', case=False, na=False), 'BodyType'] = 'Buses and coaches'\n",
    "# drop Fuel column\n",
    "government_policy_df.drop(['Fuel'], axis=1, inplace=True)\n",
    "# rename Fuel2 to Fuel\n",
    "government_policy_df.rename(columns={'Fuel2': 'Fuel'}, inplace=True)\n",
    "\n",
    "government_policy_df.dropna(subset=['Fuel', 'BodyType'], how='all', inplace=True)\n",
    "government_policy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Battery electric', 'Total', 'Plug-in hybrid electric (diesel)',\n",
       "       'Plug-in hybrid electric (petrol)', 'Range extended electric',\n",
       "       'Diesel', 'Hybrid electric (petrol)', 'Other fuels', 'Petrol'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_df['Fuel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Units</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>ONS Sort</th>\n",
       "      <th>ONS Code</th>\n",
       "      <th>ONS Geography</th>\n",
       "      <th>Number of vehicles</th>\n",
       "      <th>Government Policy_EV</th>\n",
       "      <th>Government Policy_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>1.0</td>\n",
       "      <td>K02000001</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>2.0</td>\n",
       "      <td>K03000001</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>38</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>3.0</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>0</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>0</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299769</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>462.0</td>\n",
       "      <td>N09000010</td>\n",
       "      <td>Newry, Mourne and Down</td>\n",
       "      <td>494</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299770</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>463.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Local Authority unknown within Northern Ire...</td>\n",
       "      <td>14</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299771</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>464.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Vehicle under disposal, previously GB</td>\n",
       "      <td>2914</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299772</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>465.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Vehicle under disposal, previously NI</td>\n",
       "      <td>56</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299773</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>466.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Region or county unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1299774 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year      Units           BodyType              Fuel Keepership  \\\n",
       "0        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "1        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "2        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "3        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "4        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "...       ...        ...                ...               ...        ...   \n",
       "1299769  2022  Thousands              Total             Total      Total   \n",
       "1299770  2022  Thousands              Total             Total      Total   \n",
       "1299771  2022  Thousands              Total             Total      Total   \n",
       "1299772  2022  Thousands              Total             Total      Total   \n",
       "1299773  2022  Thousands              Total             Total      Total   \n",
       "\n",
       "         ONS Sort   ONS Code  \\\n",
       "0             1.0  K02000001   \n",
       "1             2.0  K03000001   \n",
       "2             3.0  E92000001   \n",
       "3             4.0  E12000001   \n",
       "4             5.0  E06000047   \n",
       "...           ...        ...   \n",
       "1299769     462.0  N09000010   \n",
       "1299770     463.0        [z]   \n",
       "1299771     464.0        [z]   \n",
       "1299772     465.0        [z]   \n",
       "1299773     466.0        [z]   \n",
       "\n",
       "                                             ONS Geography  \\\n",
       "0                                           United Kingdom   \n",
       "1                                            Great Britain   \n",
       "2                                                  England   \n",
       "3                                               North East   \n",
       "4                                            County Durham   \n",
       "...                                                    ...   \n",
       "1299769                             Newry, Mourne and Down   \n",
       "1299770     Local Authority unknown within Northern Ire...   \n",
       "1299771              Vehicle under disposal, previously GB   \n",
       "1299772              Vehicle under disposal, previously NI   \n",
       "1299773                           Region or county unknown   \n",
       "\n",
       "         Number of vehicles Government Policy_EV  \\\n",
       "0                         0            No policy   \n",
       "1                        38            No policy   \n",
       "2                        36            No policy   \n",
       "3                         0            No policy   \n",
       "4                         0            No policy   \n",
       "...                     ...                  ...   \n",
       "1299769                 494            No policy   \n",
       "1299770                  14            No policy   \n",
       "1299771                2914            No policy   \n",
       "1299772                  56            No policy   \n",
       "1299773                  14            No policy   \n",
       "\n",
       "                                  Government Policy_weight  \n",
       "0                                                No policy  \n",
       "1                                                No policy  \n",
       "2                                                No policy  \n",
       "3                                                No policy  \n",
       "4                                                No policy  \n",
       "...                                                    ...  \n",
       "1299769  Electric vehicle infrastructure strategy: Arou...  \n",
       "1299770  Electric vehicle infrastructure strategy: Arou...  \n",
       "1299771  Electric vehicle infrastructure strategy: Arou...  \n",
       "1299772  Electric vehicle infrastructure strategy: Arou...  \n",
       "1299773  Electric vehicle infrastructure strategy: Arou...  \n",
       "\n",
       "[1299774 rows x 11 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary mapping 'Year','Fuel Type' and 'BodyType' to 'Description' in government_policy_electric_df\n",
    "policy_dict = government_policy_df.set_index(['Year','Fuel'])['Description'].to_dict()\n",
    "weight_dict = government_policy_df.set_index(['Year','BodyType'])['Description'].to_dict()\n",
    "# update the 'Government Policy' column in vehicle_df based on the dictionary where Fuel contains strings from Fuel\n",
    "vehicle_df['Government Policy_EV'] = vehicle_df.set_index(['Year','Fuel']).index.map(policy_dict).fillna('No policy')\n",
    "vehicle_df['Government Policy_weight'] = vehicle_df.set_index(['Year','BodyType']).index.map(weight_dict).fillna('No policy')\n",
    "# drop duplicates\n",
    "vehicle_df.drop_duplicates(inplace=True)\n",
    "# get all values in Year column in all_vehicles_electric__df\n",
    "vehicle_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_df['BodyType'].unique()\n",
    "# save the dataframe to a porquet file\n",
    "vehicle_df.to_parquet('data/Cleaned data/vehicle_policy_df.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Units</th>\n",
       "      <th>BodyType</th>\n",
       "      <th>Fuel</th>\n",
       "      <th>Keepership</th>\n",
       "      <th>ONS Sort</th>\n",
       "      <th>ONS Code</th>\n",
       "      <th>ONS Geography</th>\n",
       "      <th>Number of vehicles</th>\n",
       "      <th>Government Policy_EV</th>\n",
       "      <th>Government Policy_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>1.0</td>\n",
       "      <td>K02000001</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>2.0</td>\n",
       "      <td>K03000001</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>38</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>3.0</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>North East</td>\n",
       "      <td>0</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>Number</td>\n",
       "      <td>Buses and coaches</td>\n",
       "      <td>Battery electric</td>\n",
       "      <td>Company</td>\n",
       "      <td>5.0</td>\n",
       "      <td>E06000047</td>\n",
       "      <td>County Durham</td>\n",
       "      <td>0</td>\n",
       "      <td>No policy</td>\n",
       "      <td>No policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299769</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>462.0</td>\n",
       "      <td>N09000010</td>\n",
       "      <td>Newry, Mourne and Down</td>\n",
       "      <td>494</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299770</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>463.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Local Authority unknown within Northern Ire...</td>\n",
       "      <td>14</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299771</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>464.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Vehicle under disposal, previously GB</td>\n",
       "      <td>2914</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299772</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>465.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Vehicle under disposal, previously NI</td>\n",
       "      <td>56</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299773</th>\n",
       "      <td>2022</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>466.0</td>\n",
       "      <td>[z]</td>\n",
       "      <td>Region or county unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>No policy</td>\n",
       "      <td>Electric vehicle infrastructure strategy: Arou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1299774 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year      Units           BodyType              Fuel Keepership  \\\n",
       "0        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "1        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "2        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "3        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "4        2009     Number  Buses and coaches  Battery electric    Company   \n",
       "...       ...        ...                ...               ...        ...   \n",
       "1299769  2022  Thousands              Total             Total      Total   \n",
       "1299770  2022  Thousands              Total             Total      Total   \n",
       "1299771  2022  Thousands              Total             Total      Total   \n",
       "1299772  2022  Thousands              Total             Total      Total   \n",
       "1299773  2022  Thousands              Total             Total      Total   \n",
       "\n",
       "         ONS Sort   ONS Code  \\\n",
       "0             1.0  K02000001   \n",
       "1             2.0  K03000001   \n",
       "2             3.0  E92000001   \n",
       "3             4.0  E12000001   \n",
       "4             5.0  E06000047   \n",
       "...           ...        ...   \n",
       "1299769     462.0  N09000010   \n",
       "1299770     463.0        [z]   \n",
       "1299771     464.0        [z]   \n",
       "1299772     465.0        [z]   \n",
       "1299773     466.0        [z]   \n",
       "\n",
       "                                             ONS Geography  \\\n",
       "0                                           United Kingdom   \n",
       "1                                            Great Britain   \n",
       "2                                                  England   \n",
       "3                                               North East   \n",
       "4                                            County Durham   \n",
       "...                                                    ...   \n",
       "1299769                             Newry, Mourne and Down   \n",
       "1299770     Local Authority unknown within Northern Ire...   \n",
       "1299771              Vehicle under disposal, previously GB   \n",
       "1299772              Vehicle under disposal, previously NI   \n",
       "1299773                           Region or county unknown   \n",
       "\n",
       "         Number of vehicles Government Policy_EV  \\\n",
       "0                         0            No policy   \n",
       "1                        38            No policy   \n",
       "2                        36            No policy   \n",
       "3                         0            No policy   \n",
       "4                         0            No policy   \n",
       "...                     ...                  ...   \n",
       "1299769                 494            No policy   \n",
       "1299770                  14            No policy   \n",
       "1299771                2914            No policy   \n",
       "1299772                  56            No policy   \n",
       "1299773                  14            No policy   \n",
       "\n",
       "                                  Government Policy_weight  \n",
       "0                                                No policy  \n",
       "1                                                No policy  \n",
       "2                                                No policy  \n",
       "3                                                No policy  \n",
       "4                                                No policy  \n",
       "...                                                    ...  \n",
       "1299769  Electric vehicle infrastructure strategy: Arou...  \n",
       "1299770  Electric vehicle infrastructure strategy: Arou...  \n",
       "1299771  Electric vehicle infrastructure strategy: Arou...  \n",
       "1299772  Electric vehicle infrastructure strategy: Arou...  \n",
       "1299773  Electric vehicle infrastructure strategy: Arou...  \n",
       "\n",
       "[1299774 rows x 11 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
